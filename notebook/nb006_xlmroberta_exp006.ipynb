{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"nb006_xlmroberta_exp006.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"11T5zct7pwivKK8bOdJMalEXXZPHeSMuT","authorship_tag":"ABX9TyOIzn/mAqWe3cozArDkShK4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f36976d19af442b2bee21b6871aa5fb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_04109b339741416aaf109d278cac609d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cdea76b715ca44a69dd4639328071883","IPY_MODEL_1d9d02f8f6b141df80f6b991d1cfaf44","IPY_MODEL_9a8306523d184c66a0f4f1a94bc71978"]}},"04109b339741416aaf109d278cac609d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cdea76b715ca44a69dd4639328071883":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cb3b8dbf495e480999835c85dc0c8fc9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"[get features]: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ed4cff752326438f938df11e05a622c5"}},"1d9d02f8f6b141df80f6b991d1cfaf44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ca9b1bf5b46b44bf87452d970a00bea6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":7506,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7506,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd0ca6f2267146cfbe5a5cfb14352bad"}},"9a8306523d184c66a0f4f1a94bc71978":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5b4e81ab49f041bf9ab7e1697538e843","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7506/7506 [02:20&lt;00:00, 72.21it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8fefd820a3724e8a9bddc7b60463c9b0"}},"cb3b8dbf495e480999835c85dc0c8fc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ed4cff752326438f938df11e05a622c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca9b1bf5b46b44bf87452d970a00bea6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bd0ca6f2267146cfbe5a5cfb14352bad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b4e81ab49f041bf9ab7e1697538e843":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8fefd820a3724e8a9bddc7b60463c9b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b2711adaa0f44279896e625741bd530":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_be0d10db18c045a0b45f05b5e7074003","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c5ff308a37034b79b043c4043c2d9585","IPY_MODEL_3e01e98f070f41a4bdd2dc689d719bdd","IPY_MODEL_d7e95195fede49b2978db52ab415fcbf"]}},"be0d10db18c045a0b45f05b5e7074003":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c5ff308a37034b79b043c4043c2d9585":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8a1c4dddf940479394636af8751dfc33","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"[get features]: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_31e0993a3d89406d947c4028d5b9b5d0"}},"3e01e98f070f41a4bdd2dc689d719bdd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ed035d1fd6624dfc8a068df43454b7ac","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":223,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":223,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_16a12448e53d40dfb2a7f2fe27db1883"}},"d7e95195fede49b2978db52ab415fcbf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_783e4940578f4fdda5594f1f5be6b177","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 223/223 [00:12&lt;00:00, 16.99it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d4be154f54af4c088d4ab2c577d8351b"}},"8a1c4dddf940479394636af8751dfc33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"31e0993a3d89406d947c4028d5b9b5d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed035d1fd6624dfc8a068df43454b7ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"16a12448e53d40dfb2a7f2fe27db1883":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"783e4940578f4fdda5594f1f5be6b177":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d4be154f54af4c088d4ab2c577d8351b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2156bccdc8ef4a7a8a9dd42fbd832e8f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bb9f360aa89246598f2162830f704e2d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ca3a9b470eae49ff8507ac199b38958f","IPY_MODEL_65fcf2f7c52b4abc80e34a59b8f7d5d8","IPY_MODEL_0caa940dd6f549e6b3f5b39cf845b6e9"]}},"bb9f360aa89246598f2162830f704e2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"ca3a9b470eae49ff8507ac199b38958f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f1005c91aa7a48ee80cfa4e5ac6497b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validation sanity check:   0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db774290672f4f7a91fd18d542a9890d"}},"65fcf2f7c52b4abc80e34a59b8f7d5d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4081c4bc57e44771bf6bf86516a9408a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f325cd8f7d0444ef92dae7758db8de27"}},"0caa940dd6f549e6b3f5b39cf845b6e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_507db6298bb742a3ae4e3995a08902c4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/2 [00:02&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ac622f3016848798d6bd66216b83ca3"}},"f1005c91aa7a48ee80cfa4e5ac6497b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"db774290672f4f7a91fd18d542a9890d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4081c4bc57e44771bf6bf86516a9408a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f325cd8f7d0444ef92dae7758db8de27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"507db6298bb742a3ae4e3995a08902c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2ac622f3016848798d6bd66216b83ca3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a992b20dd62841118fb18fd5b47dd897":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fee7c7a04ec84e73bb738175754b8c14","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4237b0ffddad4ec19dd7558811138aa5","IPY_MODEL_d5d8fd8723904436904bfc78a2e272aa","IPY_MODEL_79fba9af8b724c759c8b65f0d5989ead"]}},"fee7c7a04ec84e73bb738175754b8c14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"4237b0ffddad4ec19dd7558811138aa5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f74d06efc9ec4effb8e7abc12f04d3a8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 0:  97%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1fe8c5fa6e2c4d6d821ffeff99956f40"}},"d5d8fd8723904436904bfc78a2e272aa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7461dc1c3b224ca2ac4f4287e8b0df07","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":5066,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4920,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4fa26e5191d84d7bbbcdb03a917c8248"}},"79fba9af8b724c759c8b65f0d5989ead":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4782e5e8179c4451a4082cd57a037992","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4920/5066 [45:54&lt;01:21,  1.79it/s, loss=0.547, v_num=p7eg, train/loss_step=0.697]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01ef1617f7994273b5501199cf62af59"}},"f74d06efc9ec4effb8e7abc12f04d3a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1fe8c5fa6e2c4d6d821ffeff99956f40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7461dc1c3b224ca2ac4f4287e8b0df07":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4fa26e5191d84d7bbbcdb03a917c8248":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4782e5e8179c4451a4082cd57a037992":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"01ef1617f7994273b5501199cf62af59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f378c4e07757408191b89630f377e644":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_370a8c8066bd40c5831c8a530ae0a266","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_af94f05e9eb6414593bb9c5c482bee63","IPY_MODEL_9907b76582fa4b7894772e5c958e66ab","IPY_MODEL_6edb4cacdb38485180366bfacbf6a4e3"]}},"370a8c8066bd40c5831c8a530ae0a266":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"af94f05e9eb6414593bb9c5c482bee63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a013024124524e9aa717c685e2707822","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating:  12%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c5c99e4d7b94d3ca9212c2e108eebd4"}},"9907b76582fa4b7894772e5c958e66ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0f30da9241a14d89906fdd8268db71f1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":172,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":20,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be63aff8b7344ab28c0a780be87eac83"}},"6edb4cacdb38485180366bfacbf6a4e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a02f021260754236baa9b2f02fb7e9c1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 20/172 [00:14&lt;01:49,  1.39it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b46aa3597d83463b8c3e95e106255873"}},"a013024124524e9aa717c685e2707822":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3c5c99e4d7b94d3ca9212c2e108eebd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f30da9241a14d89906fdd8268db71f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"be63aff8b7344ab28c0a780be87eac83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a02f021260754236baa9b2f02fb7e9c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b46aa3597d83463b8c3e95e106255873":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7PiERPR3JwG","executionInfo":{"status":"ok","timestamp":1632579584586,"user_tz":-540,"elapsed":242,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}},"outputId":"9949d7c6-5247-4cea-e9b7-f74b709aca2e"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Sep 25 14:19:44 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1uHWvJoM1MB","executionInfo":{"status":"ok","timestamp":1632579586038,"user_tz":-540,"elapsed":1457,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}},"outputId":"7093d93a-72ed-4076-b1c4-b641f6785592"},"source":["!mkdir ~/.kaggle\n","!cp /content/drive/MyDrive/Colab/kaggle/kaggle.json ~/.kaggle\n","\n","!pip install --upgrade --force-reinstall --no-deps kaggle"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/root/.kaggle’: File exists\n","Collecting kaggle\n","  Using cached kaggle-1.5.12-py3-none-any.whl\n","Installing collected packages: kaggle\n","  Attempting uninstall: kaggle\n","    Found existing installation: kaggle 1.5.12\n","    Uninstalling kaggle-1.5.12:\n","      Successfully uninstalled kaggle-1.5.12\n","Successfully installed kaggle-1.5.12\n"]}]},{"cell_type":"code","metadata":{"id":"Urj-Rfgn3UBV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632579586862,"user_tz":-540,"elapsed":828,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}},"outputId":"2758137f-5841-4a1b-e6e8-a12829a73830"},"source":["!cp -r /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/input /content\n","!mkdir /content/checkpoint"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/content/checkpoint’: File exists\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6dGMLhJ3f0r","executionInfo":{"status":"ok","timestamp":1632579591405,"user_tz":-540,"elapsed":4547,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}},"outputId":"698cdb4b-e288-47b8-a1f7-8a171d4ad90f"},"source":["!pip install -U pytorch-lightning transformers wandb sentencepiece torchsummaryX"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.7/dist-packages (1.4.8)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.3)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: torchsummaryX in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.2)\n","Requirement already satisfied: torchmetrics>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.5.1)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.6.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.0)\n","Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.3.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.7.4.3)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.18.2)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.9.0+cu102)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (5.4.1)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2021.9.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.7.4.post0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (2.4.7)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.40.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.17)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.4.1)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.24)\n","Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n","Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n","Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.1.5)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (5.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.2.0)\n","Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.6.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.5.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2018.9)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"]}]},{"cell_type":"code","metadata":{"id":"EGc_0a3l32o8"},"source":["import os\n","import random\n","from dataclasses import dataclass\n","import copy\n","import gc\n","\n","import numpy as np\n","import pandas as pd\n","import math\n","import sklearn.model_selection as sms\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n","import torch.optim as optim\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning import Trainer, seed_everything\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","from pytorch_lightning.loggers import WandbLogger\n","import wandb\n","\n","from transformers import AutoTokenizer, AutoModel, AutoConfig, AdamW, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","from torchsummaryX import summary\n","\n","from collections import defaultdict, OrderedDict\n","from tqdm.notebook import tqdm\n","\n","import json\n","from pathlib import Path\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2pbFM7_B4Emp"},"source":["## config"]},{"cell_type":"code","metadata":{"id":"HemZ1ng-4FIW"},"source":["@dataclass\n","class Config:\n","    #########################\n","    # Globals #\n","    #########################\n","    exp_name = \"exp006\"\n","    debug = False\n","    gpus = 1\n","    num_workers = 8\n","    num_epochs = 1\n","    grad_accumulate = 8\n","    fp16 = False\n","    seed = [42, 2434, 98, 24, 1991]\n","    #########################\n","    # Data #\n","    #########################\n","    train_csv = \"input/train.csv\"\n","    test_csv = \"input/test.csv\"\n","    sample_submission_csv = \"input/sample_submission.csv\"\n","    mlqa_hindi_csv = \"input/external_data/mlqa_hindi.csv\"\n","    xquad_hindi_csv = \"input/external_data/xquad_hindi.csv\"\n","    checkpoint_dir = \"checkpoint\"\n","    #########################\n","    # Split #\n","    #########################\n","    split_name = \"StratifiedKFold\"\n","    split_params = {\n","        \"n_splits\": 5,\n","        \"random_state\": 42,\n","        \"shuffle\": True,\n","        }\n","    #########################\n","    # Tokenizer #\n","    #########################\n","    tokenizer_name = \"deepset/xlm-roberta-large-squad2\"\n","    max_seq_length = 400\n","    doc_stride = 135\n","    truncation = \"only_second\"\n","    padding = \"max_length\"\n","    #########################\n","    # Dataset #\n","    #########################\n","    #########################\n","    # DataLoader #\n","    #########################\n","    train_batch_size = 4\n","    valid_batch_size = 16\n","    test_batch_size = 128\n","    #########################\n","    # Model #\n","    #########################\n","    base_model_name = \"deepset/xlm-roberta-large-squad2\"\n","    base_model_config = \"deepset/xlm-roberta-large-squad2\"\n","    num_classes = 2\n","    init_layers = 1\n","    #########################\n","    # Criterion #\n","    #########################\n","    loss_name = \"CrossEntropyLoss\"\n","    loss_params = {\n","        \"ignore_index\": -1,\n","    }\n","    #########################\n","    # Optimizer #\n","    #########################\n","    optimizer_name = \"AdamW\"\n","    optimizer_params = {\n","        \"lr\": 1.5e-5,\n","        \"weight_decay\": 1e-2,\n","        \"eps\": 1e-8,\n","        \"correct_bias\": True\n","    }\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    header_weight_decay = 1e-2\n","    header_lr = 1e-3\n","    lr_decay = 0.98\n","    ######################\n","    # Scheduler #\n","    ######################\n","    scheduler_name = \"linear-warmup\"\n","    scheduler_params = {\n","        \"warmup_ratio\": 0.1,\n","    }\n","    ######################\n","    # Callbacks #\n","    ######################\n","    model_checkpoint_params = {\n","        \"monitor\": \"val/jaccard_epoch\",\n","        \"save_top_k\": 1,\n","        \"save_weights_only\": True,\n","    }\n","    early_stopping_params = {\n","        \"monitor\": \"val/jaccard_epoch\",\n","        \"min_delta\": 0.0,\n","        \"patience\": 5,\n","        \"verbose\": False,\n","        \"mode\": \"max\",\n","    }\n","    wandb_logger_params = {\n","        \"project\": \"kaggle-chaii-hindi-and-tamil-question-answering\"\n","    }\n","\n","\n","cfg = Config()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N75ldQ_N4_lF"},"source":["## utils"]},{"cell_type":"code","metadata":{"id":"N1OPGpKZ48h-"},"source":["def load_dataset(cfg):\n","    train_df = pd.read_csv(cfg.train_csv, nrows= 100 if cfg.debug else None)\n","    test_df = pd.read_csv(cfg.test_csv)\n","    external_mlqa_df = pd.read_csv(cfg.mlqa_hindi_csv)\n","    external_xquad_df = pd.read_csv(cfg.xquad_hindi_csv)\n","    external_train_df = pd.concat([external_mlqa_df, external_xquad_df], axis=0).reset_index(drop=True)\n","    sample_submission_df = pd.read_csv(cfg.sample_submission_csv)\n","\n","    return train_df, test_df, external_train_df, sample_submission_df\n","\n","\n","def get_split(cfg):\n","    split_name = cfg.split_name\n","    split_params = cfg.split_params\n","\n","    return sms.__getattribute__(split_name)(**split_params)\n","\n","\n","def get_fold(cfg, train_df: pd.DataFrame, y_train: pd.DataFrame):\n","    splitter = get_split(cfg)\n","    train_df[\"fold\"] = -1\n","    for fold_id, (train_idx, valid_idx) in enumerate(splitter.split(train_df, y_train)):\n","        train_df.loc[valid_idx, \"fold\"] = int(fold_id)\n","\n","    return train_df\n","\n","\n","def convert_answers(row):\n","    return {\"answer_start\": [row[0]], \"text\": [row[1]]}\n","\n","\n","def jaccard(str1, str2):\n","    a = set(str1.lower().split())\n","    b = set(str2.lower().split())\n","    c = a.intersection(b)\n","\n","    return float(len(c)) / (len(a) + len(b) - len(c))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RBsFiLLN5EVr"},"source":["## load data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":568},"id":"AwmhgEfk4vR8","executionInfo":{"status":"ok","timestamp":1632579600920,"user_tz":-540,"elapsed":879,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}},"outputId":"778a8d7f-ecdf-481e-c0e7-2ffb5818650a"},"source":["train_df, test_df, external_train_df, sample_submission_df = load_dataset(cfg)\n","\n","train_df = get_fold(cfg, train_df, train_df[\"language\"])\n","\n","external_train_df[\"fold\"] = -1\n","external_train_df[\"id\"] = list(np.arange(1, len(external_train_df) + 1))\n","train_df = pd.concat([train_df, external_train_df], axis=0).reset_index(drop=True)\n","\n","train_df[\"answers\"] = train_df[[\"answer_start\", \"answer_text\"]].apply(convert_answers, axis=1)\n","train_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>answer_text</th>\n","      <th>answer_start</th>\n","      <th>language</th>\n","      <th>fold</th>\n","      <th>answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>903deec17</td>\n","      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n","      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n","      <td>206</td>\n","      <td>53</td>\n","      <td>tamil</td>\n","      <td>2</td>\n","      <td>{'answer_start': [53], 'text': ['206']}</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>d9841668c</td>\n","      <td>காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...</td>\n","      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n","      <td>காசுமீரில்</td>\n","      <td>2358</td>\n","      <td>tamil</td>\n","      <td>0</td>\n","      <td>{'answer_start': [2358], 'text': ['காசுமீரில்']}</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29d154b56</td>\n","      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n","      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n","      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n","      <td>0</td>\n","      <td>tamil</td>\n","      <td>0</td>\n","      <td>{'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>41660850a</td>\n","      <td>குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...</td>\n","      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n","      <td>தாலாட்டு</td>\n","      <td>68</td>\n","      <td>tamil</td>\n","      <td>4</td>\n","      <td>{'answer_start': [68], 'text': ['தாலாட்டு']}</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>b29c82c22</td>\n","      <td>சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...</td>\n","      <td>பூமியின் அருகில் உள்ள விண்மீன் எது?</td>\n","      <td>சூரியனும்</td>\n","      <td>585</td>\n","      <td>tamil</td>\n","      <td>0</td>\n","      <td>{'answer_start': [585], 'text': ['சூரியனும்']}</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7724</th>\n","      <td>6611</td>\n","      <td>विद्युत आवेश के परिवर्तन की समय दर के रूप में ...</td>\n","      <td>इलेक्ट्रोस्टैटिक और चुंबकीय बल के योग के रूप क...</td>\n","      <td>इलेक्ट्रोस्टैटिक बल</td>\n","      <td>328</td>\n","      <td>hindi</td>\n","      <td>-1</td>\n","      <td>{'answer_start': [328], 'text': ['इलेक्ट्रोस्ट...</td>\n","    </tr>\n","    <tr>\n","      <th>7725</th>\n","      <td>6612</td>\n","      <td>उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...</td>\n","      <td>संरचनाओं में तनाव का कारण क्या बनता है?</td>\n","      <td>तनाव टेंसर</td>\n","      <td>343</td>\n","      <td>hindi</td>\n","      <td>-1</td>\n","      <td>{'answer_start': [343], 'text': ['तनाव टेंसर']}</td>\n","    </tr>\n","    <tr>\n","      <th>7726</th>\n","      <td>6613</td>\n","      <td>उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...</td>\n","      <td>किसी वस्तु के आयतन में क्रॉस सेक्शन क्षेत्र की...</td>\n","      <td>दबाव की शर्तें</td>\n","      <td>118</td>\n","      <td>hindi</td>\n","      <td>-1</td>\n","      <td>{'answer_start': [118], 'text': ['दबाव की शर्त...</td>\n","    </tr>\n","    <tr>\n","      <th>7727</th>\n","      <td>6614</td>\n","      <td>उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...</td>\n","      <td>सामान्य ताकतों से क्या जुड़ा है?</td>\n","      <td>दबाव की शर्तें</td>\n","      <td>118</td>\n","      <td>hindi</td>\n","      <td>-1</td>\n","      <td>{'answer_start': [118], 'text': ['दबाव की शर्त...</td>\n","    </tr>\n","    <tr>\n","      <th>7728</th>\n","      <td>6615</td>\n","      <td>उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...</td>\n","      <td>आयतन में क्षेत्र की गणना करते समय दबाव की क्या...</td>\n","      <td>नियम-निष्ठता</td>\n","      <td>101</td>\n","      <td>hindi</td>\n","      <td>-1</td>\n","      <td>{'answer_start': [101], 'text': ['नियम-निष्ठता']}</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7729 rows × 8 columns</p>\n","</div>"],"text/plain":["             id  ...                                            answers\n","0     903deec17  ...            {'answer_start': [53], 'text': ['206']}\n","1     d9841668c  ...   {'answer_start': [2358], 'text': ['காசுமீரில்']}\n","2     29d154b56  ...  {'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...\n","3     41660850a  ...       {'answer_start': [68], 'text': ['தாலாட்டு']}\n","4     b29c82c22  ...     {'answer_start': [585], 'text': ['சூரியனும்']}\n","...         ...  ...                                                ...\n","7724       6611  ...  {'answer_start': [328], 'text': ['इलेक्ट्रोस्ट...\n","7725       6612  ...    {'answer_start': [343], 'text': ['तनाव टेंसर']}\n","7726       6613  ...  {'answer_start': [118], 'text': ['दबाव की शर्त...\n","7727       6614  ...  {'answer_start': [118], 'text': ['दबाव की शर्त...\n","7728       6615  ...  {'answer_start': [101], 'text': ['नियम-निष्ठता']}\n","\n","[7729 rows x 8 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"WcJnS8s25JLn"},"source":["## preprocess"]},{"cell_type":"code","metadata":{"id":"nxgeHj2A82w0"},"source":["def prepare_train_features(cfg, example, tokenizer):\n","    example[\"question\"] = example[\"question\"].lstrip()\n","\n","    tokenized_example = tokenizer(\n","        example[\"question\"],\n","        example[\"context\"],\n","        truncation=cfg.truncation,\n","        max_length=cfg.max_seq_length,\n","        stride=cfg.doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=cfg.padding,\n","        # return_tensors=\"pt\"\n","    )\n","\n","    sample_mapping = tokenized_example.pop(\"overflow_to_sample_mapping\")\n","    offset_mapping = tokenized_example.pop(\"offset_mapping\")\n","\n","    features = []\n","    for i, offsets in enumerate(offset_mapping):\n","        feature = {}\n","\n","        input_ids  = tokenized_example[\"input_ids\"][i]\n","        attention_mask = tokenized_example[\"attention_mask\"][i]\n","\n","        feature[\"input_ids\"] = input_ids\n","        feature[\"attention_mask\"] = attention_mask\n","        feature[\"offset_mapping\"] = offsets\n","        feature[\"example_id\"] = example[\"id\"]\n","        feature[\"sequence_ids\"] = [0 if i is None else i for i in tokenized_example.sequence_ids(i)]\n","\n","        cls_index = input_ids.index(tokenizer.cls_token_id) # cls_token_id = 0, pad_token_id = 1\n","        sequence_ids = tokenized_example.sequence_ids(i)\n","\n","        # sample_indx = sample_mapping[i]\n","        answers = example[\"answers\"]\n","\n","        if len(answers[\"answer_start\"]) == 0: # sampleにanswerがなければ開始・終了位置をCLS(=[CLS], <s>)にする\n","            feature[\"start_position\"] = cls_index\n","            feature[\"end_position\"] = cls_index\n","        else:\n","            start_char = answers[\"answer_start\"][0] # answer部分の文字レベルの開始位置\n","            end_char = start_char + len(answers[\"text\"][0]) # answer部分の文字レベルの終了位置\n","\n","            token_start_index = 0 # sequenceにおけるcontext部分のトークンレベルの開始位置\n","            while sequence_ids[token_start_index] != 1: # sequence_idsが1(=context部分)になるまで足す(<s>,</s>, querstion部分を飛ばすイメージ)\n","                token_start_index += 1\n","\n","            token_end_index = len(input_ids) - 1 # sequenceにおけるcontext部分のトークンレベルの終了位置\n","            while sequence_ids[token_end_index] != 1: # sequence_idsが1(=context部分)になるまで引く(paddingはNoneなので<pad>部分を引くイメージ)\n","                token_end_index -= 1\n","\n","            # token_start_index, token_end_indexがanswer部分の範囲外にあればpositionを0(=[CLS], <s>)とする(truncationされてる場合はこっち)\n","            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n","                feature[\"start_position\"] = cls_index\n","                feature[\"end_position\"] = cls_index\n","            # star_char, end_charを含むtokenまでtoken_start_index, token_end_indexを調整\n","            else:\n","                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n","                    token_start_index += 1\n","                feature[\"start_position\"] = token_start_index - 1 # 行き過ぎた1token分戻す\n","\n","                while offsets[token_end_index][1] >= end_char:\n","                    token_end_index -= 1\n","                feature[\"end_position\"] = token_end_index + 1 # 行き過ぎた1token分戻す\n","\n","        features.append(feature)\n","\n","    return features\n","\n","\n","def prepare_test_features(cfg, example, tokenizer):\n","    example[\"question\"] = example[\"question\"].lstrip()\n","\n","    tokenized_example = tokenizer(\n","        example[\"question\"],\n","        example[\"context\"],\n","        truncation=cfg.truncation,\n","        max_length=cfg.max_seq_length,\n","        stride=cfg.doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=cfg.padding,\n","        # return_tensors=\"pt\"\n","    )\n","\n","    features = []\n","    for i in range(len(tokenized_example[\"input_ids\"])):\n","        feature = {}\n","        feature[\"example_id\"] = example[\"id\"]\n","        feature[\"context\"] = example[\"context\"]\n","        feature[\"question\"] = example[\"question\"]\n","        feature[\"input_ids\"] = tokenized_example[\"input_ids\"][i]\n","        feature[\"attention_mask\"] = tokenized_example[\"attention_mask\"][i]\n","        feature[\"offset_mapping\"] = tokenized_example[\"offset_mapping\"][i]\n","        feature[\"sequence_ids\"] = [0 if i is None else i for i in tokenized_example.sequence_ids(i)]\n","        features.append(feature)\n","\n","    return features\n","\n","\n","def postprocess_qa_predictions(tokenizer, examples: pd.DataFrame, features, raw_predictions, n_best_size=20, max_answer_length=30):\n","    '''予測値の後処理関数\n","    '''\n","    all_start_logits, all_end_logits = raw_predictions\n","\n","    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])} # dataframeのidをkeyとしたindexのmapping用dict\n","    features_per_example = defaultdict(list) # dataframeのidに対応するexample_id_to_indexのidをkeyとしたdict。valueはfeaturesに対応するidのリスト\n","    for i, feature in enumerate(features):\n","        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","\n","    predictions = OrderedDict()\n","    # print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n","\n","    for example_index, example in examples.iterrows():\n","        feature_indices = features_per_example[example_index] # 対応するfeaturesのindexを取り出す\n","\n","        # min_null_score = None\n","        valid_answers = []\n","\n","        context = example[\"context\"]\n","        for feature_index in feature_indices:\n","            start_logits = all_start_logits[feature_index]\n","            end_logits = all_end_logits[feature_index]\n","\n","            sequence_ids = features[feature_index][\"sequence_ids\"]\n","            context_index = 1 # contextのsequence_id(questionは0)\n","            \n","            # contextのみoffset_mappingを保持(questionのoffset_mappingをNoneに)\n","            features[feature_index][\"offset_mapping\"] = [\n","                (o if sequence_ids[k] == context_index else None)\n","                for k, o in enumerate(features[feature_index][\"offset_mapping\"])\n","            ]\n","            offset_mapping = features[feature_index][\"offset_mapping\"]\n","            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n","\n","            # feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n","            # if min_null_score is None or min_null_score < feature_null_score:\n","            #     min_null_score = feature_null_score\n","\n","            # start_indexes = np.argsort(start_logits)[-1: -n_best_size - 1: -1].tolist()\n","            # end_indexes = np.argsort(end_logits)[-1: -n_best_size - 1: -1].tolist()\n","            start_indexes = np.argsort(start_logits)[::-1][:n_best_size].tolist()\n","            end_indexes = np.argsort(end_logits)[::-1][:n_best_size].tolist()\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    if (\n","                        start_index >= len(offset_mapping)\n","                        or end_index >= len(offset_mapping)\n","                        or offset_mapping[start_index] is None\n","                        or offset_mapping[end_index] is None\n","                    ):\n","                        continue\n","                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n","                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n","                        continue\n","\n","                    start_char = offset_mapping[start_index][0]\n","                    end_char = offset_mapping[end_index][1]\n","                    valid_answers.append(\n","                        {\n","                            \"score\": start_logits[start_index] + end_logits[end_index],\n","                            \"text\": context[start_char: end_char]\n","                        }\n","                    )\n","        # 各レコード・チャンク(feature)におけるstart+end出力値のスコアが最も大きいペアを最終的な予測値とする\n","        if len(valid_answers) > 0:\n","            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n","        else:\n","            best_answer = {\"text\": \"\", \"score\": 0.0}\n","\n","        predictions[example[\"id\"]] = best_answer[\"text\"]\n","\n","    return predictions\n","\n","\n","def postprocess_cleaned_predictions(input_df: pd.DataFrame):\n","    bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\n","    bad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n","\n","    tamil_ad = \"கி.பி\"\n","    tamil_bc = \"கி.மு\"\n","    tamil_km = \"கி.மீ\"\n","    hindi_ad = \"ई\"\n","    hindi_bc = \"ई.पू\"\n","\n","\n","    cleaned_preds = []\n","    for pred, context in input_df[[\"PredictionString\", \"context\"]].to_numpy():\n","        if pred == \"\":\n","            cleaned_preds.append(pred)\n","            continue\n","        while any([pred.startswith(y) for y in bad_starts]):\n","            pred = pred[1:]\n","        while any([pred.endswith(y) for y in bad_endings]):\n","            if pred.endswith(\"...\"):\n","                pred = pred[:-3]\n","            else:\n","                pred = pred[:-1]\n","        if pred.endswith(\"...\"):\n","                pred = pred[:-3]\n","\n","        if any([pred.endswith(tamil_ad), pred.endswith(tamil_bc), pred.endswith(tamil_km), pred.endswith(hindi_ad), pred.endswith(hindi_bc)]) and pred+\".\" in context:\n","            pred = pred+\".\"\n","\n","        cleaned_preds.append(pred)\n","        \n","    return cleaned_preds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3nn0RX0BicrZ"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"OHSxITfLa9y8"},"source":["class ChaiiDataset(Dataset):\n","    def __init__(self, features, phase):\n","        super(ChaiiDataset, self).__init__()\n","        self.features = features\n","        self.phase = phase\n","        \n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, index):\n","        feature = self.features[index]\n","\n","        if self.phase == \"train\":\n","            return {\n","                \"input_ids\": torch.tensor(feature[\"input_ids\"], dtype=torch.long),\n","                \"attention_mask\": torch.tensor(feature[\"attention_mask\"], dtype=torch.long),\n","                \"offset_mapping\": torch.tensor(feature[\"offset_mapping\"], dtype=torch.long),\n","                \"start_position\": torch.tensor(feature[\"start_position\"], dtype=torch.long),\n","                \"end_position\": torch.tensor(feature[\"end_position\"], dtype=torch.long),\n","            }\n","        else:\n","            return {\n","                \"input_ids\": torch.tensor(feature[\"input_ids\"], dtype=torch.long),\n","                \"attention_mask\": torch.tensor(feature[\"attention_mask\"], dtype=torch.long),\n","                \"offset_mapping\": torch.tensor(feature[\"offset_mapping\"], dtype=torch.long),\n","                \"sequence_ids\": feature[\"sequence_ids\"],\n","                \"id\": feature[\"example_id\"],\n","                \"context\": feature[\"context\"],\n","                \"question\": feature[\"question\"],\n","            }\n","\n","\n","class ChaiiDataModule(pl.LightningDataModule):\n","    def __init__(self, cfg, tokenizer, input_df: pd.DataFrame, phase: str, fold: int = 0):\n","        super(ChaiiDataModule, self).__init__()\n","        self.cfg = cfg\n","        self.tokenizer = tokenizer\n","        self.input_df = input_df\n","        self.phase = phase\n","        self.fold = fold\n","\n","    def get_train_features(self, cfg, input_df, tokenizer):\n","        features = []\n","        for i, row in tqdm(input_df.iterrows(), total=len(input_df), desc=\"[get features]\"):\n","            features += prepare_train_features(cfg, row, tokenizer)\n","        \n","        return features\n","\n","    def get_test_features(self, cfg, input_df, tokenizer):\n","        features = []\n","        for i, row in tqdm(input_df.iterrows(), total=len(input_df), desc=\"[get features]\"):\n","            features += prepare_test_features(cfg, row, tokenizer)\n","        \n","        return features\n","\n","    def setup(self, stage=None):\n","        assert self.phase in (\"train\", \"test\"), \"Input phase is not exist.\"\n","        if self.phase == \"train\":\n","            self.train_df = self.input_df[self.input_df[\"fold\"] != self.fold].reset_index(drop=True)\n","            self.valid_df = self.input_df[self.input_df[\"fold\"] == self.fold].reset_index(drop=True)\n","\n","            self.train_features = self.get_train_features(self.cfg, self.train_df, self.tokenizer)\n","            self.valid_features = self.get_train_features(self.cfg, self.valid_df, self.tokenizer)\n","\n","            self.train_dataset = ChaiiDataset(self.train_features, self.phase)\n","            self.valid_dataset = ChaiiDataset(self.valid_features, self.phase)\n","            print(f\"Number of train features: {len(self.train_dataset)}, Number of valid features: {len(self.valid_dataset)}\")\n","        elif self.phase == \"test\":\n","            self.test_features = self.get_test_features(self.cfg, self.input_df, self.tokenizer)\n","            self.test_dataset = ChaiiDataset(self.test_features, self.phase)\n","            print(f\"Number of test features: {len(self.test_dataset)}\")\n","        else:\n","            raise NotImplementedError\n","        \n","    def train_dataloader(self):\n","        return DataLoader(self.train_dataset, batch_size=self.cfg.train_batch_size, num_workers=self.cfg.num_workers, pin_memory=True, shuffle=True, drop_last=False)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.valid_dataset, batch_size=self.cfg.valid_batch_size, num_workers=self.cfg.num_workers, pin_memory=True, shuffle=False, drop_last=False)\n","\n","    def predict_dataloader(self):\n","        return DataLoader(self.test_dataset, batch_size=self.cfg.test_batch_size, num_workers=self.cfg.num_workers, pin_memory=True, shuffle=False, drop_last=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HhzSnmitfua7"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"IcStqJUDfees"},"source":["class ChaiiModel(nn.Module):\n","    def __init__(self, cfg):\n","        super(ChaiiModel, self).__init__()\n","        self.cfg = cfg\n","        self.model_config = AutoConfig.from_pretrained(self.cfg.base_model_config)\n","        self.encoder = AutoModel.from_pretrained(self.cfg.base_model_name, config=self.model_config)\n","        self.classifier = nn.Linear(self.model_config.hidden_size, cfg.num_classes)\n","        self._init_header_weights(self.classifier)\n","        # self._init_roberta_weights(self.encoder)\n","\n","    def _init_header_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","\n","    def _init_roberta_weights(self, model):\n","        for layer in model.encoder.layer[-cfg.init_layers:]:\n","            for module in layer.modules():\n","                if isinstance(module, nn.Linear):\n","                    module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n","                    if module.bias is not None:\n","                        module.bias.data.zero_()\n","                elif isinstance(module, nn.Embedding):\n","                    module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n","                    if module.padding_idx is not None:\n","                        module.weight.data[module.padding_idx].zero_()\n","                elif isinstance(module, nn.LayerNorm):\n","                    module.bias.data.zero_()\n","                    module.weight.data.fill_(1.0)\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        output = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n","        x = self.classifier(output[0]) # (batch_size, hidden_size, num_classes)\n","        x0, x1 = x.split(1, dim=-1) # (batch_size, hidden_size, 1)\n","        start_logits, end_logits = x0.squeeze(-1), x1.squeeze(-1) # (batch_size, hidden_size)\n","\n","        return start_logits, end_logits"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lZ15q-gb5DiO"},"source":["## training"]},{"cell_type":"code","metadata":{"id":"8mKGz0xAqy3L"},"source":["def get_optimizer_grouped_parameters(cfg, model):\n","    no_decay = cfg.no_decay\n","    # header layerのweight_decay, lr\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if \"classifier\" in n],\n","            \"weight_decay\": cfg.header_weight_decay,\n","            \"lr\": cfg.header_lr\n","        },\n","    ]\n","\n","    # num_layers = model.base_model.config.num_hidden_layers\n","    layers = [getattr(model, \"base_model\").embeddings] + list(getattr(model, \"base_model\").encoder.layer)\n","    layers.reverse()\n","    lr = cfg.optimizer_params[\"lr\"]\n","    \n","    for layer in layers:\n","        lr *= cfg.lr_decay\n","        optimizer_grouped_parameters += [\n","            # no_decayのリストに含まれないパラメータはweight decayを設定\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": cfg.optimizer_params[\"weight_decay\"],\n","                \"lr\": lr,\n","            },\n","            # no_decayのリストに含まれるパラメータはweight decayを設定しない\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            }\n","        ]\n","    \n","    return optimizer_grouped_parameters\n","\n","\n","def get_criterion(cfg):\n","    loss_name = cfg.loss_name\n","    loss_params = cfg.loss_params\n","    return nn.__getattribute__(loss_name)(**loss_params)\n","\n","\n","def get_optimizer(cfg, model=None, optimizer_grouped_parameters=None):\n","    optimizer_name = cfg.optimizer_name\n","    optimizer_params = cfg.optimizer_params\n","\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": cfg.optimizer_params[\"weight_decay\"],\n","        },\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","\n","    if optimizer_name == \"AdamW\":\n","        return AdamW(\n","            optimizer_grouped_parameters,\n","            **optimizer_params\n","        )\n","    else:\n","        return optim.__getattribute__(optimizer_name)(model.parameters(), **optimizer_params)\n","\n","\n","def get_scheduler(cfg, optimizer, num_warmup_steps=None, num_training_steps=None):\n","    scheduler_name = cfg.scheduler_name\n","    scheduler_params = cfg.scheduler_params\n","\n","    if scheduler_name == \"cosine-warmup\":\n","        return get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","        )\n","    elif scheduler_name == \"linear-warmup\":\n","        return get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","        )\n","    elif scheduler_name not in (\"cosine-warmup\", \"linear-warmup\"):\n","        return optim.lr_scheduler.__getattribute__(scheduler_name)(optimizer, **scheduler_params)\n","    elif scheduler_name is not None:\n","        return\n","\n","\n","class ChaiiLightningModule(pl.LightningModule):\n","    def __init__(self, cfg):\n","        super(ChaiiLightningModule, self).__init__()\n","        self.cfg = cfg\n","        self.model = ChaiiModel(self.cfg)\n","        self.criterion = get_criterion(self.cfg)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output_start, output_end = self.model(input_ids, attention_mask)\n","        return output_start, output_end\n","\n","    def training_step(self, batch, batch_idx):\n","        input_ids, attention_mask, target_start, target_end = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"start_position\"], batch[\"end_position\"]\n","        output_start, output_end = self.forward(input_ids, attention_mask)\n","\n","        loss_start = self.criterion(output_start, target_start)\n","        loss_end = self.criterion(output_end, target_end)\n","        loss = (loss_start + loss_end) / 2\n","\n","        self.log(\"train/loss\", loss.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"train/loss_start_epoch\", loss_start.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"train/loss_end_epoch\", loss_end.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        input_ids, attention_mask, target_start, target_end = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"start_position\"], batch[\"end_position\"]\n","        output_start, output_end = self.forward(input_ids, attention_mask)\n","\n","        loss_start = self.criterion(output_start, target_start)\n","        loss_end = self.criterion(output_end, target_end)\n","        loss = (loss_start + loss_end) / 2\n","\n","        self.log(\"val/loss\", loss.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"val/loss_start_epoch\", loss_start.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"val/loss_end_epoch\", loss_end.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","\n","        outputs = OrderedDict({\n","            \"start_logits\": output_start.detach(),\n","            \"end_logits\": output_end.detach(),\n","        }\n","        )\n","\n","        return outputs\n","\n","    def validation_epoch_end(self, outputs):\n","        pred_start = torch.cat([output[\"start_logits\"] for output in outputs]).cpu().numpy()\n","        pred_end = torch.cat([output[\"end_logits\"] for output in outputs]).cpu().numpy()\n","\n","        preds = postprocess_qa_predictions(\n","            self.trainer.datamodule.tokenizer,\n","            self.trainer.datamodule.valid_df,\n","            copy.deepcopy(self.trainer.datamodule.valid_features[:pred_start.shape[0]]),\n","            (pred_start, pred_end)\n","        )\n","        jaccard_score = np.mean([jaccard(x, y) for x, y in zip(self.trainer.datamodule.valid_df[\"answer_text\"].values, preds.values())], axis=0)\n","\n","        self.log(\"val/jaccard_epoch\", jaccard_score, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n","        input_ids, attention_mask = batch[\"input_ids\"], batch[\"attention_mask\"]\n","        output_start, output_end = self.forward(input_ids, attention_mask)\n","\n","        outputs = OrderedDict({\n","            \"start_logits\": output_start,\n","            \"end_logits\": output_end,\n","        }\n","        )\n","\n","        return outputs\n","\n","    def configure_optimizers(self):\n","        # optimizer_grouped_parameters = get_optimizer_grouped_parameters(self.cfg, self.model)\n","        optimizer = get_optimizer(\n","            self.cfg,\n","            self.model,\n","            # optimizer_grouped_parameters=optimizer_grouped_parameters\n","        )\n","\n","        num_training_steps = math.ceil(len(self.trainer.datamodule.train_dataloader()) / self.trainer.accumulate_grad_batches) * self.trainer.max_epochs\n","        if self.cfg.scheduler_params[\"warmup_ratio\"] > 0:\n","            num_warmup_steps = int(num_training_steps * self.cfg.scheduler_params[\"warmup_ratio\"])\n","        else:\n","            num_warmup_steps = 0\n","        scheduler = get_scheduler(self.cfg, optimizer, num_warmup_steps, num_training_steps)\n","        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n","        print(f\"Total Training Steps: {num_training_steps}, Total Warmup Steps: {num_warmup_steps}\")\n","\n","        return [optimizer], [scheduler]\n","\n","\n","def run_fold(cfg, train_df, fold, tokenizer):\n","    seed_everything(cfg.seed[0])\n","\n","    checkpoint_callback = ModelCheckpoint(\n","        dirpath=cfg.checkpoint_dir,\n","        filename=f\"{cfg.exp_name}_fold_{fold}\",\n","        **cfg.model_checkpoint_params,\n","    )\n","\n","    early_stopping_callback = EarlyStopping(**cfg.early_stopping_params)\n","\n","    wandb_logger = WandbLogger(\n","        name=f\"{cfg.exp_name}_fold_{fold}\",\n","        **cfg.wandb_logger_params,\n","    )\n","\n","    trainer = Trainer(\n","        default_root_dir=cfg.checkpoint_dir,\n","        gpus=cfg.gpus,\n","        max_epochs=cfg.num_epochs,\n","        accumulate_grad_batches=cfg.grad_accumulate,\n","        precision=16 if cfg.fp16 else 32,\n","        callbacks=[\n","            checkpoint_callback,\n","            # early_stopping_callback,\n","        ],\n","        logger=[\n","            wandb_logger,\n","        ],\n","        log_every_n_steps=10,\n","    )\n","\n","    model = ChaiiLightningModule(cfg)\n","    datamodule = ChaiiDataModule(cfg, tokenizer=tokenizer, input_df=train_df, phase=\"train\", fold=fold)\n","    trainer.fit(model, datamodule=datamodule)\n","\n","    wandb.finish()\n","\n","    del trainer, model, datamodule\n","    gc.collect()\n","\n","    return checkpoint_callback.best_model_path, checkpoint_callback.best_model_score.item()\n","\n","\n","def run_training(cfg, train_df):\n","    tokenizer = AutoTokenizer.from_pretrained(cfg.tokenizer_name)\n","\n","    checkpoint_path_list = []\n","    oof_score = 0\n","\n","    for fold_id in range(cfg.split_params[\"n_splits\"]):\n","        checkpoint_path, best_score = run_fold(cfg, train_df, fold_id, tokenizer)\n","        checkpoint_path_list.append(checkpoint_path)\n","        oof_score += best_score / int(cfg.split_params[\"n_splits\"])\n","\n","    print(\"CV jaccard score :\", oof_score)\n","\n","    return checkpoint_path_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":791,"referenced_widgets":["f36976d19af442b2bee21b6871aa5fb2","04109b339741416aaf109d278cac609d","cdea76b715ca44a69dd4639328071883","1d9d02f8f6b141df80f6b991d1cfaf44","9a8306523d184c66a0f4f1a94bc71978","cb3b8dbf495e480999835c85dc0c8fc9","ed4cff752326438f938df11e05a622c5","ca9b1bf5b46b44bf87452d970a00bea6","bd0ca6f2267146cfbe5a5cfb14352bad","5b4e81ab49f041bf9ab7e1697538e843","8fefd820a3724e8a9bddc7b60463c9b0","6b2711adaa0f44279896e625741bd530","be0d10db18c045a0b45f05b5e7074003","c5ff308a37034b79b043c4043c2d9585","3e01e98f070f41a4bdd2dc689d719bdd","d7e95195fede49b2978db52ab415fcbf","8a1c4dddf940479394636af8751dfc33","31e0993a3d89406d947c4028d5b9b5d0","ed035d1fd6624dfc8a068df43454b7ac","16a12448e53d40dfb2a7f2fe27db1883","783e4940578f4fdda5594f1f5be6b177","d4be154f54af4c088d4ab2c577d8351b","2156bccdc8ef4a7a8a9dd42fbd832e8f","bb9f360aa89246598f2162830f704e2d","ca3a9b470eae49ff8507ac199b38958f","65fcf2f7c52b4abc80e34a59b8f7d5d8","0caa940dd6f549e6b3f5b39cf845b6e9","f1005c91aa7a48ee80cfa4e5ac6497b6","db774290672f4f7a91fd18d542a9890d","4081c4bc57e44771bf6bf86516a9408a","f325cd8f7d0444ef92dae7758db8de27","507db6298bb742a3ae4e3995a08902c4","2ac622f3016848798d6bd66216b83ca3","a992b20dd62841118fb18fd5b47dd897","fee7c7a04ec84e73bb738175754b8c14","4237b0ffddad4ec19dd7558811138aa5","d5d8fd8723904436904bfc78a2e272aa","79fba9af8b724c759c8b65f0d5989ead","f74d06efc9ec4effb8e7abc12f04d3a8","1fe8c5fa6e2c4d6d821ffeff99956f40","7461dc1c3b224ca2ac4f4287e8b0df07","4fa26e5191d84d7bbbcdb03a917c8248","4782e5e8179c4451a4082cd57a037992","01ef1617f7994273b5501199cf62af59","f378c4e07757408191b89630f377e644","370a8c8066bd40c5831c8a530ae0a266","af94f05e9eb6414593bb9c5c482bee63","9907b76582fa4b7894772e5c958e66ab","6edb4cacdb38485180366bfacbf6a4e3","a013024124524e9aa717c685e2707822","3c5c99e4d7b94d3ca9212c2e108eebd4","0f30da9241a14d89906fdd8268db71f1","be63aff8b7344ab28c0a780be87eac83","a02f021260754236baa9b2f02fb7e9c1","b46aa3597d83463b8c3e95e106255873"]},"id":"hhGIfEKXBatS","outputId":"2024eb54-1554-4f84-d060-417186ed4232"},"source":["# checkpoint_path_list = run_training(cfg, train_df)\n","tokenizer = AutoTokenizer.from_pretrained(cfg.tokenizer_name)\n","_, _ = run_fold(cfg, train_df, 0, tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Global seed set to 42\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory checkpoint exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f36976d19af442b2bee21b6871aa5fb2","version_minor":0,"version_major":2},"text/plain":["[get features]:   0%|          | 0/7506 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b2711adaa0f44279896e625741bd530","version_minor":0,"version_major":2},"text/plain":["[get features]:   0%|          | 0/223 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"stream","name":"stdout","text":["Number of train features: 19575, Number of valid features: 2751\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["Total Training Steps: 612, Total Warmup Steps: 61\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mazupero\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.12.2<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">exp006_fold_0</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering</a><br/>\n","                Run page: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/3nnnp7eg\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/3nnnp7eg</a><br/>\n","                Run data is saved locally in <code>/content/wandb/run-20210925_142747-3nnnp7eg</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","  | Name      | Type             | Params\n","-----------------------------------------------\n","0 | model     | ChaiiModel       | 559 M \n","1 | criterion | CrossEntropyLoss | 0     \n","-----------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2156bccdc8ef4a7a8a9dd42fbd832e8f","version_minor":0,"version_major":2},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Global seed set to 42\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a992b20dd62841118fb18fd5b47dd897","version_minor":0,"version_major":2},"text/plain":["Training: -1it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f378c4e07757408191b89630f377e644","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"MbsE5t9-jbB3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632583217532,"user_tz":-540,"elapsed":32573,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}},"outputId":"f3b81931-a420-4cf2-d2dd-7c217a992640"},"source":["# ID = \"azupero\"\n","# DATASET_ID = f\"chaii-qa-checkpoint-{cfg.exp_name}\"\n","# UPLOAD_DIR = Path(cfg.checkpoint_dir)\n","\n","# def dataset_create_new():\n","#     dataset_metadata = {}\n","#     dataset_metadata['id'] = f'{ID}/{DATASET_ID}'\n","#     dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","#     dataset_metadata['title'] = DATASET_ID\n","#     with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","#         json.dump(dataset_metadata, f, indent=4)\n","#     api = KaggleApi()\n","#     api.authenticate()\n","#     api.dataset_create_new(folder=UPLOAD_DIR, convert_to_csv=False, dir_mode='tar')\n","\n","# dataset_create_new()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting upload for file exp006_fold_0.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.09G/2.09G [00:29<00:00, 76.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp006_fold_0.ckpt (2GB)\n","Starting upload for file .ipynb_checkpoints.tar\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10.0k/10.0k [00:00<00:00, 55.4kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: .ipynb_checkpoints.tar (10KB)\n"]}]},{"cell_type":"markdown","metadata":{"id":"USegY8kE1TMN"},"source":["## inference"]},{"cell_type":"code","metadata":{"id":"a2iSNKOK7-32"},"source":["def run_predict(cfg, input_df):\n","    tokenizer = AutoTokenizer.from_pretrained(cfg.tokenizer_name)\n","    checkpoint_path = list(Path(cfg.checkpoint_dir).iterdir())\n","    start_logits = []\n","    end_logits = []\n","\n","    for path in checkpoint_path:\n","        seed_everything(cfg.seed[0])\n","\n","        model = ChaiiLightningModule.load_from_checkpoint(checkpoint_path=path, cfg=cfg)\n","        datamodule = ChaiiDataModule(cfg, tokenizer=tokenizer, input_df=input_df, phase=\"test\")\n","        trainer = Trainer(gpus=cfg.gpus)\n","        preds = trainer.predict(model, datamodule=datamodule, return_predictions=True)\n","        start_logits.append(torch.cat([pred[\"start_logits\"] for pred in preds]).cpu().numpy())\n","        end_logits.append(torch.cat([pred[\"end_logits\"] for pred in preds]).cpu().numpy())\n","\n","    start_logits, end_logits = np.mean(start_logits, axis=0), np.mean(end_logits, axis=0)\n","    predictions = postprocess_qa_predictions(input_df, datamodule.test_features, (start_logits, end_logits))\n","\n","    input_df[\"PredictionString\"] = input_df[\"id\"].map(predictions)\n","    input_df[\"PredictionString\"] = postprocess_cleaned_predictions(input_df)\n","    input_df[[\"id\", \"PredictionString\"]].to_csv(\"submission.csv\", index=False)"],"execution_count":null,"outputs":[]}]}