{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"h7PiERPR3JwG"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1uHWvJoM1MB"},"outputs":[],"source":["!mkdir ~/.kaggle\n","!cp /content/drive/MyDrive/Colab/kaggle/kaggle.json ~/.kaggle\n","\n","!pip install --upgrade --force-reinstall --no-deps kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Urj-Rfgn3UBV"},"outputs":[],"source":["!cp -r /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/input /content\n","!mkdir /content/checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6dGMLhJ3f0r"},"outputs":[],"source":["!pip install -U pytorch-lightning transformers wandb sentencepiece torchsummaryX"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4095,"status":"ok","timestamp":1636044697559,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"},"user_tz":-540},"id":"EGc_0a3l32o8"},"outputs":[],"source":["import os\n","import random\n","from dataclasses import dataclass\n","import copy\n","import gc\n","\n","import numpy as np\n","import pandas as pd\n","import math\n","import sklearn.model_selection as sms\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n","import torch.optim as optim\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning import Trainer, seed_everything\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","from pytorch_lightning.loggers import WandbLogger\n","import wandb\n","\n","from transformers import AutoTokenizer, AutoModel, AutoConfig, AdamW, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","from torchsummaryX import summary\n","\n","from collections import defaultdict, OrderedDict\n","from tqdm.notebook import tqdm\n","\n","import json\n","from pathlib import Path\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"markdown","metadata":{"id":"2pbFM7_B4Emp"},"source":["## config"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1636044697560,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"},"user_tz":-540},"id":"HemZ1ng-4FIW"},"outputs":[],"source":["@dataclass\n","class Config:\n","    #########################\n","    # Globals #\n","    #########################\n","    exp_name = \"exp009\"\n","    debug = False\n","    gpus = 1\n","    num_workers = 8\n","    num_epochs = 5\n","    grad_accumulate = 4\n","    fp16 = False\n","    seed = [2021, 2434, 98, 24, 1991]\n","    #########################\n","    # Data #\n","    #########################\n","    train_csv = \"input/train.csv\"\n","    test_csv = \"input/test.csv\"\n","    sample_submission_csv = \"input/sample_submission.csv\"\n","    mlqa_hindi_csv = \"input/external_data/mlqa_hindi.csv\"\n","    xquad_hindi_csv = \"input/external_data/xquad_hindi.csv\"\n","    xquad_tamil_csv = \"input/external_data/squad_translated_tamil.csv\"\n","    checkpoint_dir = \"drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint\"\n","    #########################\n","    # Split #\n","    #########################\n","    split_name = \"StratifiedKFold\"\n","    split_params = {\n","        \"n_splits\": 5,\n","        \"random_state\": 2021,\n","        \"shuffle\": True,\n","        }\n","    #########################\n","    # Tokenizer #\n","    #########################\n","    tokenizer_name = \"deepset/xlm-roberta-large-squad2\"\n","    max_seq_length = 400\n","    doc_stride = 135\n","    truncation = \"only_second\"\n","    padding = \"max_length\"\n","    #########################\n","    # Dataset #\n","    #########################\n","    #########################\n","    # DataLoader #\n","    #########################\n","    train_batch_size = 3\n","    valid_batch_size = 8\n","    test_batch_size = 64\n","    #########################\n","    # Model #\n","    #########################\n","    base_model_name = \"deepset/xlm-roberta-large-squad2\"\n","    base_model_config = \"deepset/xlm-roberta-large-squad2\"\n","    num_classes = 2\n","    init_layers = 1\n","    #########################\n","    # Criterion #\n","    #########################\n","    loss_name = \"CrossEntropyLoss\"\n","    loss_params = {\n","        \"ignore_index\": -1,\n","    }\n","    #########################\n","    # Optimizer #\n","    #########################\n","    optimizer_name = \"AdamW\"\n","    optimizer_params = {\n","        \"lr\": 1e-5,\n","        \"weight_decay\": 1e-2,\n","        \"eps\": 1e-8,\n","        \"correct_bias\": True\n","    }\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    header_weight_decay = 1e-2\n","    header_lr = 1e-3\n","    lr_decay = 0.98\n","    ######################\n","    # Scheduler #\n","    ######################\n","    scheduler_name = \"linear-warmup\"\n","    scheduler_params = {\n","        \"warmup_ratio\": 0.1,\n","    }\n","    ######################\n","    # Callbacks #\n","    ######################\n","    model_checkpoint_params = {\n","        \"monitor\": \"val/jaccard_epoch\",\n","        \"save_top_k\": 1,\n","        \"save_weights_only\": True,\n","    }\n","    early_stopping_params = {\n","        \"monitor\": \"val/jaccard_epoch\",\n","        \"min_delta\": 0.0,\n","        \"patience\": 5,\n","        \"verbose\": False,\n","        \"mode\": \"max\",\n","    }\n","    wandb_logger_params = {\n","        \"project\": \"kaggle-chaii-hindi-and-tamil-question-answering\"\n","    }\n","\n","\n","cfg = Config()"]},{"cell_type":"markdown","metadata":{"id":"N75ldQ_N4_lF"},"source":["## utils"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1636044697561,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"},"user_tz":-540},"id":"N1OPGpKZ48h-"},"outputs":[],"source":["def load_dataset(cfg):\n","    train_df = pd.read_csv(cfg.train_csv, nrows= 100 if cfg.debug else None)\n","    test_df = pd.read_csv(cfg.test_csv)\n","    external_mlqa_df = pd.read_csv(cfg.mlqa_hindi_csv)\n","    external_xquad_df = pd.read_csv(cfg.xquad_hindi_csv)\n","    # external_tamil_xquad_df = pd.read_csv(cfg.xquad_tamil_csv)\n","    external_train_df = pd.concat([\n","                                   external_mlqa_df, \n","                                   external_xquad_df, \n","                                #    external_tamil_xquad_df\n","                                   ], axis=0).reset_index(drop=True)\n","    sample_submission_df = pd.read_csv(cfg.sample_submission_csv)\n","\n","    return train_df, test_df, external_train_df, sample_submission_df\n","\n","\n","def get_split(cfg):\n","    split_name = cfg.split_name\n","    split_params = cfg.split_params\n","\n","    return sms.__getattribute__(split_name)(**split_params)\n","\n","\n","def get_fold(cfg, train_df: pd.DataFrame, y_train: pd.DataFrame):\n","    splitter = get_split(cfg)\n","    train_df[\"fold\"] = -1\n","    for fold_id, (train_idx, valid_idx) in enumerate(splitter.split(train_df, y_train)):\n","        train_df.loc[valid_idx, \"fold\"] = int(fold_id)\n","\n","    return train_df\n","\n","\n","def convert_answers(row):\n","    return {\"answer_start\": [row[0]], \"text\": [row[1]]}\n","\n","\n","def jaccard(str1, str2):\n","    a = set(str1.lower().split())\n","    b = set(str2.lower().split())\n","    c = a.intersection(b)\n","\n","    return float(len(c)) / (len(a) + len(b) - len(c))"]},{"cell_type":"markdown","metadata":{"id":"RBsFiLLN5EVr"},"source":["## load data"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":568},"executionInfo":{"elapsed":532,"status":"ok","timestamp":1636044698088,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"},"user_tz":-540},"id":"AwmhgEfk4vR8","outputId":"9d8a8701-7053-4197-9227-12949e585293"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003equestion\u003c/th\u003e\n","      \u003cth\u003eanswer_text\u003c/th\u003e\n","      \u003cth\u003eanswer_start\u003c/th\u003e\n","      \u003cth\u003elanguage\u003c/th\u003e\n","      \u003cth\u003efold\u003c/th\u003e\n","      \u003cth\u003eanswers\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e903deec17\u003c/td\u003e\n","      \u003ctd\u003eஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...\u003c/td\u003e\n","      \u003ctd\u003eமனித உடலில் எத்தனை எலும்புகள் உள்ளன?\u003c/td\u003e\n","      \u003ctd\u003e206\u003c/td\u003e\n","      \u003ctd\u003e53\u003c/td\u003e\n","      \u003ctd\u003etamil\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e{'answer_start': [53], 'text': ['206']}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003ed9841668c\u003c/td\u003e\n","      \u003ctd\u003eகாளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...\u003c/td\u003e\n","      \u003ctd\u003eகாளிதாசன் எங்கு பிறந்தார்?\u003c/td\u003e\n","      \u003ctd\u003eகாசுமீரில்\u003c/td\u003e\n","      \u003ctd\u003e2358\u003c/td\u003e\n","      \u003ctd\u003etamil\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e{'answer_start': [2358], 'text': ['காசுமீரில்']}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e29d154b56\u003c/td\u003e\n","      \u003ctd\u003eசர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...\u003c/td\u003e\n","      \u003ctd\u003eபென்சிலின் கண்டுபிடித்தவர் யார்?\u003c/td\u003e\n","      \u003ctd\u003eசர் அலெக்ஸாண்டர் ஃபிளெமிங்\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003etamil\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e{'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e41660850a\u003c/td\u003e\n","      \u003ctd\u003eகுழந்தையின் அழுகையை நிறுத்தவும், தூங்க வைக்கவு...\u003c/td\u003e\n","      \u003ctd\u003eதமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...\u003c/td\u003e\n","      \u003ctd\u003eதாலாட்டு\u003c/td\u003e\n","      \u003ctd\u003e68\u003c/td\u003e\n","      \u003ctd\u003etamil\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e{'answer_start': [68], 'text': ['தாலாட்டு']}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003eb29c82c22\u003c/td\u003e\n","      \u003ctd\u003eசூரியக் குடும்பம் சூரியக் குடும்பம் (Solar Sys...\u003c/td\u003e\n","      \u003ctd\u003eபூமியின் அருகில் உள்ள விண்மீன் எது?\u003c/td\u003e\n","      \u003ctd\u003eசூரியனும்\u003c/td\u003e\n","      \u003ctd\u003e585\u003c/td\u003e\n","      \u003ctd\u003etamil\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e{'answer_start': [585], 'text': ['சூரியனும்']}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e7724\u003c/th\u003e\n","      \u003ctd\u003e6611\u003c/td\u003e\n","      \u003ctd\u003eविद्युत आवेश के परिवर्तन की समय दर के रूप में ...\u003c/td\u003e\n","      \u003ctd\u003eइलेक्ट्रोस्टैटिक और चुंबकीय बल के योग के रूप क...\u003c/td\u003e\n","      \u003ctd\u003eइलेक्ट्रोस्टैटिक बल\u003c/td\u003e\n","      \u003ctd\u003e328\u003c/td\u003e\n","      \u003ctd\u003ehindi\u003c/td\u003e\n","      \u003ctd\u003e-1\u003c/td\u003e\n","      \u003ctd\u003e{'answer_start': [328], 'text': ['इलेक्ट्रोस्ट...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e7725\u003c/th\u003e\n","      \u003ctd\u003e6612\u003c/td\u003e\n","      \u003ctd\u003eउस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...\u003c/td\u003e\n","      \u003ctd\u003eसंरचनाओं में तनाव का कारण क्या बनता है?\u003c/td\u003e\n","      \u003ctd\u003eतनाव टेंसर\u003c/td\u003e\n","      \u003ctd\u003e343\u003c/td\u003e\n","      \u003ctd\u003ehindi\u003c/td\u003e\n","      \u003ctd\u003e-1\u003c/td\u003e\n","      \u003ctd\u003e{'answer_start': [343], 'text': ['तनाव टेंसर']}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e7726\u003c/th\u003e\n","      \u003ctd\u003e6613\u003c/td\u003e\n","      \u003ctd\u003eउस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...\u003c/td\u003e\n","      \u003ctd\u003eकिसी वस्तु के आयतन में क्रॉस सेक्शन क्षेत्र की...\u003c/td\u003e\n","      \u003ctd\u003eदबाव की शर्तें\u003c/td\u003e\n","      \u003ctd\u003e118\u003c/td\u003e\n","      \u003ctd\u003ehindi\u003c/td\u003e\n","      \u003ctd\u003e-1\u003c/td\u003e\n","      \u003ctd\u003e{'answer_start': [118], 'text': ['दबाव की शर्त...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e7727\u003c/th\u003e\n","      \u003ctd\u003e6614\u003c/td\u003e\n","      \u003ctd\u003eउस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...\u003c/td\u003e\n","      \u003ctd\u003eसामान्य ताकतों से क्या जुड़ा है?\u003c/td\u003e\n","      \u003ctd\u003eदबाव की शर्तें\u003c/td\u003e\n","      \u003ctd\u003e118\u003c/td\u003e\n","      \u003ctd\u003ehindi\u003c/td\u003e\n","      \u003ctd\u003e-1\u003c/td\u003e\n","      \u003ctd\u003e{'answer_start': [118], 'text': ['दबाव की शर्त...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e7728\u003c/th\u003e\n","      \u003ctd\u003e6615\u003c/td\u003e\n","      \u003ctd\u003eउस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...\u003c/td\u003e\n","      \u003ctd\u003eआयतन में क्षेत्र की गणना करते समय दबाव की क्या...\u003c/td\u003e\n","      \u003ctd\u003eनियम-निष्ठता\u003c/td\u003e\n","      \u003ctd\u003e101\u003c/td\u003e\n","      \u003ctd\u003ehindi\u003c/td\u003e\n","      \u003ctd\u003e-1\u003c/td\u003e\n","      \u003ctd\u003e{'answer_start': [101], 'text': ['नियम-निष्ठता']}\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e7729 rows × 8 columns\u003c/p\u003e\n","\u003c/div\u003e"],"text/plain":["             id  ...                                            answers\n","0     903deec17  ...            {'answer_start': [53], 'text': ['206']}\n","1     d9841668c  ...   {'answer_start': [2358], 'text': ['காசுமீரில்']}\n","2     29d154b56  ...  {'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...\n","3     41660850a  ...       {'answer_start': [68], 'text': ['தாலாட்டு']}\n","4     b29c82c22  ...     {'answer_start': [585], 'text': ['சூரியனும்']}\n","...         ...  ...                                                ...\n","7724       6611  ...  {'answer_start': [328], 'text': ['इलेक्ट्रोस्ट...\n","7725       6612  ...    {'answer_start': [343], 'text': ['तनाव टेंसर']}\n","7726       6613  ...  {'answer_start': [118], 'text': ['दबाव की शर्त...\n","7727       6614  ...  {'answer_start': [118], 'text': ['दबाव की शर्त...\n","7728       6615  ...  {'answer_start': [101], 'text': ['नियम-निष्ठता']}\n","\n","[7729 rows x 8 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_df, test_df, external_train_df, sample_submission_df = load_dataset(cfg)\n","\n","train_df = get_fold(cfg, train_df, train_df[\"language\"])\n","\n","external_train_df[\"fold\"] = -1\n","external_train_df[\"id\"] = list(np.arange(1, len(external_train_df) + 1))\n","train_df = pd.concat([train_df, external_train_df], axis=0).reset_index(drop=True)\n","\n","# 改行文字の削除\n","train_df[\"context\"] = train_df[\"context\"].apply(lambda x: \" \".join(x.split()))\n","train_df[\"question\"] = train_df[\"question\"].apply(lambda x: \" \".join(x.split()))\n","\n","train_df[\"answers\"] = train_df[[\"answer_start\", \"answer_text\"]].apply(convert_answers, axis=1)\n","train_df"]},{"cell_type":"markdown","metadata":{"id":"WcJnS8s25JLn"},"source":["## preprocess"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":934,"status":"ok","timestamp":1636044699019,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"},"user_tz":-540},"id":"nxgeHj2A82w0"},"outputs":[],"source":["def prepare_train_features(cfg, example, tokenizer):\n","    example[\"question\"] = example[\"question\"].lstrip()\n","\n","    tokenized_example = tokenizer(\n","        example[\"question\"],\n","        example[\"context\"],\n","        truncation=cfg.truncation,\n","        max_length=cfg.max_seq_length,\n","        stride=cfg.doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=cfg.padding,\n","        # return_tensors=\"pt\"\n","    )\n","\n","    sample_mapping = tokenized_example.pop(\"overflow_to_sample_mapping\")\n","    offset_mapping = tokenized_example.pop(\"offset_mapping\")\n","\n","    features = []\n","    for i, offsets in enumerate(offset_mapping):\n","        feature = {}\n","\n","        input_ids  = tokenized_example[\"input_ids\"][i]\n","        attention_mask = tokenized_example[\"attention_mask\"][i]\n","\n","        feature[\"input_ids\"] = input_ids\n","        feature[\"attention_mask\"] = attention_mask\n","        feature[\"offset_mapping\"] = offsets\n","        feature[\"example_id\"] = example[\"id\"]\n","        feature[\"sequence_ids\"] = [0 if i is None else i for i in tokenized_example.sequence_ids(i)]\n","\n","        cls_index = input_ids.index(tokenizer.cls_token_id) # cls_token_id = 0, pad_token_id = 1\n","        sequence_ids = tokenized_example.sequence_ids(i)\n","\n","        # sample_indx = sample_mapping[i]\n","        answers = example[\"answers\"]\n","\n","        if len(answers[\"answer_start\"]) == 0: # sampleにanswerがなければ開始・終了位置をCLS(=[CLS], \u003cs\u003e)にする\n","            feature[\"start_position\"] = cls_index\n","            feature[\"end_position\"] = cls_index\n","        else:\n","            start_char = answers[\"answer_start\"][0] # answer部分の文字レベルの開始位置\n","            end_char = start_char + len(answers[\"text\"][0]) # answer部分の文字レベルの終了位置\n","\n","            token_start_index = 0 # sequenceにおけるcontext部分のトークンレベルの開始位置\n","            while sequence_ids[token_start_index] != 1: # sequence_idsが1(=context部分)になるまで足す(\u003cs\u003e,\u003c/s\u003e, querstion部分を飛ばすイメージ)\n","                token_start_index += 1\n","\n","            token_end_index = len(input_ids) - 1 # sequenceにおけるcontext部分のトークンレベルの終了位置\n","            while sequence_ids[token_end_index] != 1: # sequence_idsが1(=context部分)になるまで引く(paddingはNoneなので\u003cpad\u003e部分を引くイメージ)\n","                token_end_index -= 1\n","\n","            # token_start_index, token_end_indexがanswer部分の範囲外にあればpositionを0(=[CLS], \u003cs\u003e)とする(truncationされてる場合はこっち)\n","            if not (offsets[token_start_index][0] \u003c= start_char and offsets[token_end_index][1] \u003e= end_char):\n","                feature[\"start_position\"] = cls_index\n","                feature[\"end_position\"] = cls_index\n","            # star_char, end_charを含むtokenまでtoken_start_index, token_end_indexを調整\n","            else:\n","                while token_start_index \u003c len(offsets) and offsets[token_start_index][0] \u003c= start_char:\n","                    token_start_index += 1\n","                feature[\"start_position\"] = token_start_index - 1 # 行き過ぎた1token分戻す\n","\n","                while offsets[token_end_index][1] \u003e= end_char:\n","                    token_end_index -= 1\n","                feature[\"end_position\"] = token_end_index + 1 # 行き過ぎた1token分戻す\n","\n","        features.append(feature)\n","\n","    return features\n","\n","\n","def prepare_test_features(cfg, example, tokenizer):\n","    example[\"question\"] = example[\"question\"].lstrip()\n","\n","    tokenized_example = tokenizer(\n","        example[\"question\"],\n","        example[\"context\"],\n","        truncation=cfg.truncation,\n","        max_length=cfg.max_seq_length,\n","        stride=cfg.doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=cfg.padding,\n","        # return_tensors=\"pt\"\n","    )\n","\n","    features = []\n","    for i in range(len(tokenized_example[\"input_ids\"])):\n","        feature = {}\n","        feature[\"example_id\"] = example[\"id\"]\n","        feature[\"context\"] = example[\"context\"]\n","        feature[\"question\"] = example[\"question\"]\n","        feature[\"input_ids\"] = tokenized_example[\"input_ids\"][i]\n","        feature[\"attention_mask\"] = tokenized_example[\"attention_mask\"][i]\n","        feature[\"offset_mapping\"] = tokenized_example[\"offset_mapping\"][i]\n","        feature[\"sequence_ids\"] = [0 if i is None else i for i in tokenized_example.sequence_ids(i)]\n","        features.append(feature)\n","\n","    return features\n","\n","\n","def postprocess_qa_predictions(tokenizer, examples: pd.DataFrame, features, raw_predictions, n_best_size=20, max_answer_length=30):\n","    '''予測値の後処理関数\n","    '''\n","    all_start_logits, all_end_logits = raw_predictions\n","\n","    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])} # dataframeのidをkeyとしたindexのmapping用dict\n","    features_per_example = defaultdict(list) # dataframeのidに対応するexample_id_to_indexのidをkeyとしたdict。valueはfeaturesに対応するidのリスト\n","    for i, feature in enumerate(features):\n","        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","\n","    predictions = OrderedDict()\n","    # print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n","\n","    for example_index, example in examples.iterrows():\n","        feature_indices = features_per_example[example_index] # 対応するfeaturesのindexを取り出す\n","\n","        # min_null_score = None\n","        valid_answers = []\n","\n","        context = example[\"context\"]\n","        for feature_index in feature_indices:\n","            start_logits = all_start_logits[feature_index]\n","            end_logits = all_end_logits[feature_index]\n","\n","            sequence_ids = features[feature_index][\"sequence_ids\"]\n","            context_index = 1 # contextのsequence_id(questionは0)\n","            \n","            # contextのみoffset_mappingを保持(questionのoffset_mappingをNoneに)\n","            features[feature_index][\"offset_mapping\"] = [\n","                (o if sequence_ids[k] == context_index else None)\n","                for k, o in enumerate(features[feature_index][\"offset_mapping\"])\n","            ]\n","            offset_mapping = features[feature_index][\"offset_mapping\"]\n","            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n","\n","            # feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n","            # if min_null_score is None or min_null_score \u003c feature_null_score:\n","            #     min_null_score = feature_null_score\n","\n","            # start_indexes = np.argsort(start_logits)[-1: -n_best_size - 1: -1].tolist()\n","            # end_indexes = np.argsort(end_logits)[-1: -n_best_size - 1: -1].tolist()\n","            start_indexes = np.argsort(start_logits)[::-1][:n_best_size].tolist()\n","            end_indexes = np.argsort(end_logits)[::-1][:n_best_size].tolist()\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    if (\n","                        start_index \u003e= len(offset_mapping)\n","                        or end_index \u003e= len(offset_mapping)\n","                        or offset_mapping[start_index] is None\n","                        or offset_mapping[end_index] is None\n","                    ):\n","                        continue\n","                    # Don't consider answers with a length that is either \u003c 0 or \u003e max_answer_length.\n","                    if end_index \u003c start_index or end_index - start_index + 1 \u003e max_answer_length:\n","                        continue\n","\n","                    start_char = offset_mapping[start_index][0]\n","                    end_char = offset_mapping[end_index][1]\n","                    valid_answers.append(\n","                        {\n","                            \"score\": start_logits[start_index] + end_logits[end_index],\n","                            \"text\": context[start_char: end_char]\n","                        }\n","                    )\n","        # 各レコード・チャンク(feature)におけるstart+end出力値のスコアが最も大きいペアを最終的な予測値とする\n","        if len(valid_answers) \u003e 0:\n","            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n","        else:\n","            best_answer = {\"text\": \"\", \"score\": 0.0}\n","\n","        predictions[example[\"id\"]] = best_answer[\"text\"]\n","\n","    return predictions\n","\n","\n","def postprocess_cleaned_predictions(input_df: pd.DataFrame):\n","    bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\n","    bad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n","\n","    tamil_ad = \"கி.பி\"\n","    tamil_bc = \"கி.மு\"\n","    tamil_km = \"கி.மீ\"\n","    hindi_ad = \"ई\"\n","    hindi_bc = \"ई.पू\"\n","\n","\n","    cleaned_preds = []\n","    for pred, context in input_df[[\"PredictionString\", \"context\"]].to_numpy():\n","        if pred == \"\":\n","            cleaned_preds.append(pred)\n","            continue\n","        while any([pred.startswith(y) for y in bad_starts]):\n","            pred = pred[1:]\n","        while any([pred.endswith(y) for y in bad_endings]):\n","            if pred.endswith(\"...\"):\n","                pred = pred[:-3]\n","            else:\n","                pred = pred[:-1]\n","        if pred.endswith(\"...\"):\n","                pred = pred[:-3]\n","\n","        if any([pred.endswith(tamil_ad), pred.endswith(tamil_bc), pred.endswith(tamil_km), pred.endswith(hindi_ad), pred.endswith(hindi_bc)]) and pred+\".\" in context:\n","            pred = pred+\".\"\n","\n","        cleaned_preds.append(pred)\n","        \n","    return cleaned_preds"]},{"cell_type":"markdown","metadata":{"id":"3nn0RX0BicrZ"},"source":["## Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1636044699019,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"},"user_tz":-540},"id":"OHSxITfLa9y8"},"outputs":[],"source":["class ChaiiDataset(Dataset):\n","    def __init__(self, features, phase):\n","        super(ChaiiDataset, self).__init__()\n","        self.features = features\n","        self.phase = phase\n","        \n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, index):\n","        feature = self.features[index]\n","\n","        if self.phase == \"train\":\n","            return {\n","                \"input_ids\": torch.tensor(feature[\"input_ids\"], dtype=torch.long),\n","                \"attention_mask\": torch.tensor(feature[\"attention_mask\"], dtype=torch.long),\n","                \"offset_mapping\": torch.tensor(feature[\"offset_mapping\"], dtype=torch.long),\n","                \"start_position\": torch.tensor(feature[\"start_position\"], dtype=torch.long),\n","                \"end_position\": torch.tensor(feature[\"end_position\"], dtype=torch.long),\n","            }\n","        else:\n","            return {\n","                \"input_ids\": torch.tensor(feature[\"input_ids\"], dtype=torch.long),\n","                \"attention_mask\": torch.tensor(feature[\"attention_mask\"], dtype=torch.long),\n","                \"offset_mapping\": torch.tensor(feature[\"offset_mapping\"], dtype=torch.long),\n","                \"sequence_ids\": feature[\"sequence_ids\"],\n","                \"id\": feature[\"example_id\"],\n","                \"context\": feature[\"context\"],\n","                \"question\": feature[\"question\"],\n","            }\n","\n","\n","class ChaiiDataModule(pl.LightningDataModule):\n","    def __init__(self, cfg, tokenizer, input_df: pd.DataFrame, phase: str, fold: int = 0):\n","        super(ChaiiDataModule, self).__init__()\n","        self.cfg = cfg\n","        self.tokenizer = tokenizer\n","        self.input_df = input_df\n","        self.phase = phase\n","        self.fold = fold\n","\n","    def get_train_features(self, cfg, input_df, tokenizer):\n","        features = []\n","        for i, row in tqdm(input_df.iterrows(), total=len(input_df), desc=\"[get features]\"):\n","            features += prepare_train_features(cfg, row, tokenizer)\n","        \n","        return features\n","\n","    def get_test_features(self, cfg, input_df, tokenizer):\n","        features = []\n","        for i, row in tqdm(input_df.iterrows(), total=len(input_df), desc=\"[get features]\"):\n","            features += prepare_test_features(cfg, row, tokenizer)\n","        \n","        return features\n","\n","    def setup(self, stage=None):\n","        assert self.phase in (\"train\", \"test\"), \"Input phase is not exist.\"\n","        if self.phase == \"train\":\n","            self.train_df = self.input_df[self.input_df[\"fold\"] != self.fold].reset_index(drop=True)\n","            self.valid_df = self.input_df[self.input_df[\"fold\"] == self.fold].reset_index(drop=True)\n","\n","            self.train_features = self.get_train_features(self.cfg, self.train_df, self.tokenizer)\n","            self.valid_features = self.get_train_features(self.cfg, self.valid_df, self.tokenizer)\n","\n","            self.train_dataset = ChaiiDataset(self.train_features, self.phase)\n","            self.valid_dataset = ChaiiDataset(self.valid_features, self.phase)\n","            print(f\"Number of train features: {len(self.train_dataset)}, Number of valid features: {len(self.valid_dataset)}\")\n","        elif self.phase == \"test\":\n","            self.test_features = self.get_test_features(self.cfg, self.input_df, self.tokenizer)\n","            self.test_dataset = ChaiiDataset(self.test_features, self.phase)\n","            print(f\"Number of test features: {len(self.test_dataset)}\")\n","        else:\n","            raise NotImplementedError\n","        \n","    def train_dataloader(self):\n","        return DataLoader(self.train_dataset, batch_size=self.cfg.train_batch_size, num_workers=self.cfg.num_workers, pin_memory=True, shuffle=True, drop_last=False)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.valid_dataset, batch_size=self.cfg.valid_batch_size, num_workers=self.cfg.num_workers, pin_memory=True, shuffle=False, drop_last=False)\n","\n","    def predict_dataloader(self):\n","        return DataLoader(self.test_dataset, batch_size=self.cfg.test_batch_size, num_workers=self.cfg.num_workers, pin_memory=True, shuffle=False, drop_last=False)"]},{"cell_type":"markdown","metadata":{"id":"HhzSnmitfua7"},"source":["## Model"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1636044699020,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"},"user_tz":-540},"id":"IcStqJUDfees"},"outputs":[],"source":["class ChaiiModel(nn.Module):\n","    def __init__(self, cfg):\n","        super(ChaiiModel, self).__init__()\n","        self.cfg = cfg\n","        self.model_config = AutoConfig.from_pretrained(self.cfg.base_model_config)\n","        self.encoder = AutoModel.from_pretrained(self.cfg.base_model_name, config=self.model_config)\n","        self.start_head = nn.Conv1d(in_channels=1024, out_channels=1, kernel_size=1)\n","        self.end_head = nn.Conv1d(in_channels=1024, out_channels=1, kernel_size=1)\n","        # self._init_header_weights(self.classifier)\n","        # self._init_roberta_weights(self.encoder)\n","\n","    def _init_header_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","\n","    def _init_roberta_weights(self, model):\n","        for layer in model.encoder.layer[-cfg.init_layers:]:\n","            for module in layer.modules():\n","                if isinstance(module, nn.Linear):\n","                    module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n","                    if module.bias is not None:\n","                        module.bias.data.zero_()\n","                elif isinstance(module, nn.Embedding):\n","                    module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n","                    if module.padding_idx is not None:\n","                        module.weight.data[module.padding_idx].zero_()\n","                elif isinstance(module, nn.LayerNorm):\n","                    module.bias.data.zero_()\n","                    module.weight.data.fill_(1.0)\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        output = self.encoder(input_ids=input_ids, attention_mask=attention_mask) # (batch_size, max_seq, hidden_size)\n","        x = output[0].transpose(1, 2) # (batch_size, hidden_size, max_seq)\n","        start_logits = self.start_head(x).transpose(1, 2).squeeze(-1) # (batch_size, max_seq)\n","        end_logits = self.end_head(x).transpose(1, 2).squeeze(-1) # (batch_size, max_seq)\n","\n","        return start_logits, end_logits\n","\n","\n","# model = ChaiiModel(cfg)\n","# summary(model, torch.zeros(1, 400, dtype=torch.long))"]},{"cell_type":"markdown","metadata":{"id":"lZ15q-gb5DiO"},"source":["## training"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":911,"status":"ok","timestamp":1636044699928,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"},"user_tz":-540},"id":"8mKGz0xAqy3L"},"outputs":[],"source":["def get_optimizer_grouped_parameters(cfg, model):\n","    no_decay = cfg.no_decay\n","    # header layerのweight_decay, lr\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if \"classifier\" in n],\n","            \"weight_decay\": cfg.header_weight_decay,\n","            \"lr\": cfg.header_lr\n","        },\n","    ]\n","\n","    # num_layers = model.base_model.config.num_hidden_layers\n","    layers = [getattr(model, \"base_model\").embeddings] + list(getattr(model, \"base_model\").encoder.layer)\n","    layers.reverse()\n","    lr = cfg.optimizer_params[\"lr\"]\n","    \n","    for layer in layers:\n","        lr *= cfg.lr_decay\n","        optimizer_grouped_parameters += [\n","            # no_decayのリストに含まれないパラメータはweight decayを設定\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": cfg.optimizer_params[\"weight_decay\"],\n","                \"lr\": lr,\n","            },\n","            # no_decayのリストに含まれるパラメータはweight decayを設定しない\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            }\n","        ]\n","    \n","    return optimizer_grouped_parameters\n","\n","\n","def get_criterion(cfg):\n","    loss_name = cfg.loss_name\n","    loss_params = cfg.loss_params\n","    return nn.__getattribute__(loss_name)(**loss_params)\n","\n","\n","def get_optimizer(cfg, model=None, optimizer_grouped_parameters=None):\n","    optimizer_name = cfg.optimizer_name\n","    optimizer_params = cfg.optimizer_params\n","\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": cfg.optimizer_params[\"weight_decay\"],\n","        },\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","\n","    if optimizer_name == \"AdamW\":\n","        return AdamW(\n","            optimizer_grouped_parameters,\n","            **optimizer_params\n","        )\n","    else:\n","        return optim.__getattribute__(optimizer_name)(model.parameters(), **optimizer_params)\n","\n","\n","def get_scheduler(cfg, optimizer, num_warmup_steps=None, num_training_steps=None):\n","    scheduler_name = cfg.scheduler_name\n","    scheduler_params = cfg.scheduler_params\n","\n","    if scheduler_name == \"cosine-warmup\":\n","        return get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","        )\n","    elif scheduler_name == \"linear-warmup\":\n","        return get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","        )\n","    elif scheduler_name not in (\"cosine-warmup\", \"linear-warmup\"):\n","        return optim.lr_scheduler.__getattribute__(scheduler_name)(optimizer, **scheduler_params)\n","    elif scheduler_name is not None:\n","        return\n","\n","\n","class ChaiiLightningModule(pl.LightningModule):\n","    def __init__(self, cfg):\n","        super(ChaiiLightningModule, self).__init__()\n","        self.cfg = cfg\n","        self.model = ChaiiModel(self.cfg)\n","        self.criterion = get_criterion(self.cfg)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output_start, output_end = self.model(input_ids, attention_mask)\n","        return output_start, output_end\n","\n","    def training_step(self, batch, batch_idx):\n","        input_ids, attention_mask, target_start, target_end = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"start_position\"], batch[\"end_position\"]\n","        output_start, output_end = self.forward(input_ids, attention_mask)\n","\n","        loss_start = self.criterion(output_start, target_start)\n","        loss_end = self.criterion(output_end, target_end)\n","        loss = (loss_start + loss_end) / 2\n","\n","        self.log(\"train/loss\", loss.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"train/loss_start_epoch\", loss_start.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"train/loss_end_epoch\", loss_end.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        input_ids, attention_mask, target_start, target_end = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"start_position\"], batch[\"end_position\"]\n","        output_start, output_end = self.forward(input_ids, attention_mask)\n","\n","        loss_start = self.criterion(output_start, target_start)\n","        loss_end = self.criterion(output_end, target_end)\n","        loss = (loss_start + loss_end) / 2\n","\n","        self.log(\"val/loss\", loss.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"val/loss_start_epoch\", loss_start.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"val/loss_end_epoch\", loss_end.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","\n","        outputs = OrderedDict({\n","            \"start_logits\": output_start.detach(),\n","            \"end_logits\": output_end.detach(),\n","        }\n","        )\n","\n","        return outputs\n","\n","    def validation_epoch_end(self, outputs):\n","        pred_start = torch.cat([output[\"start_logits\"] for output in outputs]).cpu().numpy()\n","        pred_end = torch.cat([output[\"end_logits\"] for output in outputs]).cpu().numpy()\n","\n","        preds = postprocess_qa_predictions(\n","            self.trainer.datamodule.tokenizer,\n","            self.trainer.datamodule.valid_df,\n","            copy.deepcopy(self.trainer.datamodule.valid_features[:pred_start.shape[0]]),\n","            (pred_start, pred_end)\n","        )\n","        jaccard_score = np.mean([jaccard(x, y) for x, y in zip(self.trainer.datamodule.valid_df[\"answer_text\"].values, preds.values())], axis=0)\n","\n","        self.log(\"val/jaccard_epoch\", jaccard_score, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n","        input_ids, attention_mask = batch[\"input_ids\"], batch[\"attention_mask\"]\n","        output_start, output_end = self.forward(input_ids, attention_mask)\n","\n","        outputs = OrderedDict({\n","            \"start_logits\": output_start,\n","            \"end_logits\": output_end,\n","        }\n","        )\n","\n","        return outputs\n","\n","    def configure_optimizers(self):\n","        # optimizer_grouped_parameters = get_optimizer_grouped_parameters(self.cfg, self.model)\n","        optimizer = get_optimizer(\n","            self.cfg,\n","            self.model,\n","            # optimizer_grouped_parameters=optimizer_grouped_parameters\n","        )\n","\n","        num_training_steps = math.ceil(len(self.trainer.datamodule.train_dataloader()) / self.trainer.accumulate_grad_batches) * self.trainer.max_epochs\n","        if self.cfg.scheduler_params[\"warmup_ratio\"] \u003e 0:\n","            num_warmup_steps = int(num_training_steps * self.cfg.scheduler_params[\"warmup_ratio\"])\n","        else:\n","            num_warmup_steps = 0\n","        scheduler = get_scheduler(self.cfg, optimizer, num_warmup_steps, num_training_steps)\n","        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n","        print(f\"Total Training Steps: {num_training_steps}, Total Warmup Steps: {num_warmup_steps}\")\n","\n","        return [optimizer], [scheduler]\n","\n","\n","def run_fold(cfg, train_df, fold, tokenizer):\n","    seed_everything(cfg.seed[0])\n","    checkpoint_path = cfg.checkpoint_dir + \"/\" + cfg.exp_name\n","\n","    if not os.path.exists(checkpoint_path):\n","        os.makedirs(checkpoint_path)\n","\n","    checkpoint_callback = ModelCheckpoint(\n","        dirpath=checkpoint_path,\n","        filename=f\"{cfg.exp_name}_fold_{fold}\",\n","        **cfg.model_checkpoint_params,\n","    )\n","\n","    early_stopping_callback = EarlyStopping(**cfg.early_stopping_params)\n","\n","    wandb_logger = WandbLogger(\n","        name=f\"{cfg.exp_name}_fold_{fold}\",\n","        **cfg.wandb_logger_params,\n","    )\n","\n","    trainer = Trainer(\n","        default_root_dir=cfg.checkpoint_dir,\n","        gpus=cfg.gpus,\n","        max_epochs=cfg.num_epochs,\n","        accumulate_grad_batches=cfg.grad_accumulate,\n","        precision=16 if cfg.fp16 else 32,\n","        callbacks=[\n","            checkpoint_callback,\n","            # early_stopping_callback,\n","        ],\n","        logger=[\n","            wandb_logger,\n","        ],\n","        log_every_n_steps=10,\n","    )\n","\n","    model = ChaiiLightningModule(cfg)\n","    datamodule = ChaiiDataModule(cfg, tokenizer=tokenizer, input_df=train_df, phase=\"train\", fold=fold)\n","    trainer.fit(model, datamodule=datamodule)\n","\n","    wandb.finish()\n","\n","    del trainer, model, datamodule\n","    gc.collect()\n","\n","    return checkpoint_callback.best_model_path, checkpoint_callback.best_model_score.item()\n","\n","\n","def run_training(cfg, train_df):\n","    tokenizer = AutoTokenizer.from_pretrained(cfg.tokenizer_name)\n","\n","    checkpoint_path_list = []\n","    oof_score = 0\n","\n","    for fold_id in range(cfg.split_params[\"n_splits\"]):\n","        checkpoint_path, best_score = run_fold(cfg, train_df, fold_id, tokenizer)\n","        checkpoint_path_list.append(checkpoint_path)\n","        oof_score += best_score / int(cfg.split_params[\"n_splits\"])\n","\n","    print(\"CV jaccard score :\", oof_score)\n","\n","    return checkpoint_path_list"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":224},"id":"hhGIfEKXBatS"},"outputs":[{"name":"stderr","output_type":"stream","text":["Global seed set to 2021\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8bf9f1b948974d769b38649039faa1e2","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/7506 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09728f5fea71471aa8f3e7ce43f3076a","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/223 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 19354, Number of valid features: 2972\n","Total Training Steps: 8065, Total Warmup Steps: 806\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mazupero\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["\n","                    Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/mu56wooh\" target=\"_blank\"\u003eexp009_fold_0\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\"\u003edocs\u003c/a\u003e).\u003cbr/\u003e\n","\n","                "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name      | Type             | Params\n","-----------------------------------------------\n","0 | model     | ChaiiModel       | 559 M \n","1 | criterion | CrossEntropyLoss | 0     \n","-----------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae961d2ef39040a7aeec47267db384f7","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2021\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b91a8ece59e145f9a1411ee050b88869","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23abfb66cc254a17ae0385d75e5c0052","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad55994214364a2fa2b66ca9310ae13f","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cf8a54b1aa84e35834aec5ebc2de987","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24bb44b9253344eb97da011a0b59102f","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5adb6c0e3f5e4f84ad520462505d4a35","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cbr/\u003eWaiting for W\u0026B process to finish, PID 1318... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68ed78cda3ff46bc9bae99d6f05b553f","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cstyle\u003e\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    \u003c/style\u003e\n","\u003cdiv class=\"wandb-row\"\u003e\u003cdiv class=\"wandb-col\"\u003e\n","\u003ch3\u003eRun history:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eepoch\u003c/td\u003e\u003ctd\u003e▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_end_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_start_epoch\u003c/td\u003e\u003ctd\u003e█▄▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_step\u003c/td\u003e\u003ctd\u003e█▂▃▂▁▂▁▁▁▁▂▂▁▁▃▂▂▁▁▂▁▁▁▃▁▁▂▁▃▁▁▁▂▁▂▁▂▁▁▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrainer/global_step\u003c/td\u003e\u003ctd\u003e▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/jaccard_epoch\u003c/td\u003e\u003ctd\u003e▆█▅▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss\u003c/td\u003e\u003ctd\u003e▁▂▃▅█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_end_epoch\u003c/td\u003e\u003ctd\u003e▁▁▃▄█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_start_epoch\u003c/td\u003e\u003ctd\u003e▁▂▄▅█\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003cdiv class=\"wandb-col\"\u003e\n","\u003ch3\u003eRun summary:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eepoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_end_epoch\u003c/td\u003e\u003ctd\u003e0.31953\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_epoch\u003c/td\u003e\u003ctd\u003e0.25579\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_start_epoch\u003c/td\u003e\u003ctd\u003e0.19204\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_step\u003c/td\u003e\u003ctd\u003e0.3255\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrainer/global_step\u003c/td\u003e\u003ctd\u003e8064\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/jaccard_epoch\u003c/td\u003e\u003ctd\u003e0.59557\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss\u003c/td\u003e\u003ctd\u003e0.42296\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_end_epoch\u003c/td\u003e\u003ctd\u003e0.43641\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_start_epoch\u003c/td\u003e\u003ctd\u003e0.4095\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n","\u003c/div\u003e\u003c/div\u003e\n","Synced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u003cbr/\u003eSynced \u003cstrong style=\"color:#cdcd00\"\u003eexp009_fold_0\u003c/strong\u003e: \u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/mu56wooh\" target=\"_blank\"\u003ehttps://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/mu56wooh\u003c/a\u003e\u003cbr/\u003e\n","Find logs at: \u003ccode\u003e./wandb/run-20211104_165425-mu56wooh/logs\u003c/code\u003e\u003cbr/\u003e\n"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2021\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7551cad0143148d0a1c8920cc0ab1960","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/7506 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ef19a75cef149ca9647ae16d436fab6","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/223 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 19658, Number of valid features: 2668\n","Total Training Steps: 8195, Total Warmup Steps: 819\n"]},{"data":{"text/html":["\n","                    Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/3f6ogavc\" target=\"_blank\"\u003eexp009_fold_1\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\"\u003edocs\u003c/a\u003e).\u003cbr/\u003e\n","\n","                "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name      | Type             | Params\n","-----------------------------------------------\n","0 | model     | ChaiiModel       | 559 M \n","1 | criterion | CrossEntropyLoss | 0     \n","-----------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp009 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62b609fd8c2140a689c706930782736e","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2021\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1eb8ff4f88854b64bfacaec3ffb33d93","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"154f64d603e14dd1abea509cd7cb0ac8","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15e018e8c0e744a7b3994d0b8a932317","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d131eada439465faf0063e4d435b3cf","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c94105718d0465a9efc3d8d1cac4b69","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1106cc62c03447a09edef871747577b5","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cbr/\u003eWaiting for W\u0026B process to finish, PID 1839... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd4c6d173ba8489c8a11b1aeb0d486e5","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cstyle\u003e\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    \u003c/style\u003e\n","\u003cdiv class=\"wandb-row\"\u003e\u003cdiv class=\"wandb-col\"\u003e\n","\u003ch3\u003eRun history:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eepoch\u003c/td\u003e\u003ctd\u003e▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_end_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_start_epoch\u003c/td\u003e\u003ctd\u003e█▄▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_step\u003c/td\u003e\u003ctd\u003e█▄▂▂▂▂▃▁▁▁▁▄▁▃▃▂▂▁▂▁▁▁▁▁▁▁▃▁▁▁▂▁▁▁▁▁▁▁▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrainer/global_step\u003c/td\u003e\u003ctd\u003e▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/jaccard_epoch\u003c/td\u003e\u003ctd\u003e██▅▄▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss\u003c/td\u003e\u003ctd\u003e▄▄▁▂█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_end_epoch\u003c/td\u003e\u003ctd\u003e▃▄▁▂█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_start_epoch\u003c/td\u003e\u003ctd\u003e▄▄▁▂█\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003cdiv class=\"wandb-col\"\u003e\n","\u003ch3\u003eRun summary:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eepoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_end_epoch\u003c/td\u003e\u003ctd\u003e0.31269\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_epoch\u003c/td\u003e\u003ctd\u003e0.2528\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_start_epoch\u003c/td\u003e\u003ctd\u003e0.19291\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_step\u003c/td\u003e\u003ctd\u003e0.34558\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrainer/global_step\u003c/td\u003e\u003ctd\u003e8194\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/jaccard_epoch\u003c/td\u003e\u003ctd\u003e0.56631\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss\u003c/td\u003e\u003ctd\u003e0.45404\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_end_epoch\u003c/td\u003e\u003ctd\u003e0.45931\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_start_epoch\u003c/td\u003e\u003ctd\u003e0.44878\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n","\u003c/div\u003e\u003c/div\u003e\n","Synced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u003cbr/\u003eSynced \u003cstrong style=\"color:#cdcd00\"\u003eexp009_fold_1\u003c/strong\u003e: \u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/3f6ogavc\" target=\"_blank\"\u003ehttps://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/3f6ogavc\u003c/a\u003e\u003cbr/\u003e\n","Find logs at: \u003ccode\u003e./wandb/run-20211104_191745-3f6ogavc/logs\u003c/code\u003e\u003cbr/\u003e\n"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2021\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36c1ef33917948c8a54474f9b49a80d2","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/7506 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7be8e74b77004e9396af0f5bec75ce24","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/223 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 19332, Number of valid features: 2994\n","Total Training Steps: 8055, Total Warmup Steps: 805\n"]},{"data":{"text/html":["\n","                    Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1wi2r1fd\" target=\"_blank\"\u003eexp009_fold_2\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\"\u003edocs\u003c/a\u003e).\u003cbr/\u003e\n","\n","                "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name      | Type             | Params\n","-----------------------------------------------\n","0 | model     | ChaiiModel       | 559 M \n","1 | criterion | CrossEntropyLoss | 0     \n","-----------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp009 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c9ae06e8f8a42178cc89a8a14414388","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2021\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4f10461f9ae4fce8e293a3912eb2967","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"729a645621b34573b42a53221cae8b1e","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a5ba2c1abdb4536a53e9f38971c666d","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acdaea05b48d4540807c8756a8c05ef7","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10f1f24007d34b82a7b9aa1e3fa89a7e","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97781230dd20458b92b6a94fb47cfabe","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cbr/\u003eWaiting for W\u0026B process to finish, PID 2286... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db15efd86f6246c9b591a7e6bc028e63","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cstyle\u003e\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    \u003c/style\u003e\n","\u003cdiv class=\"wandb-row\"\u003e\u003cdiv class=\"wandb-col\"\u003e\n","\u003ch3\u003eRun history:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eepoch\u003c/td\u003e\u003ctd\u003e▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_end_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_start_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_step\u003c/td\u003e\u003ctd\u003e█▂▁▂▁▃▁▄▃▃▃▄▂▂▂▂▃▁▁▁▁▂▂▂▃▁▁▆▁▂▁▂▂▁▁▁▁▁▂▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrainer/global_step\u003c/td\u003e\u003ctd\u003e▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/jaccard_epoch\u003c/td\u003e\u003ctd\u003e▇█▅▃▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss\u003c/td\u003e\u003ctd\u003e▂▁▄▅█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_end_epoch\u003c/td\u003e\u003ctd\u003e▃▁▄▅█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_start_epoch\u003c/td\u003e\u003ctd\u003e▂▁▄▄█\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003cdiv class=\"wandb-col\"\u003e\n","\u003ch3\u003eRun summary:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eepoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_end_epoch\u003c/td\u003e\u003ctd\u003e0.34105\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_epoch\u003c/td\u003e\u003ctd\u003e0.27399\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_start_epoch\u003c/td\u003e\u003ctd\u003e0.20693\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_step\u003c/td\u003e\u003ctd\u003e0.00047\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrainer/global_step\u003c/td\u003e\u003ctd\u003e8054\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/jaccard_epoch\u003c/td\u003e\u003ctd\u003e0.61145\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss\u003c/td\u003e\u003ctd\u003e0.35027\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_end_epoch\u003c/td\u003e\u003ctd\u003e0.35963\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_start_epoch\u003c/td\u003e\u003ctd\u003e0.34091\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n","\u003c/div\u003e\u003c/div\u003e\n","Synced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u003cbr/\u003eSynced \u003cstrong style=\"color:#cdcd00\"\u003eexp009_fold_2\u003c/strong\u003e: \u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1wi2r1fd\" target=\"_blank\"\u003ehttps://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1wi2r1fd\u003c/a\u003e\u003cbr/\u003e\n","Find logs at: \u003ccode\u003e./wandb/run-20211104_214236-1wi2r1fd/logs\u003c/code\u003e\u003cbr/\u003e\n"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2021\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"435e41af10bf45dd9d4277e2520aa29a","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/7506 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94d879612d3e4c67bfdbbdd002dd243a","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/223 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 19529, Number of valid features: 2797\n","Total Training Steps: 8140, Total Warmup Steps: 814\n"]},{"data":{"text/html":["\n","                    Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1860mdvv\" target=\"_blank\"\u003eexp009_fold_3\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\"\u003edocs\u003c/a\u003e).\u003cbr/\u003e\n","\n","                "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name      | Type             | Params\n","-----------------------------------------------\n","0 | model     | ChaiiModel       | 559 M \n","1 | criterion | CrossEntropyLoss | 0     \n","-----------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp009 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f100bab47d2463fb1274a963591ead7","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2021\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e79139e037a42fbbc5152aa1ed63326","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74f95d1d8ef64bde8e9ecbd14b4b27c6","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30012696b96f4618bed082ef7b191671","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5114dfef187648959008915a02876392","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc2fc047199b404b9d5e6d222c2d21d6","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fa45b26bffd4838b6595771266ed6a7","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cbr/\u003eWaiting for W\u0026B process to finish, PID 2735... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26b5256fe5cd4a5eaebb8f5c7d712100","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cstyle\u003e\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    \u003c/style\u003e\n","\u003cdiv class=\"wandb-row\"\u003e\u003cdiv class=\"wandb-col\"\u003e\n","\u003ch3\u003eRun history:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eepoch\u003c/td\u003e\u003ctd\u003e▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_end_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_start_epoch\u003c/td\u003e\u003ctd\u003e█▄▂▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_step\u003c/td\u003e\u003ctd\u003e█▁▇▂▃▃▂▂▂▂▄▁▁▂▁▁▂▁▄▁▁▃▂▁▃▁▁▂▂▂▁▁▁▁▁▁▁▁▁▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrainer/global_step\u003c/td\u003e\u003ctd\u003e▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/jaccard_epoch\u003c/td\u003e\u003ctd\u003e█▅▃▅▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss\u003c/td\u003e\u003ctd\u003e▂▁▁██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_end_epoch\u003c/td\u003e\u003ctd\u003e▂▂▁█▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_start_epoch\u003c/td\u003e\u003ctd\u003e▃▁▂██\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003cdiv class=\"wandb-col\"\u003e\n","\u003ch3\u003eRun summary:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eepoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_end_epoch\u003c/td\u003e\u003ctd\u003e0.31334\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_epoch\u003c/td\u003e\u003ctd\u003e0.25317\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_start_epoch\u003c/td\u003e\u003ctd\u003e0.193\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_step\u003c/td\u003e\u003ctd\u003e0.003\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrainer/global_step\u003c/td\u003e\u003ctd\u003e8139\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/jaccard_epoch\u003c/td\u003e\u003ctd\u003e0.54043\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss\u003c/td\u003e\u003ctd\u003e0.44037\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_end_epoch\u003c/td\u003e\u003ctd\u003e0.45564\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_start_epoch\u003c/td\u003e\u003ctd\u003e0.4251\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n","\u003c/div\u003e\u003c/div\u003e\n","Synced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u003cbr/\u003eSynced \u003cstrong style=\"color:#cdcd00\"\u003eexp009_fold_3\u003c/strong\u003e: \u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1860mdvv\" target=\"_blank\"\u003ehttps://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1860mdvv\u003c/a\u003e\u003cbr/\u003e\n","Find logs at: \u003ccode\u003e./wandb/run-20211105_000550-1860mdvv/logs\u003c/code\u003e\u003cbr/\u003e\n"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2021\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fdcc7e1253a4a51b50b2e297f914c8f","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/7507 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1f5cfcb1e1f4ce9a13de6064a2cef05","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/222 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 19569, Number of valid features: 2757\n","Total Training Steps: 8155, Total Warmup Steps: 815\n"]},{"data":{"text/html":["\n","                    Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1i0hlmc4\" target=\"_blank\"\u003eexp009_fold_4\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\"\u003edocs\u003c/a\u003e).\u003cbr/\u003e\n","\n","                "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name      | Type             | Params\n","-----------------------------------------------\n","0 | model     | ChaiiModel       | 559 M \n","1 | criterion | CrossEntropyLoss | 0     \n","-----------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp009 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08469b2cee4a4076b1195e3a411e8ad2","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2021\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02e22caef668484480369857fadf7460","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1db8596416843aaa7435c817600ddda","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09056279fb104a899125a7e78ca5f6bc","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75b8b10795bc4dcead1ee5cdbd021207","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e1517e795434dd983dbd83f0df20da4","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4df43cf5b5ac423fb5abbff08a8e520a","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cbr/\u003eWaiting for W\u0026B process to finish, PID 3184... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba7652a0c20644ba83d17efa0afdab7f","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cstyle\u003e\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    \u003c/style\u003e\n","\u003cdiv class=\"wandb-row\"\u003e\u003cdiv class=\"wandb-col\"\u003e\n","\u003ch3\u003eRun history:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eepoch\u003c/td\u003e\u003ctd\u003e▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_end_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_start_epoch\u003c/td\u003e\u003ctd\u003e█▄▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_step\u003c/td\u003e\u003ctd\u003e▇▃▃▅▁▁▂█▁▁▁▁▂▁▇▄▁▁▂▄▁▁▂▂▁▁▃▂▅▆▁▁▁▂▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrainer/global_step\u003c/td\u003e\u003ctd\u003e▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/jaccard_epoch\u003c/td\u003e\u003ctd\u003e██▅▃▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss\u003c/td\u003e\u003ctd\u003e▁▂▃▅█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_end_epoch\u003c/td\u003e\u003ctd\u003e▁▁▃▅█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_start_epoch\u003c/td\u003e\u003ctd\u003e▁▂▃▅█\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003cdiv class=\"wandb-col\"\u003e\n","\u003ch3\u003eRun summary:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eepoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_end_epoch\u003c/td\u003e\u003ctd\u003e0.33745\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_epoch\u003c/td\u003e\u003ctd\u003e0.26761\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_start_epoch\u003c/td\u003e\u003ctd\u003e0.19777\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss_step\u003c/td\u003e\u003ctd\u003e0.08966\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrainer/global_step\u003c/td\u003e\u003ctd\u003e8154\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/jaccard_epoch\u003c/td\u003e\u003ctd\u003e0.62693\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss\u003c/td\u003e\u003ctd\u003e0.37584\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_end_epoch\u003c/td\u003e\u003ctd\u003e0.39794\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eval/loss_start_epoch\u003c/td\u003e\u003ctd\u003e0.35374\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n","\u003c/div\u003e\u003c/div\u003e\n","Synced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u003cbr/\u003eSynced \u003cstrong style=\"color:#cdcd00\"\u003eexp009_fold_4\u003c/strong\u003e: \u003ca href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1i0hlmc4\" target=\"_blank\"\u003ehttps://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1i0hlmc4\u003c/a\u003e\u003cbr/\u003e\n","Find logs at: \u003ccode\u003e./wandb/run-20211105_022953-1i0hlmc4/logs\u003c/code\u003e\u003cbr/\u003e\n"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["CV jaccard score : 0.5881388187408447\n"]}],"source":["# tokenizer = AutoTokenizer.from_pretrained(cfg.tokenizer_name)\n","# _, _ = run_fold(cfg, train_df, 0, tokenizer)\n","checkpoint_path_list = run_training(cfg, train_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MbsE5t9-jbB3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting upload for file exp009_fold_0.ckpt\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.09G/2.09G [01:18\u003c00:00, 28.6MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: exp009_fold_0.ckpt (2GB)\n","Starting upload for file exp009_fold_1.ckpt\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.09G/2.09G [01:15\u003c00:00, 29.5MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: exp009_fold_1.ckpt (2GB)\n","Starting upload for file exp009_fold_2.ckpt\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.09G/2.09G [01:15\u003c00:00, 29.6MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: exp009_fold_2.ckpt (2GB)\n","Starting upload for file exp009_fold_3.ckpt\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.09G/2.09G [01:16\u003c00:00, 29.1MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: exp009_fold_3.ckpt (2GB)\n","Starting upload for file exp009_fold_4.ckpt\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.09G/2.09G [01:14\u003c00:00, 29.9MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: exp009_fold_4.ckpt (2GB)\n"]}],"source":["ID = \"azupero\"\n","DATASET_ID = f\"chaii-qa-checkpoint-{cfg.exp_name}\"\n","checkpoint_path = cfg.checkpoint_dir + \"/\" + cfg.exp_name\n","UPLOAD_DIR = Path(checkpoint_path)\n","\n","def dataset_create_new():\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{ID}/{DATASET_ID}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = DATASET_ID\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=UPLOAD_DIR, convert_to_csv=False, dir_mode='tar')\n","\n","dataset_create_new()"]},{"cell_type":"markdown","metadata":{"id":"USegY8kE1TMN"},"source":["## inference"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"a2iSNKOK7-32"},"outputs":[],"source":["def run_predict(cfg, input_df):\n","    tokenizer = AutoTokenizer.from_pretrained(cfg.tokenizer_name)\n","    checkpoint_path = list(Path(cfg.checkpoint_dir).iterdir())\n","    start_logits = []\n","    end_logits = []\n","\n","    for path in checkpoint_path:\n","        seed_everything(cfg.seed[0])\n","\n","        model = ChaiiLightningModule.load_from_checkpoint(checkpoint_path=path, cfg=cfg)\n","        datamodule = ChaiiDataModule(cfg, tokenizer=tokenizer, input_df=input_df, phase=\"test\")\n","        trainer = Trainer(gpus=cfg.gpus)\n","        preds = trainer.predict(model, datamodule=datamodule, return_predictions=True)\n","        start_logits.append(torch.cat([pred[\"start_logits\"] for pred in preds]).cpu().numpy())\n","        end_logits.append(torch.cat([pred[\"end_logits\"] for pred in preds]).cpu().numpy())\n","\n","    start_logits, end_logits = np.mean(start_logits, axis=0), np.mean(end_logits, axis=0)\n","    predictions = postprocess_qa_predictions(input_df, datamodule.test_features, (start_logits, end_logits))\n","\n","    input_df[\"PredictionString\"] = input_df[\"id\"].map(predictions)\n","    input_df[\"PredictionString\"] = postprocess_cleaned_predictions(input_df)\n","    input_df[[\"id\", \"PredictionString\"]].to_csv(\"submission.csv\", index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMOZGK5LNQkcVNx1xebeDpF","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1Z205IKZs4v9B8CwtX15Jk794b44avJFh","name":"nb009_xlmroberta_exp009.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00a78e3920754cd895bcd6ad16c13f63":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09728f5fea71471aa8f3e7ce43f3076a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aae16bfadcb14249998f16bcda25990f","IPY_MODEL_fc3ae9e14ca04353a1327bed6b054333","IPY_MODEL_f0a47137c83b4e93925dfabbfb699197"],"layout":"IPY_MODEL_75f4afd2bad140259b322f3b18547e7d"}},"21389562804646a382d8e5a51f005e55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36b2f7df9430414da05d784779e7aaf6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d64ab3f92d64868a96f5e3cc35a1b9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"710b7d77adec4ae4ad52808a57b45519":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75f4afd2bad140259b322f3b18547e7d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bf9f1b948974d769b38649039faa1e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfdebd456ffd42939be0d82d9462f71e","IPY_MODEL_b86ea5a58b7d43b7b2f7b3a9511ed2bd","IPY_MODEL_c1696f46357f4a6c911cb75b9f809dce"],"layout":"IPY_MODEL_da8454f589404cedbc1a874a3a286eb3"}},"a0519eeb7be4454dbc6e514502650f98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5091c970e3a48b7a24d6483eeea5d71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aae16bfadcb14249998f16bcda25990f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0519eeb7be4454dbc6e514502650f98","placeholder":"​","style":"IPY_MODEL_a5091c970e3a48b7a24d6483eeea5d71","value":"[get features]:  92%"}},"b2a17e08a7e540db95f675e5dc5e0fd9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b86ea5a58b7d43b7b2f7b3a9511ed2bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_00a78e3920754cd895bcd6ad16c13f63","max":7506,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d64ab3f92d64868a96f5e3cc35a1b9c","value":7506}},"ba804c2b3551486fa31be36ed7315462":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1696f46357f4a6c911cb75b9f809dce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f484f74657a247b9bebf3e3b378bd08c","placeholder":"​","style":"IPY_MODEL_710b7d77adec4ae4ad52808a57b45519","value":" 7506/7506 [02:13\u0026lt;00:00, 74.44it/s]"}},"da8454f589404cedbc1a874a3a286eb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfdebd456ffd42939be0d82d9462f71e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2a17e08a7e540db95f675e5dc5e0fd9","placeholder":"​","style":"IPY_MODEL_e7c552b88fb54b78a4bb5d08a86793c0","value":"[get features]: 100%"}},"e7c552b88fb54b78a4bb5d08a86793c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0a47137c83b4e93925dfabbfb699197":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21389562804646a382d8e5a51f005e55","placeholder":"​","style":"IPY_MODEL_fa582e545bca41cbb6aadd4fb7b9db11","value":" 205/223 [00:12\u0026lt;00:01, 14.57it/s]"}},"f484f74657a247b9bebf3e3b378bd08c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa582e545bca41cbb6aadd4fb7b9db11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc3ae9e14ca04353a1327bed6b054333":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba804c2b3551486fa31be36ed7315462","max":223,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36b2f7df9430414da05d784779e7aaf6","value":205}}}}},"nbformat":4,"nbformat_minor":0}