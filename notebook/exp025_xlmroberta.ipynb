{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"exp025_xlmroberta.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1RB0LdvV1QmcA1ggwqBeBPF191b-qeKi1","authorship_tag":"ABX9TyMIOxLoilaI9N/yLns8g+hQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c69e8425a2584f5ab5dcb82dd88147be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f3ae0d4b61b400cb93082a8675897d1","IPY_MODEL_349685e1b2e94484a68bdabef71c6eb1","IPY_MODEL_bc384e9daebf478781beb3d6c3683ba3"],"layout":"IPY_MODEL_5a03d179b69d4626b7d1d6ec2b59a6e5"}},"8f3ae0d4b61b400cb93082a8675897d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21ab2d533a7e47d589c8d2150f16ab05","placeholder":"​","style":"IPY_MODEL_bb1b94e9922c43ea8964cd5f7c7997fd","value":"Downloading: 100%"}},"349685e1b2e94484a68bdabef71c6eb1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25a2eeba7d044e92a57d422af76af4e4","max":179,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69c6ea4d5e0e4dfebcd22a370e3917d3","value":179}},"bc384e9daebf478781beb3d6c3683ba3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52591667acd64755b1274f0a93d07707","placeholder":"​","style":"IPY_MODEL_846e78edf53f470dbe420eba11a5bef7","value":" 179/179 [00:00&lt;00:00, 6.18kB/s]"}},"5a03d179b69d4626b7d1d6ec2b59a6e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21ab2d533a7e47d589c8d2150f16ab05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb1b94e9922c43ea8964cd5f7c7997fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25a2eeba7d044e92a57d422af76af4e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69c6ea4d5e0e4dfebcd22a370e3917d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52591667acd64755b1274f0a93d07707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"846e78edf53f470dbe420eba11a5bef7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98e540baa2dd4c95a8d180ae3839dd64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2aed5fdb6df4eb8bbaa6b8eb1e682ef","IPY_MODEL_a68c0ce8ce8342c98fad211b2402af98","IPY_MODEL_05bff16960d749e9837ebf0db807a827"],"layout":"IPY_MODEL_cf1fd838d0d14b6fa5ae70a6f3bffc0e"}},"b2aed5fdb6df4eb8bbaa6b8eb1e682ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5aec567fa4144606bb3818a84130bfff","placeholder":"​","style":"IPY_MODEL_77e0e6427446499ba4915587065158f2","value":"Downloading: 100%"}},"a68c0ce8ce8342c98fad211b2402af98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_201e7d5499b84d6db6ce1c9966ee0f2f","max":606,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4389d10979074aaabff9f3e184a6d406","value":606}},"05bff16960d749e9837ebf0db807a827":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61a54eac4d4f4b6dadf35dfc18e52487","placeholder":"​","style":"IPY_MODEL_1a200148451349a992a87190b6bbe00f","value":" 606/606 [00:00&lt;00:00, 22.6kB/s]"}},"cf1fd838d0d14b6fa5ae70a6f3bffc0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aec567fa4144606bb3818a84130bfff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77e0e6427446499ba4915587065158f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"201e7d5499b84d6db6ce1c9966ee0f2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4389d10979074aaabff9f3e184a6d406":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61a54eac4d4f4b6dadf35dfc18e52487":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a200148451349a992a87190b6bbe00f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8f7fb80aa174bb5802c8271b8181a93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c72c366b2a5b4349be7ee2758eab8cfc","IPY_MODEL_ba748241a6eb43aab715645d8c30380d","IPY_MODEL_74e99a3a936e489c880b5a6a81bbeda9"],"layout":"IPY_MODEL_c0ea4fe9f2a340ea8f22d5e521c89320"}},"c72c366b2a5b4349be7ee2758eab8cfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06a89907255748958454063a13fb272e","placeholder":"​","style":"IPY_MODEL_4af9119a020844c0a1190bc956ebd895","value":"Downloading: 100%"}},"ba748241a6eb43aab715645d8c30380d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3337332405604993b19b1cf9c497d037","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b48d9cf9df54a5eb501041b2d8b3b50","value":5069051}},"74e99a3a936e489c880b5a6a81bbeda9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e64fcfc72c2435d951a74591343b272","placeholder":"​","style":"IPY_MODEL_00b7cb7553234a849322c2c1deba9953","value":" 4.83M/4.83M [00:00&lt;00:00, 6.51MB/s]"}},"c0ea4fe9f2a340ea8f22d5e521c89320":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06a89907255748958454063a13fb272e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4af9119a020844c0a1190bc956ebd895":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3337332405604993b19b1cf9c497d037":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b48d9cf9df54a5eb501041b2d8b3b50":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e64fcfc72c2435d951a74591343b272":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00b7cb7553234a849322c2c1deba9953":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e62e81be170d40c5aabd60a1c4ad84f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6afb2a84be2a4bb18ea58de232345c51","IPY_MODEL_f50a84e74d2d4884aee6240151a18992","IPY_MODEL_98afc3bba61e48d6b2cc84edfd7e94fc"],"layout":"IPY_MODEL_23701b33f1da4c319eb1647c70210e8f"}},"6afb2a84be2a4bb18ea58de232345c51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dafbc2844864db3a47ea273f92de9bd","placeholder":"​","style":"IPY_MODEL_b9b30012b70447fd814c98ca7c1a5a67","value":"Downloading: 100%"}},"f50a84e74d2d4884aee6240151a18992":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f142c2f30384631a2d0ac96f7e86870","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59cafbf8e4d9442db6c2d74f40ee0995","value":150}},"98afc3bba61e48d6b2cc84edfd7e94fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38dce763494748c78d288488d420d007","placeholder":"​","style":"IPY_MODEL_dfd5910a32c14115b447300c16c7bbb7","value":" 150/150 [00:00&lt;00:00, 5.64kB/s]"}},"23701b33f1da4c319eb1647c70210e8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dafbc2844864db3a47ea273f92de9bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9b30012b70447fd814c98ca7c1a5a67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f142c2f30384631a2d0ac96f7e86870":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59cafbf8e4d9442db6c2d74f40ee0995":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"38dce763494748c78d288488d420d007":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfd5910a32c14115b447300c16c7bbb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84c793e5d7de47adacf85830bc158b22":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54d7a491e63e488c89d186636d1bc431","IPY_MODEL_052f60cfbec1475f91a9c1655ffa4986","IPY_MODEL_26e41b5d388f4846bea678edd04e273b"],"layout":"IPY_MODEL_d924f49511864ba8b6db5307e13ded30"}},"54d7a491e63e488c89d186636d1bc431":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9d99da367a84069a70f14e4ddb1dce5","placeholder":"​","style":"IPY_MODEL_0db5474a07064c42ac0e6885399ea52a","value":"Downloading: 100%"}},"052f60cfbec1475f91a9c1655ffa4986":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e20b343c0aa4615b16c8508b093a48a","max":2239666418,"min":0,"orientation":"horizontal","style":"IPY_MODEL_def0a686e8ae4cd283d70cf8a710e4d0","value":2239666418}},"26e41b5d388f4846bea678edd04e273b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaeebc94fcab4a44b511ee6c7fc779dc","placeholder":"​","style":"IPY_MODEL_5ad2c1df4a584dcb976a49ee55133b48","value":" 2.09G/2.09G [00:37&lt;00:00, 62.5MB/s]"}},"d924f49511864ba8b6db5307e13ded30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9d99da367a84069a70f14e4ddb1dce5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0db5474a07064c42ac0e6885399ea52a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e20b343c0aa4615b16c8508b093a48a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"def0a686e8ae4cd283d70cf8a710e4d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eaeebc94fcab4a44b511ee6c7fc779dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ad2c1df4a584dcb976a49ee55133b48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d459a4d50166414ea91b1352e31b4882":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ec318ff763c49d485cb193aae01da5f","IPY_MODEL_a08ea408be4b40e899a72ba211ffaf18","IPY_MODEL_b22d333861074b238660a9caf210793e"],"layout":"IPY_MODEL_7db4a83dc44b4e5ba5d7a29f65634afa"}},"5ec318ff763c49d485cb193aae01da5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4328fb76be8547da9191189ce144a471","placeholder":"​","style":"IPY_MODEL_ae1a8a95804c4df7b4965626ee787ca9","value":"[get features]: 100%"}},"a08ea408be4b40e899a72ba211ffaf18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_551716b161a944b5a6e0a6b33dbb9681","max":11184,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f90b044a2c6046b88d1775d6a53b234c","value":11184}},"b22d333861074b238660a9caf210793e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_604ecf57471f44ddb7419e6c53986fed","placeholder":"​","style":"IPY_MODEL_2935aed131e449d898931c98a9c1bbaf","value":" 11184/11184 [02:55&lt;00:00, 88.45it/s]"}},"7db4a83dc44b4e5ba5d7a29f65634afa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4328fb76be8547da9191189ce144a471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae1a8a95804c4df7b4965626ee787ca9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"551716b161a944b5a6e0a6b33dbb9681":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f90b044a2c6046b88d1775d6a53b234c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"604ecf57471f44ddb7419e6c53986fed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2935aed131e449d898931c98a9c1bbaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f1f365223924b6293b93ee2f428ea28":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_743563ddde8c4415966ec386c91be58b","IPY_MODEL_ae2622fca0824ccaabf6d51764f30b5c","IPY_MODEL_7266483c2673489a8dc2392f09ff28d8"],"layout":"IPY_MODEL_06d41f9f8b7445ff8439810f69a12050"}},"743563ddde8c4415966ec386c91be58b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1a51c61427646a89024c333c8e91230","placeholder":"​","style":"IPY_MODEL_c44e80f209644c9884f94ceb6d71eec8","value":"[get features]: 100%"}},"ae2622fca0824ccaabf6d51764f30b5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b53c7ffbc4c45b6b8b61361b7e837d0","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2dedb70d7974dc18d3e3138c6e20777","value":112}},"7266483c2673489a8dc2392f09ff28d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_417b9283b8534f53a436e530e6ff8c1c","placeholder":"​","style":"IPY_MODEL_9144eb8d968f49d1b849f393ba52e195","value":" 112/112 [00:06&lt;00:00, 16.45it/s]"}},"06d41f9f8b7445ff8439810f69a12050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1a51c61427646a89024c333c8e91230":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c44e80f209644c9884f94ceb6d71eec8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b53c7ffbc4c45b6b8b61361b7e837d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2dedb70d7974dc18d3e3138c6e20777":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"417b9283b8534f53a436e530e6ff8c1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9144eb8d968f49d1b849f393ba52e195":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed7fb1f0d66b4d289061ec98c0f87069":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ffe1206ac9a44366ab122252e0cdb894","IPY_MODEL_3b6afb481d4549409f7f2676b70bd7de","IPY_MODEL_4e7861a73f0f422083da3fb46dc41eb4"],"layout":"IPY_MODEL_ac9a192a4c5a41a7a5b9e6d41916be05"}},"ffe1206ac9a44366ab122252e0cdb894":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6e8140d1fef49c183d894ea788eb734","placeholder":"​","style":"IPY_MODEL_5f309c5122c84ef69ff2175416a99e88","value":"Validation sanity check:   0%"}},"3b6afb481d4549409f7f2676b70bd7de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_788de8c2637d41f4906a1686cf537b53","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c48dcd5617fc49ab851f4fe3c501080b","value":0}},"4e7861a73f0f422083da3fb46dc41eb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85593c6fb0654cb38e10177c2509afef","placeholder":"​","style":"IPY_MODEL_a8d5ead2d44e4ac09dea75a73255823f","value":" 0/2 [00:01&lt;?, ?it/s]"}},"ac9a192a4c5a41a7a5b9e6d41916be05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"a6e8140d1fef49c183d894ea788eb734":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f309c5122c84ef69ff2175416a99e88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"788de8c2637d41f4906a1686cf537b53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c48dcd5617fc49ab851f4fe3c501080b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85593c6fb0654cb38e10177c2509afef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8d5ead2d44e4ac09dea75a73255823f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aae64dcf92a4547948418e583ff483f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b70fa2e3c01c4ccb90b54e13c84b2057","IPY_MODEL_9d07772c57ab41a9bd093970e59cb7fd","IPY_MODEL_7af412357cdf473685e51c20ef2ce15e"],"layout":"IPY_MODEL_de0e858e867b4079aaa4539daa1f8732"}},"b70fa2e3c01c4ccb90b54e13c84b2057":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a631250e1e494c86baa7ce136a71bdbd","placeholder":"​","style":"IPY_MODEL_bb67970c2d9a403f8ed9081fae3ce701","value":"Epoch 0:   0%"}},"9d07772c57ab41a9bd093970e59cb7fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad31869717504011b69f321fb0964f32","max":8385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7bc14b174cec4bfdbe80272ab0c73c23","value":40}},"7af412357cdf473685e51c20ef2ce15e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77ae6bd52ed845bfa00b5a3783592ff7","placeholder":"​","style":"IPY_MODEL_89691547b77940a9b9c95a64ab346447","value":" 40/8385 [00:11&lt;39:06,  3.56it/s, loss=6.36, v_num=cys0, train/loss_step=6.410]"}},"de0e858e867b4079aaa4539daa1f8732":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"a631250e1e494c86baa7ce136a71bdbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb67970c2d9a403f8ed9081fae3ce701":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad31869717504011b69f321fb0964f32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bc14b174cec4bfdbe80272ab0c73c23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"77ae6bd52ed845bfa00b5a3783592ff7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89691547b77940a9b9c95a64ab346447":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7PiERPR3JwG","executionInfo":{"status":"ok","timestamp":1636873216362,"user_tz":-540,"elapsed":439,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}},"outputId":"9ddee4f1-1e63-455d-8547-3544a29a41fe"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Nov 14 07:00:15 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1uHWvJoM1MB","executionInfo":{"status":"ok","timestamp":1636873219742,"user_tz":-540,"elapsed":2813,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}},"outputId":"f346c62f-c290-433e-e8c4-69103d46757f"},"source":["!mkdir ~/.kaggle\n","!cp /content/drive/MyDrive/Colab/kaggle/kaggle.json ~/.kaggle\n","\n","!pip install --upgrade --force-reinstall --no-deps kaggle"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kaggle\n","  Downloading kaggle-1.5.12.tar.gz (58 kB)\n","\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20 kB 38.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30 kB 41.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 4.2 MB/s \n","\u001b[?25hBuilding wheels for collected packages: kaggle\n","  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=251cfa888e827a72e57dabdec80c6e09ad12442fbca177cb5b484b2fa8f591a0\n","  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n","Successfully built kaggle\n","Installing collected packages: kaggle\n","  Attempting uninstall: kaggle\n","    Found existing installation: kaggle 1.5.12\n","    Uninstalling kaggle-1.5.12:\n","      Successfully uninstalled kaggle-1.5.12\n","Successfully installed kaggle-1.5.12\n"]}]},{"cell_type":"code","metadata":{"id":"Urj-Rfgn3UBV","executionInfo":{"status":"ok","timestamp":1636873225944,"user_tz":-540,"elapsed":6206,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}}},"source":["!cp -r /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/input /content\n","!mkdir /content/checkpoint"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6dGMLhJ3f0r","executionInfo":{"status":"ok","timestamp":1636873244020,"user_tz":-540,"elapsed":18081,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}},"outputId":"97e4d869-a37a-4c82-a195-72663ca0a3f8"},"source":["!pip install -U pytorch-lightning transformers wandb sentencepiece torchsummaryX"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.5.1-py3-none-any.whl (1.0 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 38.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 44.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 50.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 163 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 194 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 225 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 256 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 266 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 317 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 327 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 378 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 399 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 440 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 450 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 460 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 471 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 501 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 512 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 522 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 532 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 563 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 573 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 593 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 604 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 624 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 634 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 645 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 655 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 665 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 696 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 706 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 716 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 727 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 737 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 757 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 768 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 788 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 798 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 819 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 829 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 839 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 849 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 860 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 870 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 880 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 890 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 901 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 911 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 921 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 931 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 942 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 952 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 962 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 983 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 993 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.0 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.0 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.0 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0 MB 15.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0 MB 15.5 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 63.2 MB/s \n","\u001b[?25hCollecting wandb\n","  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 75.3 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 63.7 MB/s \n","\u001b[?25hCollecting torchsummaryX\n","  Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.10.0+cu111)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n","\u001b[K     |████████████████████████████████| 329 kB 86.2 MB/s \n","\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 89.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.2)\n","Collecting PyYAML>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 75.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.10.0.2)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.3)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.7.0)\n","Collecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 84.2 MB/s \n","\u001b[?25hCollecting pyDeprecate==0.3.1\n","  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 68.5 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (2.4.7)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.41.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.8.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 77.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 78.6 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 7.9 MB/s \n","\u001b[?25hCollecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 80.4 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 84.4 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 8.5 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.1.5)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n","\u001b[K     |████████████████████████████████| 192 kB 93.1 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 88.3 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 89.4 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.2.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.6.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2018.9)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Building wheels for collected packages: future, subprocess32, pathtools\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=fe2d704fa86b3d02d5237b7628afde11216a12e2f0e5ab059618db59eb5f02c2\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=db0ba74bc1692f97d5943008b2aec821df456ebc9dcd3aed4bda44498f18efa1\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=21db2854497dfd64d83bce85869e5b468917569b28c409f8c97d3187b98c614b\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built future subprocess32 pathtools\n","Installing collected packages: multidict, frozenlist, yarl, smmap, asynctest, async-timeout, aiosignal, PyYAML, gitdb, fsspec, aiohttp, yaspin, torchmetrics, tokenizers, subprocess32, shortuuid, sentry-sdk, sacremoses, pyDeprecate, pathtools, huggingface-hub, GitPython, future, docker-pycreds, configparser, wandb, transformers, torchsummaryX, sentencepiece, pytorch-lightning\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","Successfully installed GitPython-3.1.24 PyYAML-6.0 aiohttp-3.8.0 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 configparser-5.1.0 docker-pycreds-0.4.0 frozenlist-1.2.0 fsspec-2021.11.0 future-0.18.2 gitdb-4.0.9 huggingface-hub-0.1.2 multidict-5.2.0 pathtools-0.1.2 pyDeprecate-0.3.1 pytorch-lightning-1.5.1 sacremoses-0.0.46 sentencepiece-0.1.96 sentry-sdk-1.4.3 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 tokenizers-0.10.3 torchmetrics-0.6.0 torchsummaryX-1.3.0 transformers-4.12.3 wandb-0.12.6 yarl-1.7.2 yaspin-2.1.0\n"]}]},{"cell_type":"code","metadata":{"id":"EGc_0a3l32o8","executionInfo":{"status":"ok","timestamp":1636873260327,"user_tz":-540,"elapsed":16330,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}}},"source":["import os\n","import random\n","from dataclasses import dataclass\n","import copy\n","import gc\n","\n","import numpy as np\n","import pandas as pd\n","import math\n","import sklearn.model_selection as sms\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n","import torch.optim as optim\n","from torchmetrics import MeanMetric\n","from torch.autograd import Variable\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning import Trainer, seed_everything\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n","from pytorch_lightning.loggers import WandbLogger\n","import wandb\n","\n","from transformers import AutoTokenizer, AutoModel, AutoConfig, AdamW, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","from torchsummaryX import summary\n","\n","from collections import defaultdict, OrderedDict\n","from tqdm.notebook import tqdm\n","\n","import json\n","from pathlib import Path\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2pbFM7_B4Emp"},"source":["## config"]},{"cell_type":"code","metadata":{"id":"HemZ1ng-4FIW","executionInfo":{"status":"ok","timestamp":1636873260328,"user_tz":-540,"elapsed":24,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}}},"source":["@dataclass\n","class Config:\n","    #########################\n","    # Globals #\n","    #########################\n","    exp_name = \"exp025\"\n","    debug = False\n","    gpus = 1\n","    num_workers = 8\n","    num_epochs = 2\n","    grad_accumulate = 2\n","    fp16 = False\n","    seed = 2434\n","    #########################\n","    # Data #\n","    #########################\n","    train_csv = \"input/train.csv\"\n","    test_csv = \"input/test.csv\"\n","    sample_submission_csv = \"input/sample_submission.csv\"\n","    mlqa_hindi_csv = \"input/external_data/mlqa_hindi.csv\"\n","    xquad_hindi_csv = \"input/external_data/xquad_hindi.csv\"\n","    xquad_tamil_csv = \"input/external_data/squad_translated_tamil.csv\"\n","    checkpoint_dir = \"drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint\"\n","    #########################\n","    # Split #\n","    #########################\n","    split_name = \"StratifiedKFold\"\n","    split_params = {\n","        \"n_splits\": 10,\n","        \"random_state\": 2434,\n","        \"shuffle\": True,\n","        }\n","    #########################\n","    # Tokenizer #\n","    #########################\n","    tokenizer_name = \"deepset/xlm-roberta-large-squad2\"\n","    max_seq_length = 400\n","    doc_stride = 135\n","    truncation = \"only_second\"\n","    padding = \"max_length\"\n","    #########################\n","    # Dataset #\n","    #########################\n","    #########################\n","    # DataLoader #\n","    #########################\n","    train_batch_size = 3\n","    valid_batch_size = 8\n","    test_batch_size = 128\n","    #########################\n","    # Model #\n","    #########################\n","    base_model_name = \"deepset/xlm-roberta-large-squad2\"\n","    base_model_config = \"deepset/xlm-roberta-large-squad2\"\n","    num_classes = 2\n","    init_layers = 1\n","    #########################\n","    # Criterion #\n","    #########################\n","    loss_name = \"CrossEntropyLoss\"\n","    loss_params = {\n","        \"ignore_index\": -1,\n","    }\n","    #########################\n","    # Optimizer #\n","    #########################\n","    optimizer_name = \"AdamW\"\n","    optimizer_params = {\n","        \"lr\": 1.5e-5,\n","        \"weight_decay\": 1e-2,\n","        \"eps\": 1e-8,\n","        \"correct_bias\": True\n","    }\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    header_weight_decay = 1e-2\n","    header_lr = 1e-3\n","    lr_decay = 0.98\n","    ######################\n","    # Scheduler #\n","    ######################\n","    scheduler_name = \"linear-warmup\"\n","    scheduler_params = {\n","        \"warmup_ratio\": 0.1,\n","    }\n","    ######################\n","    # Callbacks #\n","    ######################\n","    model_checkpoint_params = {\n","        \"monitor\": \"val/loss_epoch\",\n","        \"save_top_k\": 1,\n","        \"save_weights_only\": True,\n","        \"mode\": \"min\",\n","    }\n","    early_stopping_params = {\n","        \"monitor\": \"val/jaccard_epoch\",\n","        \"min_delta\": 0.0,\n","        \"patience\": 5,\n","        \"verbose\": False,\n","        \"mode\": \"max\",\n","    }\n","    wandb_logger_params = {\n","        \"project\": \"kaggle-chaii-hindi-and-tamil-question-answering\"\n","    }\n","\n","\n","cfg = Config()"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N75ldQ_N4_lF"},"source":["## utils"]},{"cell_type":"code","metadata":{"id":"N1OPGpKZ48h-"},"source":["def load_dataset(cfg):\n","    train_df = pd.read_csv(cfg.train_csv, nrows= 100 if cfg.debug else None)\n","    test_df = pd.read_csv(cfg.test_csv)\n","    external_mlqa_df = pd.read_csv(cfg.mlqa_hindi_csv)\n","    external_xquad_df = pd.read_csv(cfg.xquad_hindi_csv)\n","    external_tamil_xquad_df = pd.read_csv(cfg.xquad_tamil_csv)\n","    external_tamil_xquad_df['language'] = \"tamil\"\n","    external_tamil_xquad_df[\"answer_start\"] = external_tamil_xquad_df[\"answer_start\"].astype(int)\n","    external_train_df = pd.concat([\n","                                   external_mlqa_df, \n","                                   external_xquad_df, \n","                                   external_tamil_xquad_df\n","                                   ], axis=0).reset_index(drop=True)\n","    sample_submission_df = pd.read_csv(cfg.sample_submission_csv)\n","\n","    return train_df, test_df, external_train_df, sample_submission_df\n","\n","\n","def get_split(cfg):\n","    split_name = cfg.split_name\n","    split_params = cfg.split_params\n","\n","    return sms.__getattribute__(split_name)(**split_params)\n","\n","\n","def get_fold(cfg, train_df: pd.DataFrame, y_train: pd.DataFrame):\n","    splitter = get_split(cfg)\n","    train_df[\"fold\"] = -1\n","    for fold_id, (train_idx, valid_idx) in enumerate(splitter.split(train_df, y_train)):\n","        train_df.loc[valid_idx, \"fold\"] = int(fold_id)\n","\n","    return train_df\n","\n","\n","def convert_answers(row):\n","    return {\"answer_start\": [row[0]], \"text\": [row[1]]}\n","\n","\n","def jaccard(str1, str2):\n","    a = set(str1.lower().split())\n","    b = set(str2.lower().split())\n","    c = a.intersection(b)\n","\n","    return float(len(c)) / (len(a) + len(b) - len(c))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RBsFiLLN5EVr"},"source":["## load data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":585},"id":"AwmhgEfk4vR8","executionInfo":{"elapsed":810,"status":"ok","timestamp":1636823750088,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"},"user_tz":-540},"outputId":"29d32c00-4ff5-419d-fe88-6dd56eb6bc70"},"source":["train_df, test_df, external_train_df, sample_submission_df = load_dataset(cfg)\n","\n","train_df = get_fold(cfg, train_df, train_df[\"language\"])\n","\n","external_train_df[\"fold\"] = -1\n","external_train_df[\"id\"] = list(np.arange(1, len(external_train_df) + 1))\n","train_df = pd.concat([train_df, external_train_df], axis=0).reset_index(drop=True)\n","\n","# 改行文字の削除\n","# train_df[\"context\"] = train_df[\"context\"].apply(lambda x: \" \".join(x.split()))\n","# train_df[\"question\"] = train_df[\"question\"].apply(lambda x: \" \".join(x.split()))\n","\n","train_df[\"answers\"] = train_df[[\"answer_start\", \"answer_text\"]].apply(convert_answers, axis=1)\n","train_df"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>answer_text</th>\n","      <th>answer_start</th>\n","      <th>language</th>\n","      <th>fold</th>\n","      <th>answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>903deec17</td>\n","      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n","      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n","      <td>206</td>\n","      <td>53</td>\n","      <td>tamil</td>\n","      <td>9</td>\n","      <td>{'answer_start': [53], 'text': ['206']}</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>d9841668c</td>\n","      <td>காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...</td>\n","      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n","      <td>காசுமீரில்</td>\n","      <td>2358</td>\n","      <td>tamil</td>\n","      <td>0</td>\n","      <td>{'answer_start': [2358], 'text': ['காசுமீரில்']}</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29d154b56</td>\n","      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n","      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n","      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n","      <td>0</td>\n","      <td>tamil</td>\n","      <td>3</td>\n","      <td>{'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>41660850a</td>\n","      <td>குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...</td>\n","      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n","      <td>தாலாட்டு</td>\n","      <td>68</td>\n","      <td>tamil</td>\n","      <td>1</td>\n","      <td>{'answer_start': [68], 'text': ['தாலாட்டு']}</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>b29c82c22</td>\n","      <td>சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...</td>\n","      <td>பூமியின் அருகில் உள்ள விண்மீன் எது?</td>\n","      <td>சூரியனும்</td>\n","      <td>585</td>\n","      <td>tamil</td>\n","      <td>5</td>\n","      <td>{'answer_start': [585], 'text': ['சூரியனும்']}</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11291</th>\n","      <td>10178</td>\n","      <td>எமிட் அரசாங்கத்தின் பணி மற்றும் நோக்கங்களை ஆதர...</td>\n","      <td>மாணவர்களின் எண்ணிக்கை என்ன?</td>\n","      <td>50</td>\n","      <td>421</td>\n","      <td>tamil</td>\n","      <td>-1</td>\n","      <td>{'answer_start': [421], 'text': ['50']}</td>\n","    </tr>\n","    <tr>\n","      <th>11292</th>\n","      <td>10179</td>\n","      <td>தஜிகிஸ்தான்(I /tɑːdʒiːkᵻstɑːn/, /tədʒiːkᵻstæn/...</td>\n","      <td>தஜிகிஸ்தானில் எத்தனை பேர் கணக்கிடப்படுகிறார்கள்?</td>\n","      <td>8 மில்லியன்</td>\n","      <td>353</td>\n","      <td>tamil</td>\n","      <td>-1</td>\n","      <td>{'answer_start': [353], 'text': ['8 மில்லியன்']}</td>\n","    </tr>\n","    <tr>\n","      <th>11293</th>\n","      <td>10180</td>\n","      <td>டீனேஜர் சஞ்சய மலகார் தனது அசாதாரணமான ஹேர்டோவிற...</td>\n","      <td>சஞ்சய மலகார் அமெரிக்க சிலை மீது நீக்கப்பட்டதை ...</td>\n","      <td>ஏப்ரல் 18</td>\n","      <td>143</td>\n","      <td>tamil</td>\n","      <td>-1</td>\n","      <td>{'answer_start': [143], 'text': ['ஏப்ரல் 18']}</td>\n","    </tr>\n","    <tr>\n","      <th>11294</th>\n","      <td>10181</td>\n","      <td>\"இஸ்லாமிய தத்துவத்திற்கான\" பொதுவான வரையறைகளில்...</td>\n","      <td>இபின் சினாவால் எத்தனை புத்தகங்கள் எழுதப்பட்டுள...</td>\n","      <td>450</td>\n","      <td>334</td>\n","      <td>tamil</td>\n","      <td>-1</td>\n","      <td>{'answer_start': [334], 'text': ['450']}</td>\n","    </tr>\n","    <tr>\n","      <th>11295</th>\n","      <td>10182</td>\n","      <td>அவரது எதிரிகள் ஹேக்கை \"Neoleiberalmismism\" ஒரு...</td>\n","      <td>ஹெயெக்கின் அரசியலமைப்பை சுதந்திரத்தின் அரசியலம...</td>\n","      <td>சாமுவேல் பிரிட்டன்</td>\n","      <td>103</td>\n","      <td>tamil</td>\n","      <td>-1</td>\n","      <td>{'answer_start': [103], 'text': ['சாமுவேல் பிர...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11296 rows × 8 columns</p>\n","</div>"],"text/plain":["              id  ...                                            answers\n","0      903deec17  ...            {'answer_start': [53], 'text': ['206']}\n","1      d9841668c  ...   {'answer_start': [2358], 'text': ['காசுமீரில்']}\n","2      29d154b56  ...  {'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...\n","3      41660850a  ...       {'answer_start': [68], 'text': ['தாலாட்டு']}\n","4      b29c82c22  ...     {'answer_start': [585], 'text': ['சூரியனும்']}\n","...          ...  ...                                                ...\n","11291      10178  ...            {'answer_start': [421], 'text': ['50']}\n","11292      10179  ...   {'answer_start': [353], 'text': ['8 மில்லியன்']}\n","11293      10180  ...     {'answer_start': [143], 'text': ['ஏப்ரல் 18']}\n","11294      10181  ...           {'answer_start': [334], 'text': ['450']}\n","11295      10182  ...  {'answer_start': [103], 'text': ['சாமுவேல் பிர...\n","\n","[11296 rows x 8 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"WcJnS8s25JLn"},"source":["## preprocess"]},{"cell_type":"code","metadata":{"id":"nxgeHj2A82w0"},"source":["def prepare_train_features(cfg, example, tokenizer):\n","    example[\"question\"] = example[\"question\"].lstrip()\n","\n","    tokenized_example = tokenizer(\n","        example[\"question\"],\n","        example[\"context\"],\n","        truncation=cfg.truncation,\n","        max_length=cfg.max_seq_length,\n","        stride=cfg.doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=cfg.padding,\n","        # return_tensors=\"pt\"\n","    )\n","\n","    sample_mapping = tokenized_example.pop(\"overflow_to_sample_mapping\")\n","    offset_mapping = tokenized_example.pop(\"offset_mapping\")\n","\n","    features = []\n","    for i, offsets in enumerate(offset_mapping):\n","        feature = {}\n","\n","        input_ids  = tokenized_example[\"input_ids\"][i]\n","        attention_mask = tokenized_example[\"attention_mask\"][i]\n","\n","        feature[\"input_ids\"] = input_ids\n","        feature[\"attention_mask\"] = attention_mask\n","        feature[\"offset_mapping\"] = offsets\n","        feature[\"example_id\"] = example[\"id\"]\n","        feature[\"sequence_ids\"] = [0 if i is None else i for i in tokenized_example.sequence_ids(i)]\n","\n","        cls_index = input_ids.index(tokenizer.cls_token_id) # cls_token_id = 0, pad_token_id = 1\n","        sequence_ids = tokenized_example.sequence_ids(i)\n","\n","        # sample_indx = sample_mapping[i]\n","        answers = example[\"answers\"]\n","\n","        if len(answers[\"answer_start\"]) == 0: # sampleにanswerがなければ開始・終了位置をCLS(=[CLS], <s>)にする\n","            feature[\"start_position\"] = cls_index\n","            feature[\"end_position\"] = cls_index\n","        else:\n","            start_char = answers[\"answer_start\"][0] # answer部分の文字レベルの開始位置\n","            end_char = start_char + len(answers[\"text\"][0]) # answer部分の文字レベルの終了位置\n","\n","            token_start_index = 0 # sequenceにおけるcontext部分のトークンレベルの開始位置\n","            while sequence_ids[token_start_index] != 1: # sequence_idsが1(=context部分)になるまで足す(<s>,</s>, querstion部分を飛ばすイメージ)\n","                token_start_index += 1\n","\n","            token_end_index = len(input_ids) - 1 # sequenceにおけるcontext部分のトークンレベルの終了位置\n","            while sequence_ids[token_end_index] != 1: # sequence_idsが1(=context部分)になるまで引く(paddingはNoneなので<pad>部分を引くイメージ)\n","                token_end_index -= 1\n","\n","            # token_start_index, token_end_indexがanswer部分の範囲外にあればpositionを0(=[CLS], <s>)とする(truncationされてる場合はこっち)\n","            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n","                feature[\"start_position\"] = cls_index\n","                feature[\"end_position\"] = cls_index\n","            # star_char, end_charを含むtokenまでtoken_start_index, token_end_indexを調整\n","            else:\n","                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n","                    token_start_index += 1\n","                feature[\"start_position\"] = token_start_index - 1 # 行き過ぎた1token分戻す\n","\n","                while offsets[token_end_index][1] >= end_char:\n","                    token_end_index -= 1\n","                feature[\"end_position\"] = token_end_index + 1 # 行き過ぎた1token分戻す\n","\n","        features.append(feature)\n","\n","    return features\n","\n","\n","def prepare_test_features(cfg, example, tokenizer):\n","    example[\"question\"] = example[\"question\"].lstrip()\n","\n","    tokenized_example = tokenizer(\n","        example[\"question\"],\n","        example[\"context\"],\n","        truncation=cfg.truncation,\n","        max_length=cfg.max_seq_length,\n","        stride=cfg.doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=cfg.padding,\n","        # return_tensors=\"pt\"\n","    )\n","\n","    features = []\n","    for i in range(len(tokenized_example[\"input_ids\"])):\n","        feature = {}\n","        feature[\"example_id\"] = example[\"id\"]\n","        feature[\"context\"] = example[\"context\"]\n","        feature[\"question\"] = example[\"question\"]\n","        feature[\"input_ids\"] = tokenized_example[\"input_ids\"][i]\n","        feature[\"attention_mask\"] = tokenized_example[\"attention_mask\"][i]\n","        feature[\"offset_mapping\"] = tokenized_example[\"offset_mapping\"][i]\n","        feature[\"sequence_ids\"] = [0 if i is None else i for i in tokenized_example.sequence_ids(i)]\n","        features.append(feature)\n","\n","    return features\n","\n","\n","def postprocess_qa_predictions(tokenizer, examples: pd.DataFrame, features, raw_predictions, n_best_size=20, max_answer_length=30):\n","    '''予測値の後処理関数\n","    '''\n","    all_start_logits, all_end_logits = raw_predictions\n","\n","    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])} # dataframeのidをkeyとしたindexのmapping用dict\n","    features_per_example = defaultdict(list) # dataframeのidに対応するexample_id_to_indexのidをkeyとしたdict。valueはfeaturesに対応するidのリスト\n","    for i, feature in enumerate(features):\n","        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","\n","    predictions = OrderedDict()\n","    # print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n","\n","    for example_index, example in examples.iterrows():\n","        feature_indices = features_per_example[example_index] # 対応するfeaturesのindexを取り出す\n","\n","        # min_null_score = None\n","        valid_answers = []\n","\n","        context = example[\"context\"]\n","        for feature_index in feature_indices:\n","            start_logits = all_start_logits[feature_index]\n","            end_logits = all_end_logits[feature_index]\n","\n","            sequence_ids = features[feature_index][\"sequence_ids\"]\n","            context_index = 1 # contextのsequence_id(questionは0)\n","            \n","            # contextのみoffset_mappingを保持(questionのoffset_mappingをNoneに)\n","            features[feature_index][\"offset_mapping\"] = [\n","                (o if sequence_ids[k] == context_index else None)\n","                for k, o in enumerate(features[feature_index][\"offset_mapping\"])\n","            ]\n","            offset_mapping = features[feature_index][\"offset_mapping\"]\n","            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n","\n","            # feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n","            # if min_null_score is None or min_null_score < feature_null_score:\n","            #     min_null_score = feature_null_score\n","\n","            # start_indexes = np.argsort(start_logits)[-1: -n_best_size - 1: -1].tolist()\n","            # end_indexes = np.argsort(end_logits)[-1: -n_best_size - 1: -1].tolist()\n","            start_indexes = np.argsort(start_logits)[::-1][:n_best_size].tolist()\n","            end_indexes = np.argsort(end_logits)[::-1][:n_best_size].tolist()\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    if (\n","                        start_index >= len(offset_mapping)\n","                        or end_index >= len(offset_mapping)\n","                        or offset_mapping[start_index] is None\n","                        or offset_mapping[end_index] is None\n","                    ):\n","                        continue\n","                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n","                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n","                        continue\n","\n","                    start_char = offset_mapping[start_index][0]\n","                    end_char = offset_mapping[end_index][1]\n","                    valid_answers.append(\n","                        {\n","                            \"score\": start_logits[start_index] + end_logits[end_index],\n","                            \"text\": context[start_char: end_char]\n","                        }\n","                    )\n","        # 各レコード・チャンク(feature)におけるstart+end出力値のスコアが最も大きいペアを最終的な予測値とする\n","        if len(valid_answers) > 0:\n","            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n","        else:\n","            best_answer = {\"text\": \"\", \"score\": 0.0}\n","\n","        predictions[example[\"id\"]] = best_answer[\"text\"]\n","\n","    return predictions\n","\n","\n","def postprocess_cleaned_predictions(input_df: pd.DataFrame):\n","    bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\n","    bad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n","\n","    tamil_ad = \"கி.பி\"\n","    tamil_bc = \"கி.மு\"\n","    tamil_km = \"கி.மீ\"\n","    hindi_ad = \"ई\"\n","    hindi_bc = \"ई.पू\"\n","\n","\n","    cleaned_preds = []\n","    for pred, context in input_df[[\"PredictionString\", \"context\"]].to_numpy():\n","        if pred == \"\":\n","            cleaned_preds.append(pred)\n","            continue\n","        while any([pred.startswith(y) for y in bad_starts]):\n","            pred = pred[1:]\n","        while any([pred.endswith(y) for y in bad_endings]):\n","            if pred.endswith(\"...\"):\n","                pred = pred[:-3]\n","            else:\n","                pred = pred[:-1]\n","        if pred.endswith(\"...\"):\n","                pred = pred[:-3]\n","\n","        if any([pred.endswith(tamil_ad), pred.endswith(tamil_bc), pred.endswith(tamil_km), pred.endswith(hindi_ad), pred.endswith(hindi_bc)]) and pred+\".\" in context:\n","            pred = pred+\".\"\n","\n","        cleaned_preds.append(pred)\n","        \n","    return cleaned_preds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3nn0RX0BicrZ"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"OHSxITfLa9y8"},"source":["class ChaiiDataset(Dataset):\n","    def __init__(self, features, phase):\n","        super(ChaiiDataset, self).__init__()\n","        self.features = features\n","        self.phase = phase\n","        \n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, index):\n","        feature = self.features[index]\n","        # segment_target = torch.zeros(400, dtype=torch.long)\n","        # segment_target[feature[\"start_position\"]: feature[\"end_position\"] + 1] = 1\n","\n","        if self.phase == \"train\":\n","            return {\n","                \"input_ids\": torch.tensor(feature[\"input_ids\"], dtype=torch.long),\n","                \"attention_mask\": torch.tensor(feature[\"attention_mask\"], dtype=torch.long),\n","                \"offset_mapping\": torch.tensor(feature[\"offset_mapping\"], dtype=torch.long),\n","                \"start_position\": torch.tensor(feature[\"start_position\"], dtype=torch.long),\n","                \"end_position\": torch.tensor(feature[\"end_position\"], dtype=torch.long),\n","                # \"segment_target\": segment_target,\n","            }\n","        else:\n","            return {\n","                \"input_ids\": torch.tensor(feature[\"input_ids\"], dtype=torch.long),\n","                \"attention_mask\": torch.tensor(feature[\"attention_mask\"], dtype=torch.long),\n","                \"offset_mapping\": torch.tensor(feature[\"offset_mapping\"], dtype=torch.long),\n","                \"sequence_ids\": feature[\"sequence_ids\"],\n","                \"id\": feature[\"example_id\"],\n","                \"context\": feature[\"context\"],\n","                \"question\": feature[\"question\"],\n","            }\n","\n","\n","class ChaiiDataModule(pl.LightningDataModule):\n","    def __init__(self, cfg, tokenizer, input_df: pd.DataFrame, phase: str, fold: int = 0):\n","        super(ChaiiDataModule, self).__init__()\n","        self.cfg = cfg\n","        self.tokenizer = tokenizer\n","        self.input_df = input_df\n","        self.phase = phase\n","        self.fold = fold\n","\n","    def get_train_features(self, cfg, input_df, tokenizer):\n","        features = []\n","        for i, row in tqdm(input_df.iterrows(), total=len(input_df), desc=\"[get features]\"):\n","            features += prepare_train_features(cfg, row, tokenizer)\n","        \n","        return features\n","\n","    def get_test_features(self, cfg, input_df, tokenizer):\n","        features = []\n","        for i, row in tqdm(input_df.iterrows(), total=len(input_df), desc=\"[get features]\"):\n","            features += prepare_test_features(cfg, row, tokenizer)\n","        \n","        return features\n","\n","    def setup(self, stage=None):\n","        assert self.phase in (\"train\", \"test\"), \"Input phase is not exist.\"\n","        if self.phase == \"train\":\n","            self.train_df = self.input_df[self.input_df[\"fold\"] != self.fold].reset_index(drop=True)\n","            self.valid_df = self.input_df[self.input_df[\"fold\"] == self.fold].reset_index(drop=True)\n","\n","            self.train_features = self.get_train_features(self.cfg, self.train_df, self.tokenizer)\n","            self.valid_features = self.get_train_features(self.cfg, self.valid_df, self.tokenizer)\n","\n","            self.train_dataset = ChaiiDataset(self.train_features, self.phase)\n","            self.valid_dataset = ChaiiDataset(self.valid_features, self.phase)\n","            print(f\"Number of train features: {len(self.train_dataset)}, Number of valid features: {len(self.valid_dataset)}\")\n","        elif self.phase == \"test\":\n","            self.test_features = self.get_test_features(self.cfg, self.input_df, self.tokenizer)\n","            self.test_dataset = ChaiiDataset(self.test_features, self.phase)\n","            print(f\"Number of test features: {len(self.test_dataset)}\")\n","        else:\n","            raise NotImplementedError\n","        \n","    def train_dataloader(self):\n","        train_sampler = RandomSampler(self.train_dataset)\n","        return DataLoader(self.train_dataset, batch_size=self.cfg.train_batch_size, num_workers=self.cfg.num_workers, pin_memory=True, drop_last=False, sampler=train_sampler)\n","\n","    def val_dataloader(self):\n","        valid_sampler = SequentialSampler(self.valid_dataset)\n","        return DataLoader(self.valid_dataset, batch_size=self.cfg.valid_batch_size, num_workers=self.cfg.num_workers, pin_memory=True, drop_last=False, sampler=valid_sampler)\n","\n","    def predict_dataloader(self):\n","        return DataLoader(self.test_dataset, batch_size=self.cfg.test_batch_size, num_workers=self.cfg.num_workers, pin_memory=True, shuffle=False, drop_last=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HhzSnmitfua7"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"IcStqJUDfees"},"source":["class ChaiiModel(nn.Module):\n","    def __init__(self, cfg):\n","        super(ChaiiModel, self).__init__()\n","        self.cfg = cfg\n","        self.model_config = AutoConfig.from_pretrained(self.cfg.base_model_config)\n","        self.encoder = AutoModel.from_pretrained(self.cfg.base_model_name, config=self.model_config)\n","        self.classifier = nn.Linear(self.model_config.hidden_size, cfg.num_classes)\n","        self._init_header_weights(self.classifier)\n","        # self._init_roberta_weights(self.encoder)\n","\n","    def _init_header_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","\n","    def _init_roberta_weights(self, model):\n","        for layer in model.encoder.layer[-cfg.init_layers:]:\n","            for module in layer.modules():\n","                if isinstance(module, nn.Linear):\n","                    module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n","                    if module.bias is not None:\n","                        module.bias.data.zero_()\n","                elif isinstance(module, nn.Embedding):\n","                    module.weight.data.normal_(mean=0.0, std=self.base_model.config.initializer_range)\n","                    if module.padding_idx is not None:\n","                        module.weight.data[module.padding_idx].zero_()\n","                elif isinstance(module, nn.LayerNorm):\n","                    module.bias.data.zero_()\n","                    module.weight.data.fill_(1.0)\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        output = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n","        x = self.classifier(output[0]) # (batch_size, hidden_size, num_classes)\n","        x0, x1 = x.split(1, dim=-1) # (batch_size, hidden_size, 1)\n","        start_logits, end_logits = x0.squeeze(-1), x1.squeeze(-1) # (batch_size, hidden_size)\n","\n","        return start_logits, end_logits\n","\n","\n","# model = ChaiiModel(cfg)\n","# summary(model, torch.zeros(1, 400, dtype=torch.long))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lZ15q-gb5DiO"},"source":["## training"]},{"cell_type":"code","metadata":{"id":"8mKGz0xAqy3L"},"source":["def get_optimizer_grouped_parameters(cfg, model):\n","    no_decay = cfg.no_decay\n","    # header layerのweight_decay, lr\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if \"classifier\" in n],\n","            \"weight_decay\": cfg.header_weight_decay,\n","            \"lr\": cfg.header_lr\n","        },\n","    ]\n","\n","    # num_layers = model.base_model.config.num_hidden_layers\n","    layers = [getattr(model, \"base_model\").embeddings] + list(getattr(model, \"base_model\").encoder.layer)\n","    layers.reverse()\n","    lr = cfg.optimizer_params[\"lr\"]\n","    \n","    for layer in layers:\n","        lr *= cfg.lr_decay\n","        optimizer_grouped_parameters += [\n","            # no_decayのリストに含まれないパラメータはweight decayを設定\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": cfg.optimizer_params[\"weight_decay\"],\n","                \"lr\": lr,\n","            },\n","            # no_decayのリストに含まれるパラメータはweight decayを設定しない\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            }\n","        ]\n","    \n","    return optimizer_grouped_parameters\n","\n","\n","def get_criterion(cfg):\n","    loss_name = cfg.loss_name\n","    loss_params = cfg.loss_params\n","    return nn.__getattribute__(loss_name)(**loss_params)\n","\n","\n","def get_optimizer(cfg, model=None, optimizer_grouped_parameters=None):\n","    optimizer_name = cfg.optimizer_name\n","    optimizer_params = cfg.optimizer_params\n","\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": cfg.optimizer_params[\"weight_decay\"],\n","        },\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","\n","    if optimizer_name == \"AdamW\":\n","        return AdamW(\n","            optimizer_grouped_parameters,\n","            **optimizer_params\n","        )\n","    else:\n","        return optim.__getattribute__(optimizer_name)(model.parameters(), **optimizer_params)\n","\n","\n","def get_scheduler(cfg, optimizer, num_warmup_steps=None, num_training_steps=None):\n","    scheduler_name = cfg.scheduler_name\n","    scheduler_params = cfg.scheduler_params\n","\n","    if scheduler_name == \"cosine-warmup\":\n","        return get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","        )\n","    elif scheduler_name == \"linear-warmup\":\n","        return get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","        )\n","    # elif scheduler_name not in (\"cosine-warmup\", \"linear-warmup\"):\n","    #     return optim.lr_scheduler.__getattribute__(scheduler_name)(optimizer, **scheduler_params)\n","\n","\n","class ChaiiLightningModule(pl.LightningModule):\n","    def __init__(self, cfg):\n","        super(ChaiiLightningModule, self).__init__()\n","        self.cfg = cfg\n","        self.model = ChaiiModel(self.cfg)\n","        self.start_criterion = get_criterion(self.cfg)\n","        self.end_criterion = get_criterion(self.cfg)\n","        self.train_mean_metric = MeanMetric()\n","        self.valid_mean_metric = MeanMetric()\n","\n","    def forward(self, input_ids, attention_mask):\n","        output_start, output_end = self.model(input_ids, attention_mask)\n","        return output_start, output_end\n","\n","    def training_step(self, batch, batch_idx):\n","        input_ids, attention_mask, target_start, target_end = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"start_position\"], batch[\"end_position\"]\n","        output_start, output_end = self.forward(input_ids, attention_mask)\n","\n","        # CrossEntropyLoss\n","        loss_start = self.start_criterion(output_start, target_start)\n","        loss_end = self.end_criterion(output_end, target_end)\n","        loss = (loss_start + loss_end) / 2\n","\n","        self.train_mean_metric.update(loss)\n","        loss_avg = self.train_mean_metric.compute()\n","\n","        self.log(\"train/loss\", loss_avg, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"train/loss_start_epoch\", loss_start.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"train/loss_end_epoch\", loss_end.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        input_ids, attention_mask, target_start, target_end = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"start_position\"], batch[\"end_position\"]\n","        output_start, output_end = self.forward(input_ids, attention_mask)\n","\n","        # CrossEntropyLoss\n","        loss_start = self.start_criterion(output_start, target_start)\n","        loss_end = self.end_criterion(output_end, target_end)\n","        loss = (loss_start + loss_end) / 2\n","\n","        self.valid_mean_metric.update(loss)\n","        loss_avg = self.valid_mean_metric.compute()\n","\n","        self.log(\"val/loss\", loss_avg, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"val/loss_start_epoch\", loss_start.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","        self.log(\"val/loss_end_epoch\", loss_end.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","\n","        outputs = OrderedDict({\n","            \"start_logits\": output_start.detach(),\n","            \"end_logits\": output_end.detach(),\n","        }\n","        )\n","\n","        return outputs\n","\n","    def validation_epoch_end(self, outputs):\n","        pred_start = torch.cat([output[\"start_logits\"] for output in outputs]).cpu().numpy()\n","        pred_end = torch.cat([output[\"end_logits\"] for output in outputs]).cpu().numpy()\n","\n","        preds = postprocess_qa_predictions(\n","            self.trainer.datamodule.tokenizer,\n","            self.trainer.datamodule.valid_df,\n","            copy.deepcopy(self.trainer.datamodule.valid_features[:pred_start.shape[0]]),\n","            (pred_start, pred_end)\n","        )\n","        jaccard_score = np.mean([jaccard(x, y) for x, y in zip(self.trainer.datamodule.valid_df[\"answer_text\"].values, preds.values())], axis=0)\n","\n","        self.log(\"val/jaccard_epoch\", jaccard_score, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n","        input_ids, attention_mask = batch[\"input_ids\"], batch[\"attention_mask\"]\n","        output_start, output_end = self.forward(input_ids, attention_mask)\n","\n","        outputs = OrderedDict({\n","            \"start_logits\": output_start,\n","            \"end_logits\": output_end,\n","        }\n","        )\n","\n","        return outputs\n","\n","    def configure_optimizers(self):\n","        # optimizer_grouped_parameters = get_optimizer_grouped_parameters(self.cfg, self.model)\n","        optimizer = get_optimizer(\n","            self.cfg,\n","            self.model,\n","            # optimizer_grouped_parameters=optimizer_grouped_parameters\n","        )\n","\n","        num_training_steps = math.ceil(len(self.trainer.datamodule.train_dataloader()) / self.trainer.accumulate_grad_batches) * self.trainer.max_epochs\n","        # num_training_steps = len(self.trainer.datamodule.train_dataloader()) * self.trainer.max_epochs\n","        if self.cfg.scheduler_params[\"warmup_ratio\"] > 0:\n","            num_warmup_steps = int(num_training_steps * self.cfg.scheduler_params[\"warmup_ratio\"])\n","        else:\n","            num_warmup_steps = 0\n","        scheduler = get_scheduler(self.cfg, optimizer, num_warmup_steps, num_training_steps)\n","        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n","        print(f\"Total Training Steps: {num_training_steps}, Total Warmup Steps: {num_warmup_steps}\")\n","\n","        return [optimizer], [scheduler]\n","\n","\n","def run_fold(cfg, train_df, fold, tokenizer):\n","    seed_everything(cfg.seed)\n","    checkpoint_path = cfg.checkpoint_dir + \"/\" + cfg.exp_name\n","\n","    if not os.path.exists(checkpoint_path):\n","        os.makedirs(checkpoint_path)\n","\n","    checkpoint_callback = ModelCheckpoint(\n","        dirpath=checkpoint_path,\n","        filename=f\"{cfg.exp_name}-fold-{fold}\" + \"-{epoch}\",\n","        **cfg.model_checkpoint_params,\n","    )\n","\n","    early_stopping_callback = EarlyStopping(**cfg.early_stopping_params)\n","\n","    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n","\n","    wandb_logger = WandbLogger(\n","        name=f\"{cfg.exp_name}_fold_{fold}\",\n","        **cfg.wandb_logger_params,\n","    )\n","\n","    trainer = Trainer(\n","        default_root_dir=cfg.checkpoint_dir,\n","        gpus=cfg.gpus,\n","        max_epochs=cfg.num_epochs,\n","        accumulate_grad_batches=cfg.grad_accumulate,\n","        precision=16 if cfg.fp16 else 32,\n","        callbacks=[\n","            checkpoint_callback,\n","            # early_stopping_callback,\n","            lr_monitor,\n","        ],\n","        logger=[\n","            wandb_logger,\n","        ],\n","        log_every_n_steps=10,\n","    )\n","\n","    model = ChaiiLightningModule(cfg)\n","    datamodule = ChaiiDataModule(cfg, tokenizer=tokenizer, input_df=train_df, phase=\"train\", fold=fold)\n","    trainer.fit(model, datamodule=datamodule)\n","\n","    wandb.finish()\n","\n","    del trainer, model, datamodule\n","    gc.collect()\n","\n","    return checkpoint_callback.best_model_path, checkpoint_callback.best_model_score.item()\n","\n","\n","def run_training(cfg, train_df):\n","    tokenizer = AutoTokenizer.from_pretrained(cfg.tokenizer_name)\n","\n","    checkpoint_path_list = []\n","    # oof_score = 0\n","\n","    for fold_id in range(cfg.split_params[\"n_splits\"]):\n","        checkpoint_path, best_score = run_fold(cfg, train_df, fold_id, tokenizer)\n","        checkpoint_path_list.append(checkpoint_path)\n","        # oof_score += best_score / int(cfg.split_params[\"n_splits\"])\n","\n","    # print(\"CV jaccard score :\", oof_score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":798,"referenced_widgets":["c69e8425a2584f5ab5dcb82dd88147be","8f3ae0d4b61b400cb93082a8675897d1","349685e1b2e94484a68bdabef71c6eb1","bc384e9daebf478781beb3d6c3683ba3","5a03d179b69d4626b7d1d6ec2b59a6e5","21ab2d533a7e47d589c8d2150f16ab05","bb1b94e9922c43ea8964cd5f7c7997fd","25a2eeba7d044e92a57d422af76af4e4","69c6ea4d5e0e4dfebcd22a370e3917d3","52591667acd64755b1274f0a93d07707","846e78edf53f470dbe420eba11a5bef7","98e540baa2dd4c95a8d180ae3839dd64","b2aed5fdb6df4eb8bbaa6b8eb1e682ef","a68c0ce8ce8342c98fad211b2402af98","05bff16960d749e9837ebf0db807a827","cf1fd838d0d14b6fa5ae70a6f3bffc0e","5aec567fa4144606bb3818a84130bfff","77e0e6427446499ba4915587065158f2","201e7d5499b84d6db6ce1c9966ee0f2f","4389d10979074aaabff9f3e184a6d406","61a54eac4d4f4b6dadf35dfc18e52487","1a200148451349a992a87190b6bbe00f","a8f7fb80aa174bb5802c8271b8181a93","c72c366b2a5b4349be7ee2758eab8cfc","ba748241a6eb43aab715645d8c30380d","74e99a3a936e489c880b5a6a81bbeda9","c0ea4fe9f2a340ea8f22d5e521c89320","06a89907255748958454063a13fb272e","4af9119a020844c0a1190bc956ebd895","3337332405604993b19b1cf9c497d037","9b48d9cf9df54a5eb501041b2d8b3b50","6e64fcfc72c2435d951a74591343b272","00b7cb7553234a849322c2c1deba9953","e62e81be170d40c5aabd60a1c4ad84f6","6afb2a84be2a4bb18ea58de232345c51","f50a84e74d2d4884aee6240151a18992","98afc3bba61e48d6b2cc84edfd7e94fc","23701b33f1da4c319eb1647c70210e8f","5dafbc2844864db3a47ea273f92de9bd","b9b30012b70447fd814c98ca7c1a5a67","9f142c2f30384631a2d0ac96f7e86870","59cafbf8e4d9442db6c2d74f40ee0995","38dce763494748c78d288488d420d007","dfd5910a32c14115b447300c16c7bbb7","84c793e5d7de47adacf85830bc158b22","54d7a491e63e488c89d186636d1bc431","052f60cfbec1475f91a9c1655ffa4986","26e41b5d388f4846bea678edd04e273b","d924f49511864ba8b6db5307e13ded30","f9d99da367a84069a70f14e4ddb1dce5","0db5474a07064c42ac0e6885399ea52a","0e20b343c0aa4615b16c8508b093a48a","def0a686e8ae4cd283d70cf8a710e4d0","eaeebc94fcab4a44b511ee6c7fc779dc","5ad2c1df4a584dcb976a49ee55133b48","d459a4d50166414ea91b1352e31b4882","5ec318ff763c49d485cb193aae01da5f","a08ea408be4b40e899a72ba211ffaf18","b22d333861074b238660a9caf210793e","7db4a83dc44b4e5ba5d7a29f65634afa","4328fb76be8547da9191189ce144a471","ae1a8a95804c4df7b4965626ee787ca9","551716b161a944b5a6e0a6b33dbb9681","f90b044a2c6046b88d1775d6a53b234c","604ecf57471f44ddb7419e6c53986fed","2935aed131e449d898931c98a9c1bbaf","2f1f365223924b6293b93ee2f428ea28","743563ddde8c4415966ec386c91be58b","ae2622fca0824ccaabf6d51764f30b5c","7266483c2673489a8dc2392f09ff28d8","06d41f9f8b7445ff8439810f69a12050","e1a51c61427646a89024c333c8e91230","c44e80f209644c9884f94ceb6d71eec8","8b53c7ffbc4c45b6b8b61361b7e837d0","a2dedb70d7974dc18d3e3138c6e20777","417b9283b8534f53a436e530e6ff8c1c","9144eb8d968f49d1b849f393ba52e195","ed7fb1f0d66b4d289061ec98c0f87069","ffe1206ac9a44366ab122252e0cdb894","3b6afb481d4549409f7f2676b70bd7de","4e7861a73f0f422083da3fb46dc41eb4","ac9a192a4c5a41a7a5b9e6d41916be05","a6e8140d1fef49c183d894ea788eb734","5f309c5122c84ef69ff2175416a99e88","788de8c2637d41f4906a1686cf537b53","c48dcd5617fc49ab851f4fe3c501080b","85593c6fb0654cb38e10177c2509afef","a8d5ead2d44e4ac09dea75a73255823f","1aae64dcf92a4547948418e583ff483f","b70fa2e3c01c4ccb90b54e13c84b2057","9d07772c57ab41a9bd093970e59cb7fd","7af412357cdf473685e51c20ef2ce15e","de0e858e867b4079aaa4539daa1f8732","a631250e1e494c86baa7ce136a71bdbd","bb67970c2d9a403f8ed9081fae3ce701","ad31869717504011b69f321fb0964f32","7bc14b174cec4bfdbe80272ab0c73c23","77ae6bd52ed845bfa00b5a3783592ff7","89691547b77940a9b9c95a64ab346447","9e183e5e01b64fd3b608db98fae5e609","cbd4cd6f23f04ee4b88e514b7341d6dc","a4e67c52abcd4576ad93cb511a33a8d0","8b831ee91fe8477fa5a0a61a0800c88a","b0783081fa334e31badb5d4b5c05582c","039fbf2f9f8d4763b1ede21a5dde9818","f46542aa81e54ba99c98884cda7df3d9","05625f96169249cb953c49e5a940ba36","e672c6c9190c4261acd9757cfa1b978a","28fcb690bba8460c9ff064553b7c80e7","d992e57909d94971a939530b6ea82534","63c17b34f12747c58a12914864fce0b1","6a769ccc7be543acbfd0110b8589f1ac","e3a9b355b45c4ddb951a6c68181ed296","5542cc2d008546a69a631fe02f15e922","ae1d850d0918441e9120fcbc36d04a77","6800f2a343034b6da3e46e5711912451","52b74d2dfd7049688a1a9dc427b6884d","9637a8a810e94a54aa400fbafc11a42b","ae0ae41f76ec4362b724be4898dfc9f4","4f3cff8f91a346e2b7d1847a3086f715","f74d9c38c1114b75a6630c6899c4b921","0096079c8bb94f539f0633905a7b88f5","a6fce85b50d849e2a654cef859440dcf","1b427c2b3c0a49b2ab143978c9fafed5","84cf762632934a4a9f70860b35a6d6b9","b0ddc54ba2ae46f180aa1114af20827a","50769c872b17454a831167c6002009dc","6d0879f4d87f4e6dba2b9e281b00e931","e4bed05484fb4821bddb68158e95225b","d955dfb5a3c944d083bb603bf4ba3391","8d44890fd28e43d08f173b0d7ddf77e5","36ff110db27d40c8ba7a851f5a5d4c4a","42ea3a28cf494027b4bb578ebcde964a","b440dc1f85c7419598f7041eb972846b","5c32b9cd8b96468aa8f53038688c4424","0449fc03ca154129bb8c75ea5fbc79dd","fe759a525e1349249befcbca61ebaeac","08f717838ae04f28929cbd07c7e4607e","0021f2409fea4511a417357745024740","0ec3c593054340f39519eac7f1d82afe","07a3c35d09714759a450e03098c8ccd1","61efbf2e48614866818942a66fcc9ccc","65e167fef0374d3691b6976178ca8020","ad3536d309d940d38bcd6f0cb58bf80c","8a954e8a09c44d5e9ef96e1bc1ed5ad5","67a7c4a0a1ba417f930f53fbd7959235","d4ce5325ada9433896952faade68abf8","9dbcaa1c12444d4bbfc24bd21f04686a","0c44ab73eab541aea9d80c3dc48dfd08","8c3f79b1b9144018bb1c93ab6f7806cc","d10191886f414bf0bd02d2b23d8da335","c8d5b215f0fd46eaacfbd8b065feabb9","ea1d0c82fafe430bb2d5096d5f06670b","fcf0d17e9dbd43dba6bd662204a07c9b","08c475d72fa340e0a8784ebbfdf7f212","d685ab6eebc34452ab5b9329bb7e85bc","ada66bfbf84f4526bcfb6b0da108ec97","04d14621024840e8b95505ebcabfe903","d569df3259ca405e9e4cb671d1ce0d8d","6e3d56ded1ca4220a38508e309d0aa8e","e2c6381da4d74b40abfca5f4242438bd","460e32b717154aac9c0bd09bdff161f8","78ce64815c064a4e9d33d548bbee5ab0","79452459dfbe4ad0865d69ab3eba4861","d93f8757788349048e845a2a2b69c994"]},"id":"hhGIfEKXBatS","outputId":"65c4190e-29d6-4f3b-a439-01b00fa7fc20"},"source":["# tokenizer = AutoTokenizer.from_pretrained(cfg.tokenizer_name)\n","# _, _ = run_fold(cfg, train_df, 0, tokenizer)\n","run_training(cfg, train_df)"],"execution_count":null,"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c69e8425a2584f5ab5dcb82dd88147be","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/179 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98e540baa2dd4c95a8d180ae3839dd64","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/606 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8f7fb80aa174bb5802c8271b8181a93","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e62e81be170d40c5aabd60a1c4ad84f6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84c793e5d7de47adacf85830bc158b22","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.09G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d459a4d50166414ea91b1352e31b4882","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/11184 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f1f365223924b6293b93ee2f428ea28","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/112 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 24592, Number of valid features: 1496\n","Total Training Steps: 8198, Total Warmup Steps: 819\n"]},{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/2mchcys0\" target=\"_blank\">exp025_fold_0</a></strong> to <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name              | Type             | Params\n","-------------------------------------------------------\n","0 | model             | ChaiiModel       | 559 M \n","1 | start_criterion   | CrossEntropyLoss | 0     \n","2 | end_criterion     | CrossEntropyLoss | 0     \n","3 | train_mean_metric | MeanMetric       | 0     \n","4 | valid_mean_metric | MeanMetric       | 0     \n","-------------------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed7fb1f0d66b4d289061ec98c0f87069","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1aae64dcf92a4547948418e583ff483f","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e183e5e01b64fd3b608db98fae5e609","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cbd4cd6f23f04ee4b88e514b7341d6dc","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 486... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4e67c52abcd4576ad93cb511a33a8d0","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>lr-AdamW/pg1</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss_end_epoch</td><td>█▁</td></tr><tr><td>train/loss_epoch</td><td>█▁</td></tr><tr><td>train/loss_start_epoch</td><td>█▁</td></tr><tr><td>train/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▁▁▅▅▅▅▅▆▆▆▆▆▇▇▇▇███▁▁▁</td></tr><tr><td>val/jaccard_epoch</td><td>█▁</td></tr><tr><td>val/loss_end_epoch</td><td>█▁</td></tr><tr><td>val/loss_epoch</td><td>█▁</td></tr><tr><td>val/loss_start_epoch</td><td>█▁</td></tr><tr><td>val/loss_step</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>train/loss_end_epoch</td><td>0.58368</td></tr><tr><td>train/loss_epoch</td><td>0.86416</td></tr><tr><td>train/loss_start_epoch</td><td>0.45043</td></tr><tr><td>train/loss_step</td><td>0.7666</td></tr><tr><td>trainer/global_step</td><td>8197</td></tr><tr><td>val/jaccard_epoch</td><td>0.69496</td></tr><tr><td>val/loss_end_epoch</td><td>0.19972</td></tr><tr><td>val/loss_epoch</td><td>0.24376</td></tr><tr><td>val/loss_start_epoch</td><td>0.18118</td></tr><tr><td>val/loss_step</td><td>0.22803</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">exp025_fold_0</strong>: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/2mchcys0\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/2mchcys0</a><br/>\n","Find logs at: <code>./wandb/run-20211113_172004-2mchcys0/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b831ee91fe8477fa5a0a61a0800c88a","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/11184 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0783081fa334e31badb5d4b5c05582c","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/112 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 24333, Number of valid features: 1755\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mazupero\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"name":"stdout","output_type":"stream","text":["Total Training Steps: 8112, Total Warmup Steps: 811\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1nre27oc\" target=\"_blank\">exp025_fold_1</a></strong> to <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name              | Type             | Params\n","-------------------------------------------------------\n","0 | model             | ChaiiModel       | 559 M \n","1 | start_criterion   | CrossEntropyLoss | 0     \n","2 | end_criterion     | CrossEntropyLoss | 0     \n","3 | train_mean_metric | MeanMetric       | 0     \n","4 | valid_mean_metric | MeanMetric       | 0     \n","-------------------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp025 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"039fbf2f9f8d4763b1ede21a5dde9818","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f46542aa81e54ba99c98884cda7df3d9","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05625f96169249cb953c49e5a940ba36","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e672c6c9190c4261acd9757cfa1b978a","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 795... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28fcb690bba8460c9ff064553b7c80e7","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>lr-AdamW/pg1</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss_end_epoch</td><td>█▁</td></tr><tr><td>train/loss_epoch</td><td>█▁</td></tr><tr><td>train/loss_start_epoch</td><td>█▁</td></tr><tr><td>train/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▁▁▁▅▅▅▅▅▆▆▆▆▆▇▇▇▇███▁▁▁</td></tr><tr><td>val/jaccard_epoch</td><td>▁█</td></tr><tr><td>val/loss_end_epoch</td><td>█▁</td></tr><tr><td>val/loss_epoch</td><td>█▁</td></tr><tr><td>val/loss_start_epoch</td><td>▁█</td></tr><tr><td>val/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>train/loss_end_epoch</td><td>0.59743</td></tr><tr><td>train/loss_epoch</td><td>0.88103</td></tr><tr><td>train/loss_start_epoch</td><td>0.46767</td></tr><tr><td>train/loss_step</td><td>0.78104</td></tr><tr><td>trainer/global_step</td><td>8111</td></tr><tr><td>val/jaccard_epoch</td><td>0.74583</td></tr><tr><td>val/loss_end_epoch</td><td>0.21319</td></tr><tr><td>val/loss_epoch</td><td>0.26163</td></tr><tr><td>val/loss_start_epoch</td><td>0.20508</td></tr><tr><td>val/loss_step</td><td>0.23862</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">exp025_fold_1</strong>: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1nre27oc\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1nre27oc</a><br/>\n","Find logs at: <code>./wandb/run-20211113_183626-1nre27oc/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d992e57909d94971a939530b6ea82534","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/11184 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63c17b34f12747c58a12914864fce0b1","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/112 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 24780, Number of valid features: 1308\n","Total Training Steps: 8260, Total Warmup Steps: 826\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/cn6hl9np\" target=\"_blank\">exp025_fold_2</a></strong> to <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name              | Type             | Params\n","-------------------------------------------------------\n","0 | model             | ChaiiModel       | 559 M \n","1 | start_criterion   | CrossEntropyLoss | 0     \n","2 | end_criterion     | CrossEntropyLoss | 0     \n","3 | train_mean_metric | MeanMetric       | 0     \n","4 | valid_mean_metric | MeanMetric       | 0     \n","-------------------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp025 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a769ccc7be543acbfd0110b8589f1ac","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3a9b355b45c4ddb951a6c68181ed296","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5542cc2d008546a69a631fe02f15e922","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae1d850d0918441e9120fcbc36d04a77","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 1029... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6800f2a343034b6da3e46e5711912451","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>lr-AdamW/pg1</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss_end_epoch</td><td>█▁</td></tr><tr><td>train/loss_epoch</td><td>█▁</td></tr><tr><td>train/loss_start_epoch</td><td>█▁</td></tr><tr><td>train/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▁▁▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███▁▁</td></tr><tr><td>val/jaccard_epoch</td><td>▁█</td></tr><tr><td>val/loss_end_epoch</td><td>█▁</td></tr><tr><td>val/loss_epoch</td><td>█▁</td></tr><tr><td>val/loss_start_epoch</td><td>█▁</td></tr><tr><td>val/loss_step</td><td>█▅▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>train/loss_end_epoch</td><td>0.58334</td></tr><tr><td>train/loss_epoch</td><td>0.86273</td></tr><tr><td>train/loss_start_epoch</td><td>0.45731</td></tr><tr><td>train/loss_step</td><td>0.7629</td></tr><tr><td>trainer/global_step</td><td>8259</td></tr><tr><td>val/jaccard_epoch</td><td>0.6898</td></tr><tr><td>val/loss_end_epoch</td><td>0.28835</td></tr><tr><td>val/loss_epoch</td><td>0.32482</td></tr><tr><td>val/loss_start_epoch</td><td>0.25185</td></tr><tr><td>val/loss_step</td><td>0.31174</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">exp025_fold_2</strong>: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/cn6hl9np\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/cn6hl9np</a><br/>\n","Find logs at: <code>./wandb/run-20211113_195232-cn6hl9np/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52b74d2dfd7049688a1a9dc427b6884d","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/11184 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9637a8a810e94a54aa400fbafc11a42b","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/112 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 24494, Number of valid features: 1594\n","Total Training Steps: 8166, Total Warmup Steps: 816\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/3pcwyh23\" target=\"_blank\">exp025_fold_3</a></strong> to <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name              | Type             | Params\n","-------------------------------------------------------\n","0 | model             | ChaiiModel       | 559 M \n","1 | start_criterion   | CrossEntropyLoss | 0     \n","2 | end_criterion     | CrossEntropyLoss | 0     \n","3 | train_mean_metric | MeanMetric       | 0     \n","4 | valid_mean_metric | MeanMetric       | 0     \n","-------------------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp025 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae0ae41f76ec4362b724be4898dfc9f4","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f3cff8f91a346e2b7d1847a3086f715","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f74d9c38c1114b75a6630c6899c4b921","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0096079c8bb94f539f0633905a7b88f5","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 1260... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6fce85b50d849e2a654cef859440dcf","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>lr-AdamW/pg1</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss_end_epoch</td><td>█▁</td></tr><tr><td>train/loss_epoch</td><td>█▁</td></tr><tr><td>train/loss_start_epoch</td><td>█▁</td></tr><tr><td>train/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▁▁▁▅▅▅▅▅▆▆▆▆▇▇▇▇▇███▁▁▁</td></tr><tr><td>val/jaccard_epoch</td><td>▁█</td></tr><tr><td>val/loss_end_epoch</td><td>█▁</td></tr><tr><td>val/loss_epoch</td><td>█▁</td></tr><tr><td>val/loss_start_epoch</td><td>█▁</td></tr><tr><td>val/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>train/loss_end_epoch</td><td>0.63442</td></tr><tr><td>train/loss_epoch</td><td>0.9076</td></tr><tr><td>train/loss_start_epoch</td><td>0.49713</td></tr><tr><td>train/loss_step</td><td>0.81056</td></tr><tr><td>trainer/global_step</td><td>8165</td></tr><tr><td>val/jaccard_epoch</td><td>0.63571</td></tr><tr><td>val/loss_end_epoch</td><td>0.20967</td></tr><tr><td>val/loss_epoch</td><td>0.27113</td></tr><tr><td>val/loss_start_epoch</td><td>0.20211</td></tr><tr><td>val/loss_step</td><td>0.25163</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">exp025_fold_3</strong>: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/3pcwyh23\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/3pcwyh23</a><br/>\n","Find logs at: <code>./wandb/run-20211113_210922-3pcwyh23/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b427c2b3c0a49b2ab143978c9fafed5","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/11185 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84cf762632934a4a9f70860b35a6d6b9","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/111 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 24712, Number of valid features: 1376\n","Total Training Steps: 8238, Total Warmup Steps: 823\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/13uam7r8\" target=\"_blank\">exp025_fold_4</a></strong> to <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name              | Type             | Params\n","-------------------------------------------------------\n","0 | model             | ChaiiModel       | 559 M \n","1 | start_criterion   | CrossEntropyLoss | 0     \n","2 | end_criterion     | CrossEntropyLoss | 0     \n","3 | train_mean_metric | MeanMetric       | 0     \n","4 | valid_mean_metric | MeanMetric       | 0     \n","-------------------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp025 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0ddc54ba2ae46f180aa1114af20827a","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50769c872b17454a831167c6002009dc","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d0879f4d87f4e6dba2b9e281b00e931","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4bed05484fb4821bddb68158e95225b","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 1491... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d955dfb5a3c944d083bb603bf4ba3391","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>lr-AdamW/pg1</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss_end_epoch</td><td>█▁</td></tr><tr><td>train/loss_epoch</td><td>█▁</td></tr><tr><td>train/loss_start_epoch</td><td>█▁</td></tr><tr><td>train/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▁▁▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██▁▁█</td></tr><tr><td>val/jaccard_epoch</td><td>▁█</td></tr><tr><td>val/loss_end_epoch</td><td>█▁</td></tr><tr><td>val/loss_epoch</td><td>█▁</td></tr><tr><td>val/loss_start_epoch</td><td>█▁</td></tr><tr><td>val/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>train/loss_end_epoch</td><td>0.60919</td></tr><tr><td>train/loss_epoch</td><td>0.87563</td></tr><tr><td>train/loss_start_epoch</td><td>0.47351</td></tr><tr><td>train/loss_step</td><td>0.78006</td></tr><tr><td>trainer/global_step</td><td>8237</td></tr><tr><td>val/jaccard_epoch</td><td>0.61471</td></tr><tr><td>val/loss_end_epoch</td><td>0.29827</td></tr><tr><td>val/loss_epoch</td><td>0.37253</td></tr><tr><td>val/loss_start_epoch</td><td>0.27645</td></tr><tr><td>val/loss_step</td><td>0.34473</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">exp025_fold_4</strong>: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/13uam7r8\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/13uam7r8</a><br/>\n","Find logs at: <code>./wandb/run-20211113_222532-13uam7r8/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d44890fd28e43d08f173b0d7ddf77e5","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/11185 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36ff110db27d40c8ba7a851f5a5d4c4a","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/111 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 24590, Number of valid features: 1498\n","Total Training Steps: 8198, Total Warmup Steps: 819\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/104rb7jh\" target=\"_blank\">exp025_fold_5</a></strong> to <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name              | Type             | Params\n","-------------------------------------------------------\n","0 | model             | ChaiiModel       | 559 M \n","1 | start_criterion   | CrossEntropyLoss | 0     \n","2 | end_criterion     | CrossEntropyLoss | 0     \n","3 | train_mean_metric | MeanMetric       | 0     \n","4 | valid_mean_metric | MeanMetric       | 0     \n","-------------------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp025 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42ea3a28cf494027b4bb578ebcde964a","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b440dc1f85c7419598f7041eb972846b","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c32b9cd8b96468aa8f53038688c4424","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0449fc03ca154129bb8c75ea5fbc79dd","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 1724... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe759a525e1349249befcbca61ebaeac","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>lr-AdamW/pg1</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss_end_epoch</td><td>█▁</td></tr><tr><td>train/loss_epoch</td><td>█▁</td></tr><tr><td>train/loss_start_epoch</td><td>█▁</td></tr><tr><td>train/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▁▁▅▅▅▅▅▆▆▆▆▆▇▇▇▇███▁▁▁</td></tr><tr><td>val/jaccard_epoch</td><td>▁█</td></tr><tr><td>val/loss_end_epoch</td><td>█▁</td></tr><tr><td>val/loss_epoch</td><td>█▁</td></tr><tr><td>val/loss_start_epoch</td><td>█▁</td></tr><tr><td>val/loss_step</td><td>█▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>train/loss_end_epoch</td><td>0.61183</td></tr><tr><td>train/loss_epoch</td><td>0.87405</td></tr><tr><td>train/loss_start_epoch</td><td>0.47149</td></tr><tr><td>train/loss_step</td><td>0.77758</td></tr><tr><td>trainer/global_step</td><td>8197</td></tr><tr><td>val/jaccard_epoch</td><td>0.71388</td></tr><tr><td>val/loss_end_epoch</td><td>0.22062</td></tr><tr><td>val/loss_epoch</td><td>0.29505</td></tr><tr><td>val/loss_start_epoch</td><td>0.20513</td></tr><tr><td>val/loss_step</td><td>0.25807</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">exp025_fold_5</strong>: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/104rb7jh\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/104rb7jh</a><br/>\n","Find logs at: <code>./wandb/run-20211113_234224-104rb7jh/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08f717838ae04f28929cbd07c7e4607e","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/11185 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0021f2409fea4511a417357745024740","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/111 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 24913, Number of valid features: 1175\n","Total Training Steps: 8306, Total Warmup Steps: 830\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/3vpl1gd5\" target=\"_blank\">exp025_fold_6</a></strong> to <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name              | Type             | Params\n","-------------------------------------------------------\n","0 | model             | ChaiiModel       | 559 M \n","1 | start_criterion   | CrossEntropyLoss | 0     \n","2 | end_criterion     | CrossEntropyLoss | 0     \n","3 | train_mean_metric | MeanMetric       | 0     \n","4 | valid_mean_metric | MeanMetric       | 0     \n","-------------------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp025 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ec3c593054340f39519eac7f1d82afe","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07a3c35d09714759a450e03098c8ccd1","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61efbf2e48614866818942a66fcc9ccc","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65e167fef0374d3691b6976178ca8020","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 1957... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad3536d309d940d38bcd6f0cb58bf80c","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>lr-AdamW/pg1</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss_end_epoch</td><td>█▁</td></tr><tr><td>train/loss_epoch</td><td>█▁</td></tr><tr><td>train/loss_start_epoch</td><td>█▁</td></tr><tr><td>train/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▁▁▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███▁▁</td></tr><tr><td>val/jaccard_epoch</td><td>█▁</td></tr><tr><td>val/loss_end_epoch</td><td>█▁</td></tr><tr><td>val/loss_epoch</td><td>█▁</td></tr><tr><td>val/loss_start_epoch</td><td>▁█</td></tr><tr><td>val/loss_step</td><td>█▅▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>train/loss_end_epoch</td><td>0.58411</td></tr><tr><td>train/loss_epoch</td><td>0.86009</td></tr><tr><td>train/loss_start_epoch</td><td>0.45424</td></tr><tr><td>train/loss_step</td><td>0.76161</td></tr><tr><td>trainer/global_step</td><td>8305</td></tr><tr><td>val/jaccard_epoch</td><td>0.6973</td></tr><tr><td>val/loss_end_epoch</td><td>0.26583</td></tr><tr><td>val/loss_epoch</td><td>0.30703</td></tr><tr><td>val/loss_start_epoch</td><td>0.23492</td></tr><tr><td>val/loss_step</td><td>0.29273</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">exp025_fold_6</strong>: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/3vpl1gd5\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/3vpl1gd5</a><br/>\n","Find logs at: <code>./wandb/run-20211114_005901-3vpl1gd5/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a954e8a09c44d5e9ef96e1bc1ed5ad5","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/11185 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67a7c4a0a1ba417f930f53fbd7959235","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/111 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 24683, Number of valid features: 1405\n","Total Training Steps: 8228, Total Warmup Steps: 822\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1aoov5j7\" target=\"_blank\">exp025_fold_7</a></strong> to <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name              | Type             | Params\n","-------------------------------------------------------\n","0 | model             | ChaiiModel       | 559 M \n","1 | start_criterion   | CrossEntropyLoss | 0     \n","2 | end_criterion     | CrossEntropyLoss | 0     \n","3 | train_mean_metric | MeanMetric       | 0     \n","4 | valid_mean_metric | MeanMetric       | 0     \n","-------------------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp025 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4ce5325ada9433896952faade68abf8","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9dbcaa1c12444d4bbfc24bd21f04686a","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c44ab73eab541aea9d80c3dc48dfd08","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c3f79b1b9144018bb1c93ab6f7806cc","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 2190... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d10191886f414bf0bd02d2b23d8da335","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>lr-AdamW/pg1</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss_end_epoch</td><td>█▁</td></tr><tr><td>train/loss_epoch</td><td>█▁</td></tr><tr><td>train/loss_start_epoch</td><td>█▁</td></tr><tr><td>train/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▁▁▅▅▅▅▅▆▆▆▆▆▇▇▇▇███▁▁▁</td></tr><tr><td>val/jaccard_epoch</td><td>█▁</td></tr><tr><td>val/loss_end_epoch</td><td>▁█</td></tr><tr><td>val/loss_epoch</td><td>█▁</td></tr><tr><td>val/loss_start_epoch</td><td>▁█</td></tr><tr><td>val/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>train/loss_end_epoch</td><td>0.5712</td></tr><tr><td>train/loss_epoch</td><td>0.85982</td></tr><tr><td>train/loss_start_epoch</td><td>0.44597</td></tr><tr><td>train/loss_step</td><td>0.75905</td></tr><tr><td>trainer/global_step</td><td>8227</td></tr><tr><td>val/jaccard_epoch</td><td>0.62801</td></tr><tr><td>val/loss_end_epoch</td><td>0.27268</td></tr><tr><td>val/loss_epoch</td><td>0.3012</td></tr><tr><td>val/loss_start_epoch</td><td>0.22331</td></tr><tr><td>val/loss_step</td><td>0.27904</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">exp025_fold_7</strong>: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1aoov5j7\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/1aoov5j7</a><br/>\n","Find logs at: <code>./wandb/run-20211114_021627-1aoov5j7/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8d5b215f0fd46eaacfbd8b065feabb9","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/11185 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea1d0c82fafe430bb2d5096d5f06670b","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/111 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 24794, Number of valid features: 1294\n","Total Training Steps: 8266, Total Warmup Steps: 826\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/27vl1ssc\" target=\"_blank\">exp025_fold_8</a></strong> to <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name              | Type             | Params\n","-------------------------------------------------------\n","0 | model             | ChaiiModel       | 559 M \n","1 | start_criterion   | CrossEntropyLoss | 0     \n","2 | end_criterion     | CrossEntropyLoss | 0     \n","3 | train_mean_metric | MeanMetric       | 0     \n","4 | valid_mean_metric | MeanMetric       | 0     \n","-------------------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp025 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcf0d17e9dbd43dba6bd662204a07c9b","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08c475d72fa340e0a8784ebbfdf7f212","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d685ab6eebc34452ab5b9329bb7e85bc","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ada66bfbf84f4526bcfb6b0da108ec97","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 2421... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04d14621024840e8b95505ebcabfe903","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>lr-AdamW/pg1</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss_end_epoch</td><td>█▁</td></tr><tr><td>train/loss_epoch</td><td>█▁</td></tr><tr><td>train/loss_start_epoch</td><td>█▁</td></tr><tr><td>train/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▁▁▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███▁▁</td></tr><tr><td>val/jaccard_epoch</td><td>▁█</td></tr><tr><td>val/loss_end_epoch</td><td>█▁</td></tr><tr><td>val/loss_epoch</td><td>█▁</td></tr><tr><td>val/loss_start_epoch</td><td>█▁</td></tr><tr><td>val/loss_step</td><td>█▄▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>train/loss_end_epoch</td><td>0.60312</td></tr><tr><td>train/loss_epoch</td><td>0.88642</td></tr><tr><td>train/loss_start_epoch</td><td>0.47404</td></tr><tr><td>train/loss_step</td><td>0.78692</td></tr><tr><td>trainer/global_step</td><td>8265</td></tr><tr><td>val/jaccard_epoch</td><td>0.70962</td></tr><tr><td>val/loss_end_epoch</td><td>0.26623</td></tr><tr><td>val/loss_epoch</td><td>0.31502</td></tr><tr><td>val/loss_start_epoch</td><td>0.21893</td></tr><tr><td>val/loss_step</td><td>0.28719</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">exp025_fold_8</strong>: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/27vl1ssc\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/27vl1ssc</a><br/>\n","Find logs at: <code>./wandb/run-20211114_033317-27vl1ssc/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d569df3259ca405e9e4cb671d1ce0d8d","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/11185 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e3d56ded1ca4220a38508e309d0aa8e","version_major":2,"version_minor":0},"text/plain":["[get features]:   0%|          | 0/111 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Number of train features: 24801, Number of valid features: 1287\n","Total Training Steps: 8268, Total Warmup Steps: 826\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/2mtdh49s\" target=\"_blank\">exp025_fold_9</a></strong> to <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  | Name              | Type             | Params\n","-------------------------------------------------------\n","0 | model             | ChaiiModel       | 559 M \n","1 | start_criterion   | CrossEntropyLoss | 0     \n","2 | end_criterion     | CrossEntropyLoss | 0     \n","3 | train_mean_metric | MeanMetric       | 0     \n","4 | valid_mean_metric | MeanMetric       | 0     \n","-------------------------------------------------------\n","559 M     Trainable params\n","0         Non-trainable params\n","559 M     Total params\n","2,239.570 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab/kaggle/chaii-hindi-and-tamil-question-answering/checkpoint/exp025 exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2c6381da4d74b40abfca5f4242438bd","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Global seed set to 2434\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"460e32b717154aac9c0bd09bdff161f8","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78ce64815c064a4e9d33d548bbee5ab0","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79452459dfbe4ad0865d69ab3eba4861","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 2648... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d93f8757788349048e845a2a2b69c994","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>lr-AdamW/pg1</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>lr-AdamW/pg2</td><td>▂▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss_end_epoch</td><td>█▁</td></tr><tr><td>train/loss_epoch</td><td>█▁</td></tr><tr><td>train/loss_start_epoch</td><td>█▁</td></tr><tr><td>train/loss_step</td><td>█▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▁▁▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███▁▁</td></tr><tr><td>val/jaccard_epoch</td><td>█▁</td></tr><tr><td>val/loss_end_epoch</td><td>█▁</td></tr><tr><td>val/loss_epoch</td><td>█▁</td></tr><tr><td>val/loss_start_epoch</td><td>█▁</td></tr><tr><td>val/loss_step</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>lr-AdamW/pg1</td><td>0.0</td></tr><tr><td>lr-AdamW/pg2</td><td>0.0</td></tr><tr><td>train/loss_end_epoch</td><td>0.6082</td></tr><tr><td>train/loss_epoch</td><td>0.88672</td></tr><tr><td>train/loss_start_epoch</td><td>0.47425</td></tr><tr><td>train/loss_step</td><td>0.78824</td></tr><tr><td>trainer/global_step</td><td>8267</td></tr><tr><td>val/jaccard_epoch</td><td>0.6787</td></tr><tr><td>val/loss_end_epoch</td><td>0.23624</td></tr><tr><td>val/loss_epoch</td><td>0.26935</td></tr><tr><td>val/loss_start_epoch</td><td>0.21382</td></tr><tr><td>val/loss_step</td><td>0.26623</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">exp025_fold_9</strong>: <a href=\"https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/2mtdh49s\" target=\"_blank\">https://wandb.ai/azupero/kaggle-chaii-hindi-and-tamil-question-answering/runs/2mtdh49s</a><br/>\n","Find logs at: <code>./wandb/run-20211114_045027-2mtdh49s/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MbsE5t9-jbB3","executionInfo":{"status":"ok","timestamp":1636875404633,"user_tz":-540,"elapsed":563545,"user":{"displayName":"永友遥","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8XdDU-0vxRr4CR7yDupYRXQbKwd1ubt2GOx9uTQ=s64","userId":"11743586908271963047"}},"outputId":"986f386b-42ca-46ff-ec6f-1649442dff0e"},"source":["ID = \"azupero\"\n","DATASET_ID = f\"chaii-qa-checkpoint-{cfg.exp_name}\"\n","checkpoint_path = cfg.checkpoint_dir + \"/\" + cfg.exp_name\n","UPLOAD_DIR = Path(checkpoint_path)\n","\n","def dataset_create_new():\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{ID}/{DATASET_ID}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = DATASET_ID\n","    with open(UPLOAD_DIR / 'dataset-metadata.json', 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=UPLOAD_DIR, convert_to_csv=False, dir_mode='tar')\n","\n","dataset_create_new()"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting upload for file exp025-fold-0-epoch=1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.09G/2.09G [00:55<00:00, 40.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp025-fold-0-epoch=1.ckpt (2GB)\n","Starting upload for file exp025-fold-1-epoch=1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.09G/2.09G [00:55<00:00, 40.2MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp025-fold-1-epoch=1.ckpt (2GB)\n","Starting upload for file exp025-fold-2-epoch=1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.09G/2.09G [00:55<00:00, 40.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp025-fold-2-epoch=1.ckpt (2GB)\n","Starting upload for file exp025-fold-3-epoch=1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.09G/2.09G [00:54<00:00, 41.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp025-fold-3-epoch=1.ckpt (2GB)\n","Starting upload for file exp025-fold-4-epoch=1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.09G/2.09G [00:56<00:00, 40.0MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp025-fold-4-epoch=1.ckpt (2GB)\n","Starting upload for file exp025-fold-5-epoch=1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.09G/2.09G [00:56<00:00, 39.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp025-fold-5-epoch=1.ckpt (2GB)\n","Starting upload for file exp025-fold-6-epoch=1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.09G/2.09G [00:55<00:00, 40.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp025-fold-6-epoch=1.ckpt (2GB)\n","Starting upload for file exp025-fold-7-epoch=1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.09G/2.09G [00:56<00:00, 39.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp025-fold-7-epoch=1.ckpt (2GB)\n","Starting upload for file exp025-fold-8-epoch=1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.09G/2.09G [00:55<00:00, 40.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp025-fold-8-epoch=1.ckpt (2GB)\n","Starting upload for file exp025-fold-9-epoch=1.ckpt\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.09G/2.09G [00:54<00:00, 40.8MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp025-fold-9-epoch=1.ckpt (2GB)\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"J9EHMBsWPkzL"},"source":[""],"execution_count":null,"outputs":[]}]}